{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cpu'\n",
    "if torch.backends.mps.is_available():\n",
    "    DEVICE = 'mps'\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "DATA_PATH = Path('data/')\n",
    "DATA_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "DATA_CACHE = Path('data/cache_dir/')\n",
    "DATA_CACHE.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "DATA_PATH_SAVE_MODELS = Path('data/models/')\n",
    "DATA_PATH_SAVE_MODELS.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "pd.set_option('display.max_colwidth', 500) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"roberta-base\"\n",
    "TEST_DF_NAME = \"facebook_data_to_model.xlsx\"\n",
    "\n",
    "MAX_LENGTH = 128\n",
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_excel(DATA_PATH / TEST_DF_NAME).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = data_df.dropna(how='all')\n",
    "data_df['text'] = data_df['text'].astype(str)\n",
    "data_df = data_df[~data_df['text'].isin([None, 'none', 'nan']) & data_df['text'].notna() & (data_df['text'] != '')]\n",
    "data_df[\"truncated_text\"] = data_df[\"text\"].str[:200]\n",
    "data_df[\"id\"] = data_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_df = data_df.sample(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer\n",
    "\n",
    "tokenizer: RobertaTokenizer = RobertaTokenizer.from_pretrained(MODEL_NAME, cache_dir=DATA_CACHE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaModel\n",
    "\n",
    "model = RobertaModel.from_pretrained(\n",
    "    MODEL_NAME, cache_dir=DATA_CACHE)\n",
    "\n",
    "model.to(DEVICE)\n",
    "model.eval()\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "import numpy as np\n",
    "from typing import List\n",
    "\n",
    "def add_word2vec_embeddings(\n",
    "    texts: List[str], \n",
    "    model: KeyedVectors, \n",
    "    strategy: str = \"mean\"\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Generates embeddings for a list of texts using a pre-trained Word2Vec model.\n",
    "\n",
    "    Parameters:\n",
    "    - texts: List of texts to process.\n",
    "    - model: Pre-trained Word2Vec model (KeyedVectors).\n",
    "    - strategy: Token aggregation strategy (\"mean\", \"max\", \"sum\").\n",
    "\n",
    "    Returns:\n",
    "    - NumPy array of embeddings (shape: [num_texts, embedding_dim]).\n",
    "    \"\"\"\n",
    "    embeddings = []\n",
    "    for text in texts:\n",
    "        words = text.split()\n",
    "        word_vectors = [model[word] for word in words if word in model]\n",
    "\n",
    "        if not word_vectors:\n",
    "            embedding = np.zeros(model.vector_size)\n",
    "        else:\n",
    "            word_vectors = np.array(word_vectors)\n",
    "            if strategy == \"mean\":\n",
    "                embedding = word_vectors.mean(axis=0)\n",
    "            elif strategy == \"max\":\n",
    "                embedding = word_vectors.max(axis=0)\n",
    "            elif strategy == \"sum\":\n",
    "                embedding = word_vectors.sum(axis=0)\n",
    "            else:\n",
    "                raise ValueError(\"Invalid strategy. Choose from ['mean', 'max', 'sum'].\")\n",
    "\n",
    "        embeddings.append(embedding)\n",
    "\n",
    "    return np.array(embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import gensim.downloader as api\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "save_path = api.load(\"word2vec-google-news-300\", return_path=True)\n",
    "print(\"Model path:\", save_path)\n",
    "\n",
    "w2v_model = KeyedVectors.load_word2vec_format(save_path, binary=True)\n",
    "\n",
    "embeddings = add_word2vec_embeddings(data_df['text'].to_list(), w2v_model, strategy=\"mean\")\n",
    "\n",
    "with open(DATA_PATH / 'facebook_embeddings_word2vec.pkl', 'wb') as f:\n",
    "    pickle.dump(embeddings, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import umap\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from typing import Literal\n",
    "from scipy.spatial import cKDTree\n",
    "\n",
    "\n",
    "\n",
    "class EmbeddingVisualizer:\n",
    "    def __init__(self, embeddings: np.ndarray, data_df: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        A universal class for dimensionality reduction of embeddings and visualization.\n",
    "\n",
    "        :param embeddings: Embedding array (shape: [num_samples, embedding_dim])\n",
    "        :param data_df: DataFrame with additional data (e.g., text, predict_1, id)\n",
    "        \"\"\"\n",
    "        self.embeddings = embeddings\n",
    "        self.data_df = data_df.copy()\n",
    "        self.reduced_embeddings = None\n",
    "    \n",
    "    def reduce_dimensionality(self, method: Literal[\"pca\", \"tsne\", \"umap\"], n_components: int = 2):\n",
    "        \"\"\"\n",
    "        Reduces the dimensionality of the embeddings using the specified method.\n",
    "        \n",
    "        :param method: Dimensionality reduction method ('pca', 'tsne', 'umap')\n",
    "        :param n_components: Number of target dimensions (2 or 3 for visualization)\n",
    "        \"\"\"\n",
    "        if method == \"pca\":\n",
    "            reducer = PCA(n_components=n_components)\n",
    "        elif method == \"tsne\":\n",
    "            reducer = TSNE(n_components=n_components, perplexity=30, random_state=42)\n",
    "        elif method == \"umap\":\n",
    "            reducer = umap.UMAP(n_components=n_components, random_state=42)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported method. Use 'pca', 'tsne', or 'umap'.\")\n",
    "        \n",
    "        self.reduced_embeddings = reducer.fit_transform(self.embeddings)\n",
    "        for i in range(n_components):\n",
    "            self.data_df[f\"{method}_{i+1}\"] = self.reduced_embeddings[:, i]\n",
    "    \n",
    "    def compute_opacity(self, points: np.ndarray, radius: float = 0.1) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Computes the opacity of points based on their density.\n",
    "        Now denser points are brighter, and sparse points are dimmer.\n",
    "        \n",
    "        :param points: Array of coordinates (Nx2 or Nx3)\n",
    "        :param radius: Radius for density calculation of points\n",
    "        :return: Array of opacity values (0.3 - 1.0)\n",
    "        \"\"\"\n",
    "        tree = cKDTree(points)\n",
    "        densities = np.array([len(tree.query_ball_point(p, radius)) for p in points])\n",
    "        min_density = np.min(densities)\n",
    "        max_density = np.max(densities)\n",
    "        opacities = 0.3 + (densities - min_density) / (max_density - min_density) * 0.7  # Inverts opacity\n",
    "        return np.clip(opacities, 0.3, 1.0)\n",
    "    \n",
    "    def visualize(self, method: Literal[\"pca\", \"tsne\", \"umap\"], n_components: int = 2, title: str = \"Embedding Visualization\"):\n",
    "        \"\"\"\n",
    "        Visualizes the reduced embeddings with interactive points in Plotly.\n",
    "        \n",
    "        :param method: Method used for dimensionality reduction ('pca', 'tsne', 'umap')\n",
    "        :param n_components: Dimensionality for visualization (2D or 3D)\n",
    "        :param title: Plot title\n",
    "        \"\"\"\n",
    "        if self.reduced_embeddings is None or f\"{method}_1\" not in self.data_df.columns:\n",
    "            raise ValueError(\"Call reduce_dimensionality() first.\")\n",
    "        \n",
    "        coords = self.reduced_embeddings[:, :n_components]\n",
    "        opacities = self.compute_opacity(coords)\n",
    "                \n",
    "        fig = go.Figure()\n",
    "        \n",
    "        if n_components == 2:\n",
    "\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=self.data_df[f\"{method}_1\"],\n",
    "                y=self.data_df[f\"{method}_2\"],\n",
    "                mode=\"markers\",\n",
    "                marker=dict(\n",
    "                    size=8,\n",
    "                    opacity=opacities,\n",
    "                ),\n",
    "                name=f\"Post's text\",\n",
    "                customdata=self.data_df[[\"truncated_text\", \"id\"]],\n",
    "                hovertemplate=(\n",
    "                    \"<b>Text:</b> %{customdata[0]}<br>\" \n",
    "                    \"<b>ID:</b> %{customdata[1]}\"\n",
    "                )\n",
    "            ))\n",
    "        else:\n",
    "\n",
    "            fig.add_trace(go.Scatter3d(\n",
    "                x=self.data_df[f\"{method}_1\"],\n",
    "                y=self.data_df[f\"{method}_2\"],\n",
    "                z=self.data_df[f\"{method}_3\"],\n",
    "                mode=\"markers\",\n",
    "                marker=dict(\n",
    "                    size=5,\n",
    "                ),\n",
    "                name=f\"Post's text\",\n",
    "                customdata=self.data_df[[\"truncated_text\", \"id\"]],\n",
    "                hovertemplate=(\n",
    "                    \"<b>Text:</b> %{customdata[0]}<br>\" \n",
    "                    \"<b>ID:</b> %{customdata[1]}\"\n",
    "                )\n",
    "            ))\n",
    "        \n",
    "        fig.update_layout(\n",
    "            title=title,\n",
    "            xaxis=dict(\n",
    "                title=f\"{method.upper()} 1 →\",  # Adds arrow\n",
    "                showline=True,  # Adds border\n",
    "                linewidth=2,\n",
    "                linecolor=\"black\",\n",
    "                mirror=True,  # Border around the whole plot area\n",
    "                gridcolor=\"lightgray\",\n",
    "                gridwidth=0.5,  # Makes grid thinner\n",
    "                zeroline=True,  # X axis passes through 0\n",
    "                zerolinecolor=\"black\",\n",
    "                zerolinewidth=1.2\n",
    "            ),\n",
    "            yaxis=dict(\n",
    "                title=f\"{method.upper()} 2 →\",  # Adds arrow\n",
    "                showline=True,\n",
    "                linewidth=2,\n",
    "                linecolor=\"black\",\n",
    "                mirror=True,\n",
    "                gridcolor=\"lightgray\",\n",
    "                gridwidth=0.5,\n",
    "                zeroline=True,  # Y axis passes through 0\n",
    "                zerolinecolor=\"black\",\n",
    "                zerolinewidth=1.2\n",
    "            ),\n",
    "            template=\"plotly_white\",\n",
    "            width=1400,\n",
    "            height=1000,\n",
    "            legend_title=\"Class Labels\"\n",
    "        )\n",
    "\n",
    "        if n_components == 3:\n",
    "            fig.update_layout(scene=dict(\n",
    "                xaxis=dict(\n",
    "                    title=f\"{method.upper()} 1 →\",  # Adds arrow\n",
    "                    showline=True,\n",
    "                    linewidth=2,\n",
    "                    linecolor=\"black\",\n",
    "                    mirror=True,\n",
    "                    gridcolor=\"lightgray\",\n",
    "                    gridwidth=0.5\n",
    "                ),\n",
    "                yaxis=dict(\n",
    "                    title=f\"{method.upper()} 2 →\",  # Adds arrow\n",
    "                    showline=True,\n",
    "                    linewidth=2,\n",
    "                    linecolor=\"black\",\n",
    "                    mirror=True,\n",
    "                    gridcolor=\"lightgray\",\n",
    "                    gridwidth=0.5\n",
    "                ),\n",
    "                zaxis=dict(\n",
    "                    title=f\"{method.upper()} 3 →\",  # Adds arrow\n",
    "                    showline=True,\n",
    "                    linewidth=2,\n",
    "                    linecolor=\"black\",\n",
    "                    mirror=True,\n",
    "                    gridcolor=\"lightgray\",\n",
    "                    gridwidth=0.5\n",
    "                )\n",
    "            ))\n",
    "        \n",
    "        if n_components == 3:\n",
    "            fig.update_layout(scene=dict(\n",
    "                xaxis_title=f\"{method.upper()} 1\",\n",
    "                yaxis_title=f\"{method.upper()} 2\",\n",
    "                zaxis_title=f\"{method.upper()} 3\"\n",
    "            )) \n",
    "                \n",
    "        fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer = EmbeddingVisualizer(embeddings, data_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer.reduce_dimensionality(\"pca\", n_components=2)\n",
    "visualizer.visualize(\"pca\", n_components=2, title=\"PCA 2D Visualization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizer.reduce_dimensionality(\"pca\", n_components=3)\n",
    "# visualizer.visualize(\"pca\", n_components=3, title=\"PCA 3D Visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TSNE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer.reduce_dimensionality(\"tsne\", n_components=2)\n",
    "visualizer.visualize(\"tsne\", n_components=2, title=\"t-SNE 2D Visualization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizer.reduce_dimensionality(\"tsne\", n_components=3)\n",
    "# visualizer.visualize(\"tsne\", n_components=3, title=\"t-SNE 3D Visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer.reduce_dimensionality(\"umap\", n_components=2)\n",
    "visualizer.visualize(\"umap\", n_components=2, title=\"UMAP 2D Visualization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizer.reduce_dimensionality(\"umap\", n_components=3)\n",
    "# visualizer.visualize(\"umap\", n_components=3, title=\"UMAP 3D Visualization\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
