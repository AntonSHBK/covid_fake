{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение определения фейковых фактов о COVID и вакцинации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cpu'\n",
    "if torch.backends.mps.is_available():\n",
    "    DEVICE = 'mps'\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "DATA_PATH = Path('data/')\n",
    "DATA_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "DATA_CACHE = Path('data/cache_dir/')\n",
    "DATA_CACHE.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "DATA_PATH_SAVE_MODELS = Path('data/models/')\n",
    "DATA_PATH_SAVE_MODELS.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "pd.set_option('display.max_colwidth', 500) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"covid_vaccine_fake_model\"\n",
    "TEST_DF_NAME = \"facebook_data_to_model.xlsx\"\n",
    "\n",
    "MAX_LENGTH = 128\n",
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Group Name</th>\n",
       "      <th>User Name</th>\n",
       "      <th>Facebook Id</th>\n",
       "      <th>Page Category</th>\n",
       "      <th>Page Admin Top Country</th>\n",
       "      <th>Page Description</th>\n",
       "      <th>Page Created</th>\n",
       "      <th>Likes at Posting</th>\n",
       "      <th>Followers at Posting</th>\n",
       "      <th>Post Created</th>\n",
       "      <th>...</th>\n",
       "      <th>Final Link</th>\n",
       "      <th>Image Text</th>\n",
       "      <th>Link Text</th>\n",
       "      <th>Description</th>\n",
       "      <th>Sponsor Id</th>\n",
       "      <th>Sponsor Name</th>\n",
       "      <th>Sponsor Category</th>\n",
       "      <th>Overperforming Score (weighted  —  Likes 1x Shares 1x Comments 1x Love 1x Wow 1x Haha 1x Sad 1x Angry 1x Care 1x )</th>\n",
       "      <th>text</th>\n",
       "      <th>link_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COVID19: Real Talk from Health Care Workers around the Globe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1073058046385811</td>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66994.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-04-01 22:42:32 EDT</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>189.33</td>\n",
       "      <td>We extubated 2 covid patients today and they are doing awesome! Should be on a tele floor tomorrow! (TX)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Group Name  User Name  \\\n",
       "0  COVID19: Real Talk from Health Care Workers around the Globe        NaN   \n",
       "\n",
       "        Facebook Id Page Category  Page Admin Top Country  Page Description  \\\n",
       "0  1073058046385811          none                     NaN               NaN   \n",
       "\n",
       "   Page Created  Likes at Posting  Followers at Posting  \\\n",
       "0           NaN           66994.0                   NaN   \n",
       "\n",
       "              Post Created  ... Final Link Image Text Link Text  Description  \\\n",
       "0  2020-04-01 22:42:32 EDT  ...        NaN        NaN       NaN          NaN   \n",
       "\n",
       "   Sponsor Id  Sponsor Name  Sponsor Category  \\\n",
       "0         NaN           NaN               NaN   \n",
       "\n",
       "   Overperforming Score (weighted  —  Likes 1x Shares 1x Comments 1x Love 1x Wow 1x Haha 1x Sad 1x Angry 1x Care 1x )  \\\n",
       "0                                                                                                              189.33   \n",
       "\n",
       "                                                                                                       text  \\\n",
       "0  We extubated 2 covid patients today and they are doing awesome! Should be on a tele floor tomorrow! (TX)   \n",
       "\n",
       "   link_text  \n",
       "0        NaN  \n",
       "\n",
       "[1 rows x 42 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_excel(DATA_PATH / TEST_DF_NAME)\n",
    "data_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_df = data_df.sample(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2label = {\n",
    "    0: \"Real\",\n",
    "    1: \"Fake\",\n",
    "    2: \"Comments\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Tuple\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import PreTrainedTokenizer\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class TokenizedDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataframe: pd.DataFrame,\n",
    "        tokenizer: PreTrainedTokenizer,\n",
    "        max_length: int,\n",
    "        text_column: str = \"text\",\n",
    "        link_text_column: str = \"link_text\",\n",
    "        tensor_dtype: Tuple[torch.dtype, torch.dtype] = (torch.long, torch.long),\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Инициализация датасета с ленивой токенизацией.\n",
    "\n",
    "        Args:\n",
    "            dataframe (pd.DataFrame): DataFrame с колонками для токенизации.\n",
    "            tokenizer (PreTrainedTokenizer): Токенайзер для преобразования текста.\n",
    "            max_length (int): Максимальная длина токенов.\n",
    "            text_column (str): Название основной текстовой колонки.\n",
    "            link_text_column (str): Название колонки с дополнительным текстом.\n",
    "            tensor_dtype (tuple): Типы данных для токенов (input_ids, attention_mask).\n",
    "        \"\"\"\n",
    "        self.dataframe = dataframe.copy()  # Копируем DataFrame, чтобы избежать изменений в оригинале\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.text_column = text_column\n",
    "        self.link_text_column = link_text_column\n",
    "        self.tensor_dtype = tensor_dtype\n",
    "\n",
    "        # Проверка, есть ли указанные колонки в DataFrame\n",
    "        if text_column not in dataframe.columns:\n",
    "            raise ValueError(f\"Колонка '{text_column}' отсутствует в DataFrame\")\n",
    "        if link_text_column not in dataframe.columns:\n",
    "            raise ValueError(f\"Колонка '{link_text_column}' отсутствует в DataFrame\")\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"\n",
    "        Возвращает количество примеров в датасете.\n",
    "        \"\"\"\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def _tokenize_text(self, text: str) -> Dict[str, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Токенизирует текст, если он не пустой, иначе возвращает тензоры с нулями.\n",
    "\n",
    "        Args:\n",
    "            text (str): Текст для токенизации.\n",
    "\n",
    "        Returns:\n",
    "            Dict[str, torch.Tensor]: Тензоры input_ids и attention_mask.\n",
    "        \"\"\"\n",
    "        if pd.isna(text) or text.strip() == \"\":\n",
    "            return {\n",
    "                \"input_ids\": torch.zeros(self.max_length, dtype=self.tensor_dtype[0]),\n",
    "                \"attention_mask\": torch.zeros(self.max_length, dtype=self.tensor_dtype[1]),\n",
    "            }\n",
    "        else:\n",
    "            tokens = self.tokenizer(\n",
    "                text,\n",
    "                max_length=self.max_length,\n",
    "                padding=\"max_length\",\n",
    "                truncation=True,\n",
    "                return_tensors=\"pt\",\n",
    "            )\n",
    "            return {\n",
    "                \"input_ids\": tokens[\"input_ids\"][0].to(dtype=self.tensor_dtype[0]),\n",
    "                \"attention_mask\": tokens[\"attention_mask\"][0].to(dtype=self.tensor_dtype[1]),\n",
    "            }\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Dict[str, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Возвращает токенизированные данные.\n",
    "\n",
    "        Args:\n",
    "            idx (int): Индекс примера.\n",
    "\n",
    "        Returns:\n",
    "            Dict[str, torch.Tensor]: Словарь с токенами из двух колонок.\n",
    "        \"\"\"\n",
    "        row = self.dataframe.iloc[idx]\n",
    "\n",
    "        text_tokens = self._tokenize_text(row[self.text_column])\n",
    "\n",
    "        link_text_tokens = self._tokenize_text(row[self.link_text_column])\n",
    "\n",
    "        return {\n",
    "            \"input_ids_text\": text_tokens[\"input_ids\"],\n",
    "            \"attention_mask_text\": text_tokens[\"attention_mask\"],\n",
    "            \"input_ids_link\": link_text_tokens[\"input_ids\"],\n",
    "            \"attention_mask_link\": link_text_tokens[\"attention_mask\"],\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer\n",
    "\n",
    "tokenizer: RobertaTokenizer = RobertaTokenizer.from_pretrained(DATA_PATH_SAVE_MODELS / MODEL_NAME)\n",
    "\n",
    "dataset = TokenizedDataset(data_df, tokenizer, MAX_LENGTH, text_column='text', link_text_column='link_text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids_text': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'attention_mask_text': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'input_ids_link': tensor([    0, 34141, 39941,   231,    12,   180,    12,   279,    19, 19258,\n",
       "         29048, 19961, 29382, 13410,  6247, 43814,    12,  1646,     2,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1]),\n",
       " 'attention_mask_link': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0])}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import RobertaForSequenceClassification, RobertaTokenizer\n",
    "\n",
    "model = RobertaForSequenceClassification.from_pretrained(\n",
    "    DATA_PATH_SAVE_MODELS / MODEL_NAME)\n",
    "\n",
    "model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тестирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "from typing import Dict\n",
    "\n",
    "\n",
    "def test_model_on_dataset(\n",
    "    model: torch.nn.Module,\n",
    "    dataset: TokenizedDataset,\n",
    "    idx2label: Dict[int, str],\n",
    "    entropy_thresholds: Dict[int, float],  # Пороги энтропии по категориям\n",
    "    batch_size: int = 16,\n",
    "    device: torch.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Прогоняет датасет через модель и добавляет предсказания, энтропию и её пороги в DataFrame.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): Обученная модель.\n",
    "        dataset (Dataset): Токенизированный датасет.\n",
    "        idx2label (dict): Словарь, отображающий индексы категорий в названия.\n",
    "        entropy_thresholds (dict): Оптимальные пороги энтропии по категориям.\n",
    "        batch_size (int): Размер батча для DataLoader.\n",
    "        device (torch.device): Устройство для вычислений (CPU/GPU).\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame с добавленными предсказаниями, включая:\n",
    "            - 'predict_1', 'probability_1', 'entropy_1', 'entropy_threshold_1', 'passed_threshold_1'\n",
    "            - 'predict_2', 'probability_2', 'entropy_2', 'entropy_threshold_2', 'passed_threshold_2'\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    # Создаём DataLoader\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    test_df = dataset.dataframe.copy()\n",
    "\n",
    "    # Списки для хранения предсказаний и метрик\n",
    "    predictions_1, probabilities_1, entropies_1, entropy_thresholds_1, passed_thresholds_1 = [], [], [], [], []\n",
    "    predictions_2, probabilities_2, entropies_2, entropy_thresholds_2, passed_thresholds_2 = [], [], [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Processing\"):\n",
    "            batch_size_current = batch[\"input_ids_text\"].shape[0]\n",
    "\n",
    "            # === Обрабатываем основную колонку (text) ===\n",
    "            input_ids_text = batch[\"input_ids_text\"].to(device)\n",
    "            attention_mask_text = batch[\"attention_mask_text\"].to(device)\n",
    "\n",
    "            text_has_content = [torch.any(input_ids_text[i] != 0).item() for i in range(batch_size_current)]\n",
    "            if any(text_has_content):  # Если хотя бы в одном есть текст\n",
    "                logits = model(input_ids=input_ids_text, attention_mask=attention_mask_text).logits\n",
    "                probs = torch.softmax(logits, dim=-1)\n",
    "                entropy = -torch.sum(probs * torch.log2(probs + 1e-15), dim=1)\n",
    "\n",
    "                preds = torch.argmax(probs, dim=-1).cpu().numpy()\n",
    "                probs = probs.cpu().numpy()\n",
    "                entropy = entropy.cpu().numpy()\n",
    "\n",
    "                for i in range(batch_size_current):\n",
    "                    if text_has_content[i]:\n",
    "                        entropy_threshold = entropy_thresholds.get(preds[i], None)\n",
    "                        passed_threshold = entropy[i] < entropy_threshold if entropy_threshold is not None else None\n",
    "\n",
    "                        predictions_1.append(preds[i])\n",
    "                        probabilities_1.append(probs[i].tolist())\n",
    "                        entropies_1.append(entropy[i])\n",
    "                        entropy_thresholds_1.append(entropy_threshold)\n",
    "                        passed_thresholds_1.append(passed_threshold)\n",
    "                    else:\n",
    "                        predictions_1.append(None)\n",
    "                        probabilities_1.append(None)\n",
    "                        entropies_1.append(None)\n",
    "                        entropy_thresholds_1.append(None)\n",
    "                        passed_thresholds_1.append(None)\n",
    "            else:\n",
    "                predictions_1.extend([None] * batch_size_current)\n",
    "                probabilities_1.extend([None] * batch_size_current)\n",
    "                entropies_1.extend([None] * batch_size_current)\n",
    "                entropy_thresholds_1.extend([None] * batch_size_current)\n",
    "                passed_thresholds_1.extend([None] * batch_size_current)\n",
    "\n",
    "            # === Обрабатываем дополнительную колонку (link_text) ===\n",
    "            input_ids_link = batch[\"input_ids_link\"].to(device)\n",
    "            attention_mask_link = batch[\"attention_mask_link\"].to(device)\n",
    "\n",
    "            link_text_has_content = [torch.any(input_ids_link[i] != 0).item() for i in range(batch_size_current)]\n",
    "            if any(link_text_has_content):  # Если хотя бы в одном есть текст\n",
    "                logits = model(input_ids=input_ids_link, attention_mask=attention_mask_link).logits\n",
    "                probs = torch.softmax(logits, dim=-1)\n",
    "                entropy = -torch.sum(probs * torch.log2(probs + 1e-15), dim=1)\n",
    "\n",
    "                preds = torch.argmax(probs, dim=-1).cpu().numpy()\n",
    "                probs = probs.cpu().numpy()\n",
    "                entropy = entropy.cpu().numpy()\n",
    "\n",
    "                for i in range(batch_size_current):\n",
    "                    if link_text_has_content[i]:\n",
    "                        entropy_threshold = entropy_thresholds.get(preds[i], None)\n",
    "                        passed_threshold = entropy[i] < entropy_threshold if entropy_threshold is not None else None\n",
    "\n",
    "                        predictions_2.append(preds[i])\n",
    "                        probabilities_2.append(probs[i].tolist())\n",
    "                        entropies_2.append(entropy[i])\n",
    "                        entropy_thresholds_2.append(entropy_threshold)\n",
    "                        passed_thresholds_2.append(passed_threshold)\n",
    "                    else:\n",
    "                        predictions_2.append(None)\n",
    "                        probabilities_2.append(None)\n",
    "                        entropies_2.append(None)\n",
    "                        entropy_thresholds_2.append(None)\n",
    "                        passed_thresholds_2.append(None)\n",
    "            else:\n",
    "                predictions_2.extend([None] * batch_size_current)\n",
    "                probabilities_2.extend([None] * batch_size_current)\n",
    "                entropies_2.extend([None] * batch_size_current)\n",
    "                entropy_thresholds_2.extend([None] * batch_size_current)\n",
    "                passed_thresholds_2.extend([None] * batch_size_current)\n",
    "\n",
    "    # Преобразуем предсказания в DataFrame\n",
    "    test_df = test_df.reset_index(drop=True)\n",
    "    test_df[\"predict_1\"] = [idx2label[p] if p is not None else None for p in predictions_1]\n",
    "    test_df[\"probability_1\"] = probabilities_1\n",
    "    test_df[\"entropy_1\"] = entropies_1\n",
    "    test_df[\"entropy_threshold_1\"] = entropy_thresholds_1\n",
    "    test_df[\"passed_threshold_1\"] = passed_thresholds_1\n",
    "\n",
    "    test_df[\"predict_2\"] = [idx2label[p] if p is not None else None for p in predictions_2]\n",
    "    test_df[\"probability_2\"] = probabilities_2\n",
    "    test_df[\"entropy_2\"] = entropies_2\n",
    "    test_df[\"entropy_threshold_2\"] = entropy_thresholds_2\n",
    "    test_df[\"passed_threshold_2\"] = passed_thresholds_2\n",
    "\n",
    "    return test_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Нужно уточнить значение entropy_thresholds полученное на предыдуще шаге"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "125abe8f99684681b81c41ddf5bcb12b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing:   0%|          | 0/108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "entropy_thresholds = {1: 0.5176525712013245, 0: 0.6887069940567017, 2: 0.3750338852405548}\n",
    "\n",
    "test_results_df = test_model_on_dataset(\n",
    "    model=model,\n",
    "    dataset=dataset,\n",
    "    idx2label=idx2label,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    entropy_thresholds=entropy_thresholds,\n",
    "    device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Group Name</th>\n",
       "      <th>User Name</th>\n",
       "      <th>Facebook Id</th>\n",
       "      <th>Page Category</th>\n",
       "      <th>Page Admin Top Country</th>\n",
       "      <th>Page Description</th>\n",
       "      <th>Page Created</th>\n",
       "      <th>Likes at Posting</th>\n",
       "      <th>Followers at Posting</th>\n",
       "      <th>Post Created</th>\n",
       "      <th>...</th>\n",
       "      <th>predict_1</th>\n",
       "      <th>probability_1</th>\n",
       "      <th>entropy_1</th>\n",
       "      <th>entropy_threshold_1</th>\n",
       "      <th>passed_threshold_1</th>\n",
       "      <th>predict_2</th>\n",
       "      <th>probability_2</th>\n",
       "      <th>entropy_2</th>\n",
       "      <th>entropy_threshold_2</th>\n",
       "      <th>passed_threshold_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6313</th>\n",
       "      <td>UK against Covid-19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>670592507037280</td>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-03-25 07:33:14 EDT</td>\n",
       "      <td>...</td>\n",
       "      <td>Comments</td>\n",
       "      <td>[7.50532271922566e-05, 0.0004611665790434927, 0.9994637370109558]</td>\n",
       "      <td>0.006913</td>\n",
       "      <td>0.375034</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3285</th>\n",
       "      <td>Health Care Assistants HCA / Nurses / Support Workers - JOBS (UK)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>629521900975276</td>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27263.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-08-12 04:43:44 EDT</td>\n",
       "      <td>...</td>\n",
       "      <td>Comments</td>\n",
       "      <td>[0.03655766695737839, 0.02743767946958542, 0.9360045790672302]</td>\n",
       "      <td>0.406160</td>\n",
       "      <td>0.375034</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1503</th>\n",
       "      <td>COVID19: Real Talk from Health Care Workers around the Globe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1073058046385811</td>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33248.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-03-27 17:54:04 EDT</td>\n",
       "      <td>...</td>\n",
       "      <td>Comments</td>\n",
       "      <td>[0.00014592600928153843, 0.00045572727685794234, 0.9993983507156372]</td>\n",
       "      <td>0.007786</td>\n",
       "      <td>0.375034</td>\n",
       "      <td>True</td>\n",
       "      <td>Real</td>\n",
       "      <td>[0.8154898285865784, 0.18059402704238892, 0.003916201181709766]</td>\n",
       "      <td>0.717201</td>\n",
       "      <td>0.688707</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4404</th>\n",
       "      <td>COVID19: Real Talk from Health Care Workers around the Globe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1073058046385811</td>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>107640.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-25 23:51:25 EST</td>\n",
       "      <td>...</td>\n",
       "      <td>Comments</td>\n",
       "      <td>[0.002318063285201788, 0.013403324410319328, 0.9842786192893982]</td>\n",
       "      <td>0.126177</td>\n",
       "      <td>0.375034</td>\n",
       "      <td>True</td>\n",
       "      <td>Comments</td>\n",
       "      <td>[0.0025343268644064665, 0.003414792474359274, 0.994050920009613]</td>\n",
       "      <td>0.058394</td>\n",
       "      <td>0.375034</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4641</th>\n",
       "      <td>COVID19: Real Talk from Health Care Workers around the Globe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1073058046385811</td>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33248.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-03-27 08:14:10 EDT</td>\n",
       "      <td>...</td>\n",
       "      <td>Comments</td>\n",
       "      <td>[0.00020574108930304646, 0.0007525987457484007, 0.9990416169166565]</td>\n",
       "      <td>0.011711</td>\n",
       "      <td>0.375034</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2083</th>\n",
       "      <td>COVID19: Real Talk from Health Care Workers around the Globe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1073058046385811</td>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-03-22 12:43:10 EDT</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>Fake</td>\n",
       "      <td>[0.3974652588367462, 0.5987207889556885, 0.0038139517419040203]</td>\n",
       "      <td>1.002789</td>\n",
       "      <td>0.517653</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1160</th>\n",
       "      <td>COVID19: Real Talk from Health Care Workers around the Globe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1073058046385811</td>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54140.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-03-30 07:39:24 EDT</td>\n",
       "      <td>...</td>\n",
       "      <td>Fake</td>\n",
       "      <td>[0.324563592672348, 0.6288674473762512, 0.046569038182497025]</td>\n",
       "      <td>1.153770</td>\n",
       "      <td>0.517653</td>\n",
       "      <td>False</td>\n",
       "      <td>Real</td>\n",
       "      <td>[0.5927907228469849, 0.4059179127216339, 0.00129135069437325]</td>\n",
       "      <td>0.987591</td>\n",
       "      <td>0.688707</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6807</th>\n",
       "      <td>COVID Stories From Healthcare Workers &amp; Patients</td>\n",
       "      <td>NaN</td>\n",
       "      <td>766104867346558</td>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-12-23 09:55:00 EST</td>\n",
       "      <td>...</td>\n",
       "      <td>Fake</td>\n",
       "      <td>[0.09781228750944138, 0.8766049742698669, 0.025582754984498024]</td>\n",
       "      <td>0.629902</td>\n",
       "      <td>0.517653</td>\n",
       "      <td>False</td>\n",
       "      <td>Real</td>\n",
       "      <td>[0.709227442741394, 0.28966858983039856, 0.0011040500830858946]</td>\n",
       "      <td>0.880185</td>\n",
       "      <td>0.688707</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4037</th>\n",
       "      <td>COVID19: Real Talk from Health Care Workers around the Globe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1073058046385811</td>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>110462.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-06-28 06:00:06 EDT</td>\n",
       "      <td>...</td>\n",
       "      <td>Comments</td>\n",
       "      <td>[0.1558556705713272, 0.339207261800766, 0.5049370527267456]</td>\n",
       "      <td>1.444823</td>\n",
       "      <td>0.375034</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2871</th>\n",
       "      <td>NHS, Key Workers And The World Appreciation Page</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1055974798109854</td>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-03-26 17:46:09 EDT</td>\n",
       "      <td>...</td>\n",
       "      <td>Comments</td>\n",
       "      <td>[0.0036607368383556604, 0.01307300291955471, 0.9832662343978882]</td>\n",
       "      <td>0.135369</td>\n",
       "      <td>0.375034</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             Group Name  \\\n",
       "6313                                                UK against Covid-19   \n",
       "3285  Health Care Assistants HCA / Nurses / Support Workers - JOBS (UK)   \n",
       "1503       COVID19: Real Talk from Health Care Workers around the Globe   \n",
       "4404       COVID19: Real Talk from Health Care Workers around the Globe   \n",
       "4641       COVID19: Real Talk from Health Care Workers around the Globe   \n",
       "2083       COVID19: Real Talk from Health Care Workers around the Globe   \n",
       "1160       COVID19: Real Talk from Health Care Workers around the Globe   \n",
       "6807                   COVID Stories From Healthcare Workers & Patients   \n",
       "4037       COVID19: Real Talk from Health Care Workers around the Globe   \n",
       "2871                   NHS, Key Workers And The World Appreciation Page   \n",
       "\n",
       "      User Name       Facebook Id Page Category  Page Admin Top Country  \\\n",
       "6313        NaN   670592507037280          none                     NaN   \n",
       "3285        NaN   629521900975276          none                     NaN   \n",
       "1503        NaN  1073058046385811          none                     NaN   \n",
       "4404        NaN  1073058046385811          none                     NaN   \n",
       "4641        NaN  1073058046385811          none                     NaN   \n",
       "2083        NaN  1073058046385811          none                     NaN   \n",
       "1160        NaN  1073058046385811          none                     NaN   \n",
       "6807        NaN   766104867346558          none                     NaN   \n",
       "4037        NaN  1073058046385811          none                     NaN   \n",
       "2871        NaN  1055974798109854          none                     NaN   \n",
       "\n",
       "      Page Description  Page Created  Likes at Posting  Followers at Posting  \\\n",
       "6313               NaN           NaN               NaN                   NaN   \n",
       "3285               NaN           NaN           27263.0                   NaN   \n",
       "1503               NaN           NaN           33248.0                   NaN   \n",
       "4404               NaN           NaN          107640.0                   NaN   \n",
       "4641               NaN           NaN           33248.0                   NaN   \n",
       "2083               NaN           NaN               NaN                   NaN   \n",
       "1160               NaN           NaN           54140.0                   NaN   \n",
       "6807               NaN           NaN               NaN                   NaN   \n",
       "4037               NaN           NaN          110462.0                   NaN   \n",
       "2871               NaN           NaN               NaN                   NaN   \n",
       "\n",
       "                 Post Created  ... predict_1  \\\n",
       "6313  2020-03-25 07:33:14 EDT  ...  Comments   \n",
       "3285  2022-08-12 04:43:44 EDT  ...  Comments   \n",
       "1503  2020-03-27 17:54:04 EDT  ...  Comments   \n",
       "4404  2021-01-25 23:51:25 EST  ...  Comments   \n",
       "4641  2020-03-27 08:14:10 EDT  ...  Comments   \n",
       "2083  2020-03-22 12:43:10 EDT  ...      None   \n",
       "1160  2020-03-30 07:39:24 EDT  ...      Fake   \n",
       "6807  2020-12-23 09:55:00 EST  ...      Fake   \n",
       "4037  2020-06-28 06:00:06 EDT  ...  Comments   \n",
       "2871  2020-03-26 17:46:09 EDT  ...  Comments   \n",
       "\n",
       "                                                             probability_1  \\\n",
       "6313     [7.50532271922566e-05, 0.0004611665790434927, 0.9994637370109558]   \n",
       "3285        [0.03655766695737839, 0.02743767946958542, 0.9360045790672302]   \n",
       "1503  [0.00014592600928153843, 0.00045572727685794234, 0.9993983507156372]   \n",
       "4404      [0.002318063285201788, 0.013403324410319328, 0.9842786192893982]   \n",
       "4641   [0.00020574108930304646, 0.0007525987457484007, 0.9990416169166565]   \n",
       "2083                                                                  None   \n",
       "1160         [0.324563592672348, 0.6288674473762512, 0.046569038182497025]   \n",
       "6807       [0.09781228750944138, 0.8766049742698669, 0.025582754984498024]   \n",
       "4037           [0.1558556705713272, 0.339207261800766, 0.5049370527267456]   \n",
       "2871      [0.0036607368383556604, 0.01307300291955471, 0.9832662343978882]   \n",
       "\n",
       "     entropy_1  entropy_threshold_1  passed_threshold_1  predict_2  \\\n",
       "6313  0.006913             0.375034                True       None   \n",
       "3285  0.406160             0.375034               False       None   \n",
       "1503  0.007786             0.375034                True       Real   \n",
       "4404  0.126177             0.375034                True   Comments   \n",
       "4641  0.011711             0.375034                True       None   \n",
       "2083       NaN                  NaN                None       Fake   \n",
       "1160  1.153770             0.517653               False       Real   \n",
       "6807  0.629902             0.517653               False       Real   \n",
       "4037  1.444823             0.375034               False       None   \n",
       "2871  0.135369             0.375034                True       None   \n",
       "\n",
       "                                                         probability_2  \\\n",
       "6313                                                              None   \n",
       "3285                                                              None   \n",
       "1503   [0.8154898285865784, 0.18059402704238892, 0.003916201181709766]   \n",
       "4404  [0.0025343268644064665, 0.003414792474359274, 0.994050920009613]   \n",
       "4641                                                              None   \n",
       "2083   [0.3974652588367462, 0.5987207889556885, 0.0038139517419040203]   \n",
       "1160     [0.5927907228469849, 0.4059179127216339, 0.00129135069437325]   \n",
       "6807   [0.709227442741394, 0.28966858983039856, 0.0011040500830858946]   \n",
       "4037                                                              None   \n",
       "2871                                                              None   \n",
       "\n",
       "      entropy_2  entropy_threshold_2  passed_threshold_2  \n",
       "6313        NaN                  NaN                None  \n",
       "3285        NaN                  NaN                None  \n",
       "1503   0.717201             0.688707               False  \n",
       "4404   0.058394             0.375034                True  \n",
       "4641        NaN                  NaN                None  \n",
       "2083   1.002789             0.517653               False  \n",
       "1160   0.987591             0.688707               False  \n",
       "6807   0.880185             0.688707               False  \n",
       "4037        NaN                  NaN                None  \n",
       "2871        NaN                  NaN                None  \n",
       "\n",
       "[10 rows x 52 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.options.display.max_colwidth = 300\n",
    "\n",
    "columns_to_keep = [\n",
    "    \"text\", \"predict_1\", \"probability_1\", \"entropy_1\", \"entropy_threshold_1\", \"passed_threshold_1\"\n",
    "]\n",
    "\n",
    "test_results_df.loc[\n",
    "    (test_results_df[\"predict_1\"] == \"Fake\") & (test_results_df[\"passed_threshold_1\"] == True), \n",
    "    columns_to_keep\n",
    "].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.options.display.max_colwidth = 300\n",
    "\n",
    "columns_to_keep = [\n",
    "    \"text\", \"predict_1\", \"probability_1\", \"entropy_1\", \"entropy_threshold_1\", \"passed_threshold_1\"\n",
    "]\n",
    "\n",
    "test_results_df.loc[\n",
    "    (test_results_df[\"predict_1\"] == \"Real\") & (test_results_df[\"passed_threshold_1\"] == True), \n",
    "    columns_to_keep\n",
    "].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predict_1\n",
       "Comments    3416\n",
       "Fake         945\n",
       "Real         531\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results_df['predict_1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results_df.to_excel(DATA_PATH / 'facebook_data_to_complate.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
