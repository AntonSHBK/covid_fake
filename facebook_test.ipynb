{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –û–±—É—á–µ–Ω–∏–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ñ–µ–π–∫–æ–≤—ã—Ö —Ñ–∞–∫—Ç–æ–≤ –æ COVID –∏ –≤–∞–∫—Ü–∏–Ω–∞—Ü–∏–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cpu'\n",
    "if torch.backends.mps.is_available():\n",
    "    DEVICE = 'mps'\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "DATA_PATH = Path('data/')\n",
    "DATA_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "DATA_CACHE = Path('data/cache_dir/')\n",
    "DATA_CACHE.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "DATA_PATH_SAVE_MODELS = Path('data/models/')\n",
    "DATA_PATH_SAVE_MODELS.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "pd.set_option('display.max_colwidth', 500) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"covid_vaccine_fake_model\"\n",
    "TEST_DF_NAME = \"facebook_data_to_model.xlsx\"\n",
    "\n",
    "MAX_LENGTH = 128\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –î–∞—Ç–∞—Å–µ—Ç"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Group Name</th>\n",
       "      <th>User Name</th>\n",
       "      <th>Facebook Id</th>\n",
       "      <th>Page Category</th>\n",
       "      <th>Page Admin Top Country</th>\n",
       "      <th>Page Description</th>\n",
       "      <th>Page Created</th>\n",
       "      <th>Likes at Posting</th>\n",
       "      <th>Followers at Posting</th>\n",
       "      <th>Post Created</th>\n",
       "      <th>...</th>\n",
       "      <th>Final Link</th>\n",
       "      <th>Image Text</th>\n",
       "      <th>Link Text</th>\n",
       "      <th>Description</th>\n",
       "      <th>Sponsor Id</th>\n",
       "      <th>Sponsor Name</th>\n",
       "      <th>Sponsor Category</th>\n",
       "      <th>Overperforming Score (weighted  ‚Äî  Likes 1x Shares 1x Comments 1x Love 1x Wow 1x Haha 1x Sad 1x Angry 1x Care 1x )</th>\n",
       "      <th>text</th>\n",
       "      <th>link_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COVID19: Real Talk from Health Care Workers around the Globe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1073058046385811</td>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66994.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-04-01 22:42:32 EDT</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>189.33</td>\n",
       "      <td>We extubated 2 covid patients today and they are doing awesome! Should be on a tele floor tomorrow! (TX)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows √ó 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Group Name  User Name  \\\n",
       "0  COVID19: Real Talk from Health Care Workers around the Globe        NaN   \n",
       "\n",
       "        Facebook Id Page Category  Page Admin Top Country  Page Description  \\\n",
       "0  1073058046385811          none                     NaN               NaN   \n",
       "\n",
       "   Page Created  Likes at Posting  Followers at Posting  \\\n",
       "0           NaN           66994.0                   NaN   \n",
       "\n",
       "              Post Created  ... Final Link Image Text Link Text  Description  \\\n",
       "0  2020-04-01 22:42:32 EDT  ...        NaN        NaN       NaN          NaN   \n",
       "\n",
       "   Sponsor Id  Sponsor Name  Sponsor Category  \\\n",
       "0         NaN           NaN               NaN   \n",
       "\n",
       "   Overperforming Score (weighted  ‚Äî  Likes 1x Shares 1x Comments 1x Love 1x Wow 1x Haha 1x Sad 1x Angry 1x Care 1x )  \\\n",
       "0                                                                                                              189.33   \n",
       "\n",
       "                                                                                                       text  \\\n",
       "0  We extubated 2 covid patients today and they are doing awesome! Should be on a tele floor tomorrow! (TX)   \n",
       "\n",
       "   link_text  \n",
       "0        NaN  \n",
       "\n",
       "[1 rows x 42 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_excel(DATA_PATH / TEST_DF_NAME)\n",
    "data_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2label = {\n",
    "    0: \"Real\",\n",
    "    1: \"Fake\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Tuple\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import PreTrainedTokenizer\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class TokenizedDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataframe: pd.DataFrame,\n",
    "        tokenizer: PreTrainedTokenizer,\n",
    "        max_length: int,\n",
    "        text_column: str = \"text\",\n",
    "        link_text_column: str = \"link_text\",\n",
    "        tensor_dtype: Tuple[torch.dtype, torch.dtype] = (torch.long, torch.long),\n",
    "    ):\n",
    "        \"\"\"\n",
    "        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –¥–∞—Ç–∞—Å–µ—Ç–∞ —Å –ª–µ–Ω–∏–≤–æ–π —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–µ–π.\n",
    "\n",
    "        Args:\n",
    "            dataframe (pd.DataFrame): DataFrame —Å –∫–æ–ª–æ–Ω–∫–∞–º–∏ –¥–ª—è —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–∏.\n",
    "            tokenizer (PreTrainedTokenizer): –¢–æ–∫–µ–Ω–∞–π–∑–µ—Ä –¥–ª—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è —Ç–µ–∫—Å—Ç–∞.\n",
    "            max_length (int): –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ —Ç–æ–∫–µ–Ω–æ–≤.\n",
    "            text_column (str): –ù–∞–∑–≤–∞–Ω–∏–µ –æ—Å–Ω–æ–≤–Ω–æ–π —Ç–µ–∫—Å—Ç–æ–≤–æ–π –∫–æ–ª–æ–Ω–∫–∏.\n",
    "            link_text_column (str): –ù–∞–∑–≤–∞–Ω–∏–µ –∫–æ–ª–æ–Ω–∫–∏ —Å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–º —Ç–µ–∫—Å—Ç–æ–º.\n",
    "            tensor_dtype (tuple): –¢–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ç–æ–∫–µ–Ω–æ–≤ (input_ids, attention_mask).\n",
    "        \"\"\"\n",
    "        self.dataframe = dataframe.copy()  # –ö–æ–ø–∏—Ä—É–µ–º DataFrame, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –∏–∑–º–µ–Ω–µ–Ω–∏–π –≤ –æ—Ä–∏–≥–∏–Ω–∞–ª–µ\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.text_column = text_column\n",
    "        self.link_text_column = link_text_column\n",
    "        self.tensor_dtype = tensor_dtype\n",
    "\n",
    "        # –ü—Ä–æ–≤–µ—Ä–∫–∞, –µ—Å—Ç—å –ª–∏ —É–∫–∞–∑–∞–Ω–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –≤ DataFrame\n",
    "        if text_column not in dataframe.columns:\n",
    "            raise ValueError(f\"–ö–æ–ª–æ–Ω–∫–∞ '{text_column}' –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ DataFrame\")\n",
    "        if link_text_column not in dataframe.columns:\n",
    "            raise ValueError(f\"–ö–æ–ª–æ–Ω–∫–∞ '{link_text_column}' –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ DataFrame\")\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"\n",
    "        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–º–µ—Ä–æ–≤ –≤ –¥–∞—Ç–∞—Å–µ—Ç–µ.\n",
    "        \"\"\"\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def _tokenize_text(self, text: str) -> Dict[str, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        –¢–æ–∫–µ–Ω–∏–∑–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç, –µ—Å–ª–∏ –æ–Ω –Ω–µ –ø—É—Å—Ç–æ–π, –∏–Ω–∞—á–µ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–µ–Ω–∑–æ—Ä—ã —Å –Ω—É–ª—è–º–∏.\n",
    "\n",
    "        Args:\n",
    "            text (str): –¢–µ–∫—Å—Ç –¥–ª—è —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–∏.\n",
    "\n",
    "        Returns:\n",
    "            Dict[str, torch.Tensor]: –¢–µ–Ω–∑–æ—Ä—ã input_ids –∏ attention_mask.\n",
    "        \"\"\"\n",
    "        if pd.isna(text) or text.strip() == \"\":\n",
    "            return {\n",
    "                \"input_ids\": torch.zeros(self.max_length, dtype=self.tensor_dtype[0]),\n",
    "                \"attention_mask\": torch.zeros(self.max_length, dtype=self.tensor_dtype[1]),\n",
    "            }\n",
    "        else:\n",
    "            tokens = self.tokenizer(\n",
    "                text,\n",
    "                max_length=self.max_length,\n",
    "                padding=\"max_length\",\n",
    "                truncation=True,\n",
    "                return_tensors=\"pt\",\n",
    "            )\n",
    "            return {\n",
    "                \"input_ids\": tokens[\"input_ids\"][0].to(dtype=self.tensor_dtype[0]),\n",
    "                \"attention_mask\": tokens[\"attention_mask\"][0].to(dtype=self.tensor_dtype[1]),\n",
    "            }\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Dict[str, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–æ–∫–µ–Ω–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ.\n",
    "\n",
    "        Args:\n",
    "            idx (int): –ò–Ω–¥–µ–∫—Å –ø—Ä–∏–º–µ—Ä–∞.\n",
    "\n",
    "        Returns:\n",
    "            Dict[str, torch.Tensor]: –°–ª–æ–≤–∞—Ä—å —Å —Ç–æ–∫–µ–Ω–∞–º–∏ –∏–∑ –¥–≤—É—Ö –∫–æ–ª–æ–Ω–æ–∫.\n",
    "        \"\"\"\n",
    "        row = self.dataframe.iloc[idx]\n",
    "\n",
    "        text_tokens = self._tokenize_text(row[self.text_column])\n",
    "\n",
    "        link_text_tokens = self._tokenize_text(row[self.link_text_column])\n",
    "\n",
    "        return {\n",
    "            \"input_ids_text\": text_tokens[\"input_ids\"],\n",
    "            \"attention_mask_text\": text_tokens[\"attention_mask\"],\n",
    "            \"input_ids_link\": link_text_tokens[\"input_ids\"],\n",
    "            \"attention_mask_link\": link_text_tokens[\"attention_mask\"],\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer\n",
    "\n",
    "tokenizer: RobertaTokenizer = RobertaTokenizer.from_pretrained(DATA_PATH_SAVE_MODELS / MODEL_NAME)\n",
    "\n",
    "dataset = TokenizedDataset(data_df, tokenizer, MAX_LENGTH, text_column='text', link_text_column='link_text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids_text': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'attention_mask_text': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'input_ids_link': tensor([    0, 34141, 39941,   231,    12,   180,    12,   279,    19, 19258,\n",
       "         29048, 19961, 29382, 13410,  6247, 43814,    12,  1646,     2,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1]),\n",
       " 'attention_mask_link': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0])}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –ú–æ–¥–µ–ª—å"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import RobertaForSequenceClassification, RobertaTokenizer\n",
    "\n",
    "model = RobertaForSequenceClassification.from_pretrained(\n",
    "    DATA_PATH_SAVE_MODELS / MODEL_NAME)\n",
    "\n",
    "model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def test_model_on_dataset(\n",
    "    model: torch.nn.Module,\n",
    "    dataset: TokenizedDataset,\n",
    "    idx2label: dict,\n",
    "    batch_size: int = 16,\n",
    "    device: torch.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    –ü—Ä–æ–≥–æ–Ω—è–µ—Ç –¥–∞—Ç–∞—Å–µ—Ç —á–µ—Ä–µ–∑ –º–æ–¥–µ–ª—å –∏ –¥–æ–±–∞–≤–ª—è–µ—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –≤ DataFrame.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): –û–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å.\n",
    "        dataset (Dataset): –¢–æ–∫–µ–Ω–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç.\n",
    "        idx2label (dict): –°–ª–æ–≤–∞—Ä—å, –æ—Ç–æ–±—Ä–∞–∂–∞—é—â–∏–π –∏–Ω–¥–µ–∫—Å—ã –∫–∞—Ç–µ–≥–æ—Ä–∏–π –≤ –Ω–∞–∑–≤–∞–Ω–∏—è.\n",
    "        batch_size (int): –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –¥–ª—è DataLoader.\n",
    "        device (torch.device): –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏–π (CPU/GPU).\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame —Å –¥–æ–±–∞–≤–ª–µ–Ω–Ω—ã–º–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è–º–∏:\n",
    "            - 'predict_1': –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–∞—è –º–µ—Ç–∫–∞ –¥–ª—è –æ—Å–Ω–æ–≤–Ω–æ–π –∫–æ–ª–æ–Ω–∫–∏,\n",
    "            - 'probability_1': –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–ª—è –æ—Å–Ω–æ–≤–Ω–æ–π –∫–æ–ª–æ–Ω–∫–∏,\n",
    "            - 'predict_2': –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–∞—è –º–µ—Ç–∫–∞ –¥–ª—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –∫–æ–ª–æ–Ω–∫–∏,\n",
    "            - 'probability_2': –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–ª—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –∫–æ–ª–æ–Ω–∫–∏.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    # –°–æ–∑–¥–∞—ë–º DataLoader\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    test_df = dataset.dataframe.copy()\n",
    "\n",
    "    # –°–ø–∏—Å–∫–∏ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π\n",
    "    predictions_1, probabilities_1 = [], []\n",
    "    predictions_2, probabilities_2 = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Processing\"):\n",
    "            batch_size_current = batch[\"input_ids_text\"].shape[0]\n",
    "\n",
    "            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –æ—Å–Ω–æ–≤–Ω—É—é –∫–æ–ª–æ–Ω–∫—É (text)\n",
    "            input_ids_text = batch[\"input_ids_text\"].to(device)\n",
    "            attention_mask_text = batch[\"attention_mask_text\"].to(device)\n",
    "\n",
    "            text_has_content = [torch.any(input_ids_text[i] != 0).item() for i in range(batch_size_current)]\n",
    "            if any(text_has_content):  # –ï—Å–ª–∏ —Ö–æ—Ç—è –±—ã –≤ –æ–¥–Ω–æ–º –µ—Å—Ç—å —Ç–µ–∫—Å—Ç\n",
    "                logits = model(input_ids=input_ids_text, attention_mask=attention_mask_text).logits\n",
    "                probs = torch.softmax(logits, dim=-1).cpu().numpy()\n",
    "                preds = torch.argmax(logits, dim=-1).cpu().numpy()\n",
    "\n",
    "                for i in range(batch_size_current):\n",
    "                    if text_has_content[i]:\n",
    "                        predictions_1.append(preds[i])\n",
    "                        probabilities_1.append(probs[i].tolist())\n",
    "                    else:\n",
    "                        predictions_1.append(None)\n",
    "                        probabilities_1.append(None)\n",
    "            else:\n",
    "                predictions_1.extend([None] * batch_size_current)\n",
    "                probabilities_1.extend([None] * batch_size_current)\n",
    "\n",
    "            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—É—é –∫–æ–ª–æ–Ω–∫—É (link_text)\n",
    "            input_ids_link = batch[\"input_ids_link\"].to(device)\n",
    "            attention_mask_link = batch[\"attention_mask_link\"].to(device)\n",
    "\n",
    "            link_text_has_content = [torch.any(input_ids_link[i] != 0).item() for i in range(batch_size_current)]\n",
    "            if any(link_text_has_content):  # –ï—Å–ª–∏ —Ö–æ—Ç—è –±—ã –≤ –æ–¥–Ω–æ–º –µ—Å—Ç—å —Ç–µ–∫—Å—Ç\n",
    "                logits = model(input_ids=input_ids_link, attention_mask=attention_mask_link).logits\n",
    "                probs = torch.softmax(logits, dim=-1).cpu().numpy()\n",
    "                preds = torch.argmax(logits, dim=-1).cpu().numpy()\n",
    "\n",
    "                for i in range(batch_size_current):\n",
    "                    if link_text_has_content[i]:\n",
    "                        predictions_2.append(preds[i])\n",
    "                        probabilities_2.append(probs[i].tolist())\n",
    "                    else:\n",
    "                        predictions_2.append(None)\n",
    "                        probabilities_2.append(None)\n",
    "            else:\n",
    "                predictions_2.extend([None] * batch_size_current)\n",
    "                probabilities_2.extend([None] * batch_size_current)\n",
    "\n",
    "    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –≤ DataFrame\n",
    "    test_df = test_df.reset_index(drop=True)\n",
    "    test_df[\"predict_1\"] = [idx2label[p] if p is not None else None for p in predictions_1]\n",
    "    test_df[\"probability_1\"] = probabilities_1\n",
    "    test_df[\"predict_2\"] = [idx2label[p] if p is not None else None for p in predictions_2]\n",
    "    test_df[\"probability_2\"] = probabilities_2\n",
    "\n",
    "    return test_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d12e70cd39a489c95dff621d008c979",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing:   0%|          | 0/108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_results_df = test_model_on_dataset(\n",
    "    model=model,\n",
    "    dataset=dataset,\n",
    "    idx2label=idx2label,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Group Name</th>\n",
       "      <th>User Name</th>\n",
       "      <th>Facebook Id</th>\n",
       "      <th>Page Category</th>\n",
       "      <th>Page Admin Top Country</th>\n",
       "      <th>Page Description</th>\n",
       "      <th>Page Created</th>\n",
       "      <th>Likes at Posting</th>\n",
       "      <th>Followers at Posting</th>\n",
       "      <th>Post Created</th>\n",
       "      <th>...</th>\n",
       "      <th>Sponsor Id</th>\n",
       "      <th>Sponsor Name</th>\n",
       "      <th>Sponsor Category</th>\n",
       "      <th>Overperforming Score (weighted  ‚Äî  Likes 1x Shares 1x Comments 1x Love 1x Wow 1x Haha 1x Sad 1x Angry 1x Care 1x )</th>\n",
       "      <th>text</th>\n",
       "      <th>link_text</th>\n",
       "      <th>predict_1</th>\n",
       "      <th>probability_1</th>\n",
       "      <th>predict_2</th>\n",
       "      <th>probability_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5399</th>\n",
       "      <td>COVID19: Real Talk from Health Care Workers around the Globe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1073058046385811</td>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>107559.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-02-06 08:41:34 EST</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.14</td>\n",
       "      <td>Hey was wondering if anyone that received both doses of the vaccine got tested for antibodies yet?? And how long after?? I keep hearing mixed time frames!!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fake</td>\n",
       "      <td>[0.0518883541226387, 0.9481115937232971]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4550</th>\n",
       "      <td>COVID19: Real Talk from Health Care Workers around the Globe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1073058046385811</td>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18212.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-03-25 18:01:24 EDT</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.39</td>\n",
       "      <td>#3 Westchester NY LMT, INHC Oh thank god ! General Motors, Ford, 3M and the negotiation ability‚Äôs of States at the forefront</td>\n",
       "      <td>KARE 11 WATCH LIVE: The White House coronavirus task force provides an update in its daily briefing.</td>\n",
       "      <td>Real</td>\n",
       "      <td>[0.9917660355567932, 0.008234018459916115]</td>\n",
       "      <td>Real</td>\n",
       "      <td>[0.8347105383872986, 0.16528943181037903]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5692</th>\n",
       "      <td>Health Care Assistants HCA / Nurses / Support Workers - JOBS (UK)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>629521900975276</td>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15657.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-05-16 10:50:34 EDT</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.05</td>\n",
       "      <td>Interview taking place every week for NHS Trust in ESSEX if you have passed ILETS or OET please contact me at fabiola@global-medical-pro.com You must have minimum of 12 months experience with some experience in mental health and are looking to pursue a career in mental health in the UK this is a job opportunity for youüòä</td>\n",
       "      <td>Global Medical Professionals Our mental health is something most of us avoid seeking help for‚Ä¶\\n\\nI often question this because, if we broke a bone we would seek help, if we were in pain elsewhere we would seek medical help. \\n\\nOur mental health is also so important and when things are not right, when we are struggling mentally, we should ask for help. \\n\\nMental health services are in demand here in the U.K. and that means the demand for more experienced mental health nurses.\\n\\nLike all n...</td>\n",
       "      <td>Real</td>\n",
       "      <td>[0.990220308303833, 0.00977969728410244]</td>\n",
       "      <td>Real</td>\n",
       "      <td>[0.6824526190757751, 0.31754738092422485]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1969</th>\n",
       "      <td>COVID19: Real Talk from Health Care Workers around the Globe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1073058046385811</td>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>108534.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-10-31 10:25:09 EDT</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.41</td>\n",
       "      <td>Could someone explain exactly how the vaccine causes myocarditis?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fake</td>\n",
       "      <td>[0.0009460931178182364, 0.9990538954734802]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1905</th>\n",
       "      <td>Health Care Assistants HCA / Nurses / Support Workers - JOBS (UK)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1570841303216433</td>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33338.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-04-23 00:45:37 EDT</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2882</th>\n",
       "      <td>Health Care Assistants HCA / Nurses / Support Workers - JOBS (UK)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>629521900975276</td>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36597.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-11-08 12:06:44 EST</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Salvation Army‚Äôs Older People‚Äôs Services Do you want to work in a Care Home with a difference? Everything we do for our Older People‚Äôs Service is ‚ÄúRooted in Love‚Äù our values of Integrity, compassion, passion, respect; boldness and accountability are at the heart of all we do.\\n\\nTeam Leader\\n\\nLocation: Youell Court Care - Care Home, Skipworth Road, Binley, Coventry, CV3 2XA\\n\\nWorking hours: 35 hours per week\\n\\nContract: Permanent\\n\\nhttps://uk.indeed.com/rc/clk?jk=8eb27fc45bdf6e9b&amp;fcc...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Fake</td>\n",
       "      <td>[0.2869172990322113, 0.7130827307701111]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5124</th>\n",
       "      <td>Health Care Assistants HCA / Nurses / Support Workers - JOBS (UK)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1570841303216433</td>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45334.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-03-16 06:09:22 EDT</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.21</td>\n",
       "      <td>WhatsApp me on +971556878369 Or email your docs to sherin.rose@neptuneinternational.org</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fake</td>\n",
       "      <td>[0.04681093245744705, 0.9531890749931335]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3547</th>\n",
       "      <td>Health Care Assistants HCA / Nurses / Support Workers - JOBS (UK)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1570841303216433</td>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32178.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-11-19 16:06:12 EST</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.85</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5730</th>\n",
       "      <td>COVID19: Real Talk from Health Care Workers around the Globe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1073058046385811</td>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>108383.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-11-14 23:46:13 EST</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.05</td>\n",
       "      <td>Just had 2 friends test positive for Covid. We called them (they are husband and wife). Explained that while they had at home tests that were positive they should check with their docs and if symptoms get worse to head to the hospital. Needless to say our suggestions were not taken well. Trying to help....they don't want it. Ugh!!!! They are our best friends. No response needed ...just want to vent. Also....our nephew (who was positive weeks ago) is doing great. Home ...no O2. Thanks to all ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fake</td>\n",
       "      <td>[0.2784062325954437, 0.7215937972068787]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>COVID19: Real Talk from Health Care Workers around the Globe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1073058046385811</td>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>110462.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-06-28 05:46:50 EDT</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.52</td>\n",
       "      <td>Just taking a short break from COVID related posts. As a CNA with many high-fall risk patients, this is too relatable</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Real</td>\n",
       "      <td>[0.8647623062133789, 0.1352376490831375]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows √ó 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             Group Name  \\\n",
       "5399       COVID19: Real Talk from Health Care Workers around the Globe   \n",
       "4550       COVID19: Real Talk from Health Care Workers around the Globe   \n",
       "5692  Health Care Assistants HCA / Nurses / Support Workers - JOBS (UK)   \n",
       "1969       COVID19: Real Talk from Health Care Workers around the Globe   \n",
       "1905  Health Care Assistants HCA / Nurses / Support Workers - JOBS (UK)   \n",
       "2882  Health Care Assistants HCA / Nurses / Support Workers - JOBS (UK)   \n",
       "5124  Health Care Assistants HCA / Nurses / Support Workers - JOBS (UK)   \n",
       "3547  Health Care Assistants HCA / Nurses / Support Workers - JOBS (UK)   \n",
       "5730       COVID19: Real Talk from Health Care Workers around the Globe   \n",
       "537        COVID19: Real Talk from Health Care Workers around the Globe   \n",
       "\n",
       "      User Name       Facebook Id Page Category  Page Admin Top Country  \\\n",
       "5399        NaN  1073058046385811          none                     NaN   \n",
       "4550        NaN  1073058046385811          none                     NaN   \n",
       "5692        NaN   629521900975276          none                     NaN   \n",
       "1969        NaN  1073058046385811          none                     NaN   \n",
       "1905        NaN  1570841303216433          none                     NaN   \n",
       "2882        NaN   629521900975276          none                     NaN   \n",
       "5124        NaN  1570841303216433          none                     NaN   \n",
       "3547        NaN  1570841303216433          none                     NaN   \n",
       "5730        NaN  1073058046385811          none                     NaN   \n",
       "537         NaN  1073058046385811          none                     NaN   \n",
       "\n",
       "      Page Description  Page Created  Likes at Posting  Followers at Posting  \\\n",
       "5399               NaN           NaN          107559.0                   NaN   \n",
       "4550               NaN           NaN           18212.0                   NaN   \n",
       "5692               NaN           NaN           15657.0                   NaN   \n",
       "1969               NaN           NaN          108534.0                   NaN   \n",
       "1905               NaN           NaN           33338.0                   NaN   \n",
       "2882               NaN           NaN           36597.0                   NaN   \n",
       "5124               NaN           NaN           45334.0                   NaN   \n",
       "3547               NaN           NaN           32178.0                   NaN   \n",
       "5730               NaN           NaN          108383.0                   NaN   \n",
       "537                NaN           NaN          110462.0                   NaN   \n",
       "\n",
       "                 Post Created  ... Sponsor Id Sponsor Name Sponsor Category  \\\n",
       "5399  2021-02-06 08:41:34 EST  ...        NaN          NaN              NaN   \n",
       "4550  2020-03-25 18:01:24 EDT  ...        NaN          NaN              NaN   \n",
       "5692  2022-05-16 10:50:34 EDT  ...        NaN          NaN              NaN   \n",
       "1969  2021-10-31 10:25:09 EDT  ...        NaN          NaN              NaN   \n",
       "1905  2021-04-23 00:45:37 EDT  ...        NaN          NaN              NaN   \n",
       "2882  2022-11-08 12:06:44 EST  ...        NaN          NaN              NaN   \n",
       "5124  2022-03-16 06:09:22 EDT  ...        NaN          NaN              NaN   \n",
       "3547  2020-11-19 16:06:12 EST  ...        NaN          NaN              NaN   \n",
       "5730  2021-11-14 23:46:13 EST  ...        NaN          NaN              NaN   \n",
       "537   2020-06-28 05:46:50 EDT  ...        NaN          NaN              NaN   \n",
       "\n",
       "      Overperforming Score (weighted  ‚Äî  Likes 1x Shares 1x Comments 1x Love 1x Wow 1x Haha 1x Sad 1x Angry 1x Care 1x )  \\\n",
       "5399                                                                                                                1.14   \n",
       "4550                                                                                                                1.39   \n",
       "5692                                                                                                                1.05   \n",
       "1969                                                                                                                3.41   \n",
       "1905                                                                                                                3.55   \n",
       "2882                                                                                                                2.30   \n",
       "5124                                                                                                                1.21   \n",
       "3547                                                                                                                1.85   \n",
       "5730                                                                                                                1.05   \n",
       "537                                                                                                                11.52   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     text  \\\n",
       "5399                                                                                                                                                                                                                                                                                                                                                          Hey was wondering if anyone that received both doses of the vaccine got tested for antibodies yet?? And how long after?? I keep hearing mixed time frames!!   \n",
       "4550                                                                                                                                                                                                                                                                                                                                                                                         #3 Westchester NY LMT, INHC Oh thank god ! General Motors, Ford, 3M and the negotiation ability‚Äôs of States at the forefront   \n",
       "5692                                                                                                                                                                                    Interview taking place every week for NHS Trust in ESSEX if you have passed ILETS or OET please contact me at fabiola@global-medical-pro.com You must have minimum of 12 months experience with some experience in mental health and are looking to pursue a career in mental health in the UK this is a job opportunity for youüòä   \n",
       "1969                                                                                                                                                                                                                                                                                                                                                                                                                                                    Could someone explain exactly how the vaccine causes myocarditis?   \n",
       "1905                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  NaN   \n",
       "2882                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  NaN   \n",
       "5124                                                                                                                                                                                                                                                                                                                                                                                                                              WhatsApp me on +971556878369 Or email your docs to sherin.rose@neptuneinternational.org   \n",
       "3547                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  NaN   \n",
       "5730  Just had 2 friends test positive for Covid. We called them (they are husband and wife). Explained that while they had at home tests that were positive they should check with their docs and if symptoms get worse to head to the hospital. Needless to say our suggestions were not taken well. Trying to help....they don't want it. Ugh!!!! They are our best friends. No response needed ...just want to vent. Also....our nephew (who was positive weeks ago) is doing great. Home ...no O2. Thanks to all ...   \n",
       "537                                                                                                                                                                                                                                                                                                                                                                                                 Just taking a short break from COVID related posts. As a CNA with many high-fall risk patients, this is too relatable   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                link_text  \\\n",
       "5399                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  NaN   \n",
       "4550                                                                                                                                                                                                                                                                                                                                                                                                                 KARE 11 WATCH LIVE: The White House coronavirus task force provides an update in its daily briefing.   \n",
       "5692  Global Medical Professionals Our mental health is something most of us avoid seeking help for‚Ä¶\\n\\nI often question this because, if we broke a bone we would seek help, if we were in pain elsewhere we would seek medical help. \\n\\nOur mental health is also so important and when things are not right, when we are struggling mentally, we should ask for help. \\n\\nMental health services are in demand here in the U.K. and that means the demand for more experienced mental health nurses.\\n\\nLike all n...   \n",
       "1969                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  NaN   \n",
       "1905                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  NaN   \n",
       "2882  The Salvation Army‚Äôs Older People‚Äôs Services Do you want to work in a Care Home with a difference? Everything we do for our Older People‚Äôs Service is ‚ÄúRooted in Love‚Äù our values of Integrity, compassion, passion, respect; boldness and accountability are at the heart of all we do.\\n\\nTeam Leader\\n\\nLocation: Youell Court Care - Care Home, Skipworth Road, Binley, Coventry, CV3 2XA\\n\\nWorking hours: 35 hours per week\\n\\nContract: Permanent\\n\\nhttps://uk.indeed.com/rc/clk?jk=8eb27fc45bdf6e9b&fcc...   \n",
       "5124                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  NaN   \n",
       "3547                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  NaN   \n",
       "5730                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  NaN   \n",
       "537                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   NaN   \n",
       "\n",
       "      predict_1                                probability_1  predict_2  \\\n",
       "5399       Fake     [0.0518883541226387, 0.9481115937232971]       None   \n",
       "4550       Real   [0.9917660355567932, 0.008234018459916115]       Real   \n",
       "5692       Real     [0.990220308303833, 0.00977969728410244]       Real   \n",
       "1969       Fake  [0.0009460931178182364, 0.9990538954734802]       None   \n",
       "1905       None                                         None       None   \n",
       "2882       None                                         None       Fake   \n",
       "5124       Fake    [0.04681093245744705, 0.9531890749931335]       None   \n",
       "3547       None                                         None       None   \n",
       "5730       Fake     [0.2784062325954437, 0.7215937972068787]       None   \n",
       "537        Real     [0.8647623062133789, 0.1352376490831375]       None   \n",
       "\n",
       "                                  probability_2  \n",
       "5399                                       None  \n",
       "4550  [0.8347105383872986, 0.16528943181037903]  \n",
       "5692  [0.6824526190757751, 0.31754738092422485]  \n",
       "1969                                       None  \n",
       "1905                                       None  \n",
       "2882   [0.2869172990322113, 0.7130827307701111]  \n",
       "5124                                       None  \n",
       "3547                                       None  \n",
       "5730                                       None  \n",
       "537                                        None  \n",
       "\n",
       "[10 rows x 46 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results_df.to_excel(DATA_PATH / 'facebook_data_to_complate.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
