{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –û–±—É—á–µ–Ω–∏–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ñ–µ–π–∫–æ–≤—ã—Ö —Ñ–∞–∫—Ç–æ–≤ –æ COVID –∏ –≤–∞–∫—Ü–∏–Ω–∞—Ü–∏–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cpu'\n",
    "if torch.backends.mps.is_available():\n",
    "    DEVICE = 'mps'\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "DATA_PATH = Path('data/')\n",
    "DATA_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "DATA_CACHE = Path('data/cache_dir/')\n",
    "DATA_CACHE.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "DATA_PATH_SAVE_MODELS = Path('data/models/')\n",
    "DATA_PATH_SAVE_MODELS.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "pd.set_option('display.max_colwidth', 500) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"covid_vaccine_fake_model\"\n",
    "TEST_DF_NAME = \"facebook_data_to_model.xlsx\"\n",
    "\n",
    "MAX_LENGTH = 128\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –î–∞—Ç–∞—Å–µ—Ç"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Group Name</th>\n",
       "      <th>User Name</th>\n",
       "      <th>Facebook Id</th>\n",
       "      <th>Page Category</th>\n",
       "      <th>Page Admin Top Country</th>\n",
       "      <th>Page Description</th>\n",
       "      <th>Page Created</th>\n",
       "      <th>Likes at Posting</th>\n",
       "      <th>Followers at Posting</th>\n",
       "      <th>Post Created</th>\n",
       "      <th>...</th>\n",
       "      <th>Final Link</th>\n",
       "      <th>Image Text</th>\n",
       "      <th>Link Text</th>\n",
       "      <th>Description</th>\n",
       "      <th>Sponsor Id</th>\n",
       "      <th>Sponsor Name</th>\n",
       "      <th>Sponsor Category</th>\n",
       "      <th>Overperforming Score (weighted  ‚Äî  Likes 1x Shares 1x Comments 1x Love 1x Wow 1x Haha 1x Sad 1x Angry 1x Care 1x )</th>\n",
       "      <th>text</th>\n",
       "      <th>link_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COVID19: Real Talk from Health Care Workers around the Globe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1073058046385811</td>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66994.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-04-01 22:42:32 EDT</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>189.33</td>\n",
       "      <td>We extubated 2 covid patients today and they are doing awesome! Should be on a tele floor tomorrow! (TX)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows √ó 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Group Name  User Name  \\\n",
       "0  COVID19: Real Talk from Health Care Workers around the Globe        NaN   \n",
       "\n",
       "        Facebook Id Page Category  Page Admin Top Country  Page Description  \\\n",
       "0  1073058046385811          none                     NaN               NaN   \n",
       "\n",
       "   Page Created  Likes at Posting  Followers at Posting  \\\n",
       "0           NaN           66994.0                   NaN   \n",
       "\n",
       "              Post Created  ... Final Link Image Text Link Text  Description  \\\n",
       "0  2020-04-01 22:42:32 EDT  ...        NaN        NaN       NaN          NaN   \n",
       "\n",
       "   Sponsor Id  Sponsor Name  Sponsor Category  \\\n",
       "0         NaN           NaN               NaN   \n",
       "\n",
       "   Overperforming Score (weighted  ‚Äî  Likes 1x Shares 1x Comments 1x Love 1x Wow 1x Haha 1x Sad 1x Angry 1x Care 1x )  \\\n",
       "0                                                                                                              189.33   \n",
       "\n",
       "                                                                                                       text  \\\n",
       "0  We extubated 2 covid patients today and they are doing awesome! Should be on a tele floor tomorrow! (TX)   \n",
       "\n",
       "   link_text  \n",
       "0        NaN  \n",
       "\n",
       "[1 rows x 42 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_excel(DATA_PATH / TEST_DF_NAME)\n",
    "data_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_df = data_df.sample(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2label = {\n",
    "    0: \"Real\",\n",
    "    1: \"Fake\",\n",
    "    2: \"Comments\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Tuple\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import PreTrainedTokenizer\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class TokenizedDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataframe: pd.DataFrame,\n",
    "        tokenizer: PreTrainedTokenizer,\n",
    "        max_length: int,\n",
    "        text_column: str = \"text\",\n",
    "        link_text_column: str = \"link_text\",\n",
    "        tensor_dtype: Tuple[torch.dtype, torch.dtype] = (torch.long, torch.long),\n",
    "    ):\n",
    "        \"\"\"\n",
    "        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –¥–∞—Ç–∞—Å–µ—Ç–∞ —Å –ª–µ–Ω–∏–≤–æ–π —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–µ–π.\n",
    "\n",
    "        Args:\n",
    "            dataframe (pd.DataFrame): DataFrame —Å –∫–æ–ª–æ–Ω–∫–∞–º–∏ –¥–ª—è —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–∏.\n",
    "            tokenizer (PreTrainedTokenizer): –¢–æ–∫–µ–Ω–∞–π–∑–µ—Ä –¥–ª—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è —Ç–µ–∫—Å—Ç–∞.\n",
    "            max_length (int): –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ —Ç–æ–∫–µ–Ω–æ–≤.\n",
    "            text_column (str): –ù–∞–∑–≤–∞–Ω–∏–µ –æ—Å–Ω–æ–≤–Ω–æ–π —Ç–µ–∫—Å—Ç–æ–≤–æ–π –∫–æ–ª–æ–Ω–∫–∏.\n",
    "            link_text_column (str): –ù–∞–∑–≤–∞–Ω–∏–µ –∫–æ–ª–æ–Ω–∫–∏ —Å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–º —Ç–µ–∫—Å—Ç–æ–º.\n",
    "            tensor_dtype (tuple): –¢–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ç–æ–∫–µ–Ω–æ–≤ (input_ids, attention_mask).\n",
    "        \"\"\"\n",
    "        self.dataframe = dataframe.copy()  # –ö–æ–ø–∏—Ä—É–µ–º DataFrame, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –∏–∑–º–µ–Ω–µ–Ω–∏–π –≤ –æ—Ä–∏–≥–∏–Ω–∞–ª–µ\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.text_column = text_column\n",
    "        self.link_text_column = link_text_column\n",
    "        self.tensor_dtype = tensor_dtype\n",
    "\n",
    "        # –ü—Ä–æ–≤–µ—Ä–∫–∞, –µ—Å—Ç—å –ª–∏ —É–∫–∞–∑–∞–Ω–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –≤ DataFrame\n",
    "        if text_column not in dataframe.columns:\n",
    "            raise ValueError(f\"–ö–æ–ª–æ–Ω–∫–∞ '{text_column}' –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ DataFrame\")\n",
    "        if link_text_column not in dataframe.columns:\n",
    "            raise ValueError(f\"–ö–æ–ª–æ–Ω–∫–∞ '{link_text_column}' –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ DataFrame\")\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"\n",
    "        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–º–µ—Ä–æ–≤ –≤ –¥–∞—Ç–∞—Å–µ—Ç–µ.\n",
    "        \"\"\"\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def _tokenize_text(self, text: str) -> Dict[str, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        –¢–æ–∫–µ–Ω–∏–∑–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç, –µ—Å–ª–∏ –æ–Ω –Ω–µ –ø—É—Å—Ç–æ–π, –∏–Ω–∞—á–µ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–µ–Ω–∑–æ—Ä—ã —Å –Ω—É–ª—è–º–∏.\n",
    "\n",
    "        Args:\n",
    "            text (str): –¢–µ–∫—Å—Ç –¥–ª—è —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–∏.\n",
    "\n",
    "        Returns:\n",
    "            Dict[str, torch.Tensor]: –¢–µ–Ω–∑–æ—Ä—ã input_ids –∏ attention_mask.\n",
    "        \"\"\"\n",
    "        if pd.isna(text) or text.strip() == \"\":\n",
    "            return {\n",
    "                \"input_ids\": torch.zeros(self.max_length, dtype=self.tensor_dtype[0]),\n",
    "                \"attention_mask\": torch.zeros(self.max_length, dtype=self.tensor_dtype[1]),\n",
    "            }\n",
    "        else:\n",
    "            tokens = self.tokenizer(\n",
    "                text,\n",
    "                max_length=self.max_length,\n",
    "                padding=\"max_length\",\n",
    "                truncation=True,\n",
    "                return_tensors=\"pt\",\n",
    "            )\n",
    "            return {\n",
    "                \"input_ids\": tokens[\"input_ids\"][0].to(dtype=self.tensor_dtype[0]),\n",
    "                \"attention_mask\": tokens[\"attention_mask\"][0].to(dtype=self.tensor_dtype[1]),\n",
    "            }\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Dict[str, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–æ–∫–µ–Ω–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ.\n",
    "\n",
    "        Args:\n",
    "            idx (int): –ò–Ω–¥–µ–∫—Å –ø—Ä–∏–º–µ—Ä–∞.\n",
    "\n",
    "        Returns:\n",
    "            Dict[str, torch.Tensor]: –°–ª–æ–≤–∞—Ä—å —Å —Ç–æ–∫–µ–Ω–∞–º–∏ –∏–∑ –¥–≤—É—Ö –∫–æ–ª–æ–Ω–æ–∫.\n",
    "        \"\"\"\n",
    "        row = self.dataframe.iloc[idx]\n",
    "\n",
    "        text_tokens = self._tokenize_text(row[self.text_column])\n",
    "\n",
    "        link_text_tokens = self._tokenize_text(row[self.link_text_column])\n",
    "\n",
    "        return {\n",
    "            \"input_ids_text\": text_tokens[\"input_ids\"],\n",
    "            \"attention_mask_text\": text_tokens[\"attention_mask\"],\n",
    "            \"input_ids_link\": link_text_tokens[\"input_ids\"],\n",
    "            \"attention_mask_link\": link_text_tokens[\"attention_mask\"],\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer\n",
    "\n",
    "tokenizer: RobertaTokenizer = RobertaTokenizer.from_pretrained(DATA_PATH_SAVE_MODELS / MODEL_NAME)\n",
    "\n",
    "dataset = TokenizedDataset(data_df, tokenizer, MAX_LENGTH, text_column='text', link_text_column='link_text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids_text': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'attention_mask_text': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'input_ids_link': tensor([    0, 40827,   254, 22208,  5504,  5560,  2799,    11,  1836,   645,\n",
       "            20,   157,    12, 24872, 16126,   851,   784, 11804, 13291,    10,\n",
       "           821, 24217,    77,    51,  2967,     5, 29596, 37060, 17770,     7,\n",
       "         12579,     4,     2,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1]),\n",
       " 'attention_mask_link': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0])}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –ú–æ–¥–µ–ª—å"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import RobertaForSequenceClassification, RobertaTokenizer\n",
    "\n",
    "model = RobertaForSequenceClassification.from_pretrained(\n",
    "    DATA_PATH_SAVE_MODELS / MODEL_NAME)\n",
    "\n",
    "model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "from typing import Dict\n",
    "\n",
    "\n",
    "def test_model_on_dataset(\n",
    "    model: torch.nn.Module,\n",
    "    dataset: TokenizedDataset,\n",
    "    idx2label: Dict[int, str],\n",
    "    entropy_thresholds: Dict[int, float],  # –ü–æ—Ä–æ–≥–∏ —ç–Ω—Ç—Ä–æ–ø–∏–∏ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º\n",
    "    batch_size: int = 16,\n",
    "    device: torch.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    –ü—Ä–æ–≥–æ–Ω—è–µ—Ç –¥–∞—Ç–∞—Å–µ—Ç —á–µ—Ä–µ–∑ –º–æ–¥–µ–ª—å –∏ –¥–æ–±–∞–≤–ª—è–µ—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è, —ç–Ω—Ç—Ä–æ–ø–∏—é –∏ –µ—ë –ø–æ—Ä–æ–≥–∏ –≤ DataFrame.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): –û–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å.\n",
    "        dataset (Dataset): –¢–æ–∫–µ–Ω–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç.\n",
    "        idx2label (dict): –°–ª–æ–≤–∞—Ä—å, –æ—Ç–æ–±—Ä–∞–∂–∞—é—â–∏–π –∏–Ω–¥–µ–∫—Å—ã –∫–∞—Ç–µ–≥–æ—Ä–∏–π –≤ –Ω–∞–∑–≤–∞–Ω–∏—è.\n",
    "        entropy_thresholds (dict): –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –ø–æ—Ä–æ–≥–∏ —ç–Ω—Ç—Ä–æ–ø–∏–∏ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º.\n",
    "        batch_size (int): –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –¥–ª—è DataLoader.\n",
    "        device (torch.device): –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏–π (CPU/GPU).\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame —Å –¥–æ–±–∞–≤–ª–µ–Ω–Ω—ã–º–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è–º–∏, –≤–∫–ª—é—á–∞—è:\n",
    "            - 'predict_1', 'probability_1', 'entropy_1', 'entropy_threshold_1', 'passed_threshold_1'\n",
    "            - 'predict_2', 'probability_2', 'entropy_2', 'entropy_threshold_2', 'passed_threshold_2'\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    # –°–æ–∑–¥–∞—ë–º DataLoader\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    test_df = dataset.dataframe.copy()\n",
    "\n",
    "    # –°–ø–∏—Å–∫–∏ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –∏ –º–µ—Ç—Ä–∏–∫\n",
    "    predictions_1, probabilities_1, entropies_1, entropy_thresholds_1, passed_thresholds_1 = [], [], [], [], []\n",
    "    predictions_2, probabilities_2, entropies_2, entropy_thresholds_2, passed_thresholds_2 = [], [], [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Processing\"):\n",
    "            batch_size_current = batch[\"input_ids_text\"].shape[0]\n",
    "\n",
    "            # === –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –æ—Å–Ω–æ–≤–Ω—É—é –∫–æ–ª–æ–Ω–∫—É (text) ===\n",
    "            input_ids_text = batch[\"input_ids_text\"].to(device)\n",
    "            attention_mask_text = batch[\"attention_mask_text\"].to(device)\n",
    "\n",
    "            text_has_content = [torch.any(input_ids_text[i] != 0).item() for i in range(batch_size_current)]\n",
    "            if any(text_has_content):  # –ï—Å–ª–∏ —Ö–æ—Ç—è –±—ã –≤ –æ–¥–Ω–æ–º –µ—Å—Ç—å —Ç–µ–∫—Å—Ç\n",
    "                logits = model(input_ids=input_ids_text, attention_mask=attention_mask_text).logits\n",
    "                probs = torch.softmax(logits, dim=-1)\n",
    "                entropy = -torch.sum(probs * torch.log2(probs + 1e-15), dim=1)\n",
    "\n",
    "                preds = torch.argmax(probs, dim=-1).cpu().numpy()\n",
    "                probs = probs.cpu().numpy()\n",
    "                entropy = entropy.cpu().numpy()\n",
    "\n",
    "                for i in range(batch_size_current):\n",
    "                    if text_has_content[i]:\n",
    "                        entropy_threshold = entropy_thresholds.get(preds[i], None)\n",
    "                        passed_threshold = entropy[i] > entropy_threshold if entropy_threshold is not None else None\n",
    "\n",
    "                        predictions_1.append(preds[i])\n",
    "                        probabilities_1.append(probs[i].tolist())\n",
    "                        entropies_1.append(entropy[i])\n",
    "                        entropy_thresholds_1.append(entropy_threshold)\n",
    "                        passed_thresholds_1.append(passed_threshold)\n",
    "                    else:\n",
    "                        predictions_1.append(None)\n",
    "                        probabilities_1.append(None)\n",
    "                        entropies_1.append(None)\n",
    "                        entropy_thresholds_1.append(None)\n",
    "                        passed_thresholds_1.append(None)\n",
    "            else:\n",
    "                predictions_1.extend([None] * batch_size_current)\n",
    "                probabilities_1.extend([None] * batch_size_current)\n",
    "                entropies_1.extend([None] * batch_size_current)\n",
    "                entropy_thresholds_1.extend([None] * batch_size_current)\n",
    "                passed_thresholds_1.extend([None] * batch_size_current)\n",
    "\n",
    "            # === –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—É—é –∫–æ–ª–æ–Ω–∫—É (link_text) ===\n",
    "            input_ids_link = batch[\"input_ids_link\"].to(device)\n",
    "            attention_mask_link = batch[\"attention_mask_link\"].to(device)\n",
    "\n",
    "            link_text_has_content = [torch.any(input_ids_link[i] != 0).item() for i in range(batch_size_current)]\n",
    "            if any(link_text_has_content):  # –ï—Å–ª–∏ —Ö–æ—Ç—è –±—ã –≤ –æ–¥–Ω–æ–º –µ—Å—Ç—å —Ç–µ–∫—Å—Ç\n",
    "                logits = model(input_ids=input_ids_link, attention_mask=attention_mask_link).logits\n",
    "                probs = torch.softmax(logits, dim=-1)\n",
    "                entropy = -torch.sum(probs * torch.log2(probs + 1e-15), dim=1)\n",
    "\n",
    "                preds = torch.argmax(probs, dim=-1).cpu().numpy()\n",
    "                probs = probs.cpu().numpy()\n",
    "                entropy = entropy.cpu().numpy()\n",
    "\n",
    "                for i in range(batch_size_current):\n",
    "                    if link_text_has_content[i]:\n",
    "                        entropy_threshold = entropy_thresholds.get(preds[i], None)\n",
    "                        passed_threshold = entropy[i] < entropy_threshold if entropy_threshold is not None else None\n",
    "\n",
    "                        predictions_2.append(preds[i])\n",
    "                        probabilities_2.append(probs[i].tolist())\n",
    "                        entropies_2.append(entropy[i])\n",
    "                        entropy_thresholds_2.append(entropy_threshold)\n",
    "                        passed_thresholds_2.append(passed_threshold)\n",
    "                    else:\n",
    "                        predictions_2.append(None)\n",
    "                        probabilities_2.append(None)\n",
    "                        entropies_2.append(None)\n",
    "                        entropy_thresholds_2.append(None)\n",
    "                        passed_thresholds_2.append(None)\n",
    "            else:\n",
    "                predictions_2.extend([None] * batch_size_current)\n",
    "                probabilities_2.extend([None] * batch_size_current)\n",
    "                entropies_2.extend([None] * batch_size_current)\n",
    "                entropy_thresholds_2.extend([None] * batch_size_current)\n",
    "                passed_thresholds_2.extend([None] * batch_size_current)\n",
    "\n",
    "    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –≤ DataFrame\n",
    "    test_df = test_df.reset_index(drop=True)\n",
    "    test_df[\"predict_1\"] = [idx2label[p] if p is not None else None for p in predictions_1]\n",
    "    test_df[\"probability_1\"] = probabilities_1\n",
    "    test_df[\"entropy_1\"] = entropies_1\n",
    "    test_df[\"entropy_threshold_1\"] = entropy_thresholds_1\n",
    "    test_df[\"passed_threshold_1\"] = passed_thresholds_1\n",
    "\n",
    "    test_df[\"predict_2\"] = [idx2label[p] if p is not None else None for p in predictions_2]\n",
    "    test_df[\"probability_2\"] = probabilities_2\n",
    "    test_df[\"entropy_2\"] = entropies_2\n",
    "    test_df[\"entropy_threshold_2\"] = entropy_thresholds_2\n",
    "    test_df[\"passed_threshold_2\"] = passed_thresholds_2\n",
    "\n",
    "    return test_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dee8c53df0a246cb88e51c5e1bdb1784",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "entropy_thresholds = {1: 0.5176525712013245, 0: 0.6887069940567017, 2: 0.3750338852405548}\n",
    "\n",
    "test_results_df = test_model_on_dataset(\n",
    "    model=model,\n",
    "    dataset=dataset,\n",
    "    idx2label=idx2label,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    entropy_thresholds=entropy_thresholds,\n",
    "    device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Group Name</th>\n",
       "      <th>User Name</th>\n",
       "      <th>Facebook Id</th>\n",
       "      <th>Page Category</th>\n",
       "      <th>Page Admin Top Country</th>\n",
       "      <th>Page Description</th>\n",
       "      <th>Page Created</th>\n",
       "      <th>Likes at Posting</th>\n",
       "      <th>Followers at Posting</th>\n",
       "      <th>Post Created</th>\n",
       "      <th>...</th>\n",
       "      <th>predict_1</th>\n",
       "      <th>probability_1</th>\n",
       "      <th>entropy_1</th>\n",
       "      <th>entropy_threshold_1</th>\n",
       "      <th>passed_threshold_1</th>\n",
       "      <th>predict_2</th>\n",
       "      <th>probability_2</th>\n",
       "      <th>entropy_2</th>\n",
       "      <th>entropy_threshold_2</th>\n",
       "      <th>passed_threshold_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>COVID19: Real Talk from Health Care Workers around the Globe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1073058046385811</td>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>109582.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-08-11 21:46:31 EDT</td>\n",
       "      <td>...</td>\n",
       "      <td>Comments</td>\n",
       "      <td>[0.00010242078133160248, 0.000590130512136966, 0.99930739402771]</td>\n",
       "      <td>0.008686</td>\n",
       "      <td>0.375034</td>\n",
       "      <td>False</td>\n",
       "      <td>Comments</td>\n",
       "      <td>[0.000405871425755322, 0.003203626722097397, 0.9963905215263367]</td>\n",
       "      <td>0.036316</td>\n",
       "      <td>0.375034</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>COVID19: Real Talk from Health Care Workers around the Globe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1073058046385811</td>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48860.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-03-29 15:58:29 EDT</td>\n",
       "      <td>...</td>\n",
       "      <td>Comments</td>\n",
       "      <td>[0.009789294563233852, 0.022784806787967682, 0.9674258828163147]</td>\n",
       "      <td>0.235869</td>\n",
       "      <td>0.375034</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>COVID19: Real Talk from Health Care Workers around the Globe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1073058046385811</td>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>107766.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-12-17 23:30:26 EST</td>\n",
       "      <td>...</td>\n",
       "      <td>Comments</td>\n",
       "      <td>[0.0003218159545212984, 0.001806577667593956, 0.9978716373443604]</td>\n",
       "      <td>0.023263</td>\n",
       "      <td>0.375034</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>COVID19: Real Talk from Health Care Workers around the Globe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1073058046385811</td>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>107842.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-11-18 20:41:03 EST</td>\n",
       "      <td>...</td>\n",
       "      <td>Comments</td>\n",
       "      <td>[0.06370309740304947, 0.16327203810214996, 0.7730249166488647]</td>\n",
       "      <td>0.967071</td>\n",
       "      <td>0.375034</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Covid 19 - Newmill Community Support</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1556784341144788</td>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-04-16 15:50:01 EDT</td>\n",
       "      <td>...</td>\n",
       "      <td>Comments</td>\n",
       "      <td>[0.005032265558838844, 0.0070299385115504265, 0.9879377484321594]</td>\n",
       "      <td>0.105996</td>\n",
       "      <td>0.375034</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>Covid19 Real Stories by Frontline and Affected People</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3938079882870550</td>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-04-16 10:20:48 EDT</td>\n",
       "      <td>...</td>\n",
       "      <td>Real</td>\n",
       "      <td>[0.7864987850189209, 0.21058917045593262, 0.002912011230364442]</td>\n",
       "      <td>0.770338</td>\n",
       "      <td>0.688707</td>\n",
       "      <td>True</td>\n",
       "      <td>Fake</td>\n",
       "      <td>[0.23777706921100616, 0.7581254839897156, 0.004097355529665947]</td>\n",
       "      <td>0.828111</td>\n",
       "      <td>0.517653</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>COVID19: Real Talk from Health Care Workers around the Globe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1073058046385811</td>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>107753.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-12-07 20:46:45 EST</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>Real</td>\n",
       "      <td>[0.8064526915550232, 0.19045688211917877, 0.0030904437880963087]</td>\n",
       "      <td>0.731702</td>\n",
       "      <td>0.688707</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>COVID19: Real Talk from Health Care Workers around the Globe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1073058046385811</td>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>111149.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-05-28 15:26:37 EDT</td>\n",
       "      <td>...</td>\n",
       "      <td>Comments</td>\n",
       "      <td>[0.2533581852912903, 0.25821736454963684, 0.4884243905544281]</td>\n",
       "      <td>1.511156</td>\n",
       "      <td>0.375034</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>COVID19: Real Talk from Health Care Workers around the Globe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1073058046385811</td>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>107795.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-09 00:02:13 EST</td>\n",
       "      <td>...</td>\n",
       "      <td>Comments</td>\n",
       "      <td>[0.029040303081274033, 0.07921350002288818, 0.8917461633682251]</td>\n",
       "      <td>0.585447</td>\n",
       "      <td>0.375034</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Health Care Assistants HCA / Nurses / Support Workers - JOBS (UK)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1570841303216433</td>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34205.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-08-02 07:33:10 EDT</td>\n",
       "      <td>...</td>\n",
       "      <td>Comments</td>\n",
       "      <td>[0.005987084470689297, 0.007517407648265362, 0.9864954948425293]</td>\n",
       "      <td>0.116598</td>\n",
       "      <td>0.375034</td>\n",
       "      <td>False</td>\n",
       "      <td>Fake</td>\n",
       "      <td>[0.19375079870224, 0.6918608546257019, 0.1143883466720581]</td>\n",
       "      <td>1.184241</td>\n",
       "      <td>0.517653</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows √ó 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                            Group Name  \\\n",
       "103       COVID19: Real Talk from Health Care Workers around the Globe   \n",
       "480       COVID19: Real Talk from Health Care Workers around the Globe   \n",
       "124       COVID19: Real Talk from Health Care Workers around the Globe   \n",
       "432       COVID19: Real Talk from Health Care Workers around the Globe   \n",
       "9                                 Covid 19 - Newmill Community Support   \n",
       "315              Covid19 Real Stories by Frontline and Affected People   \n",
       "76        COVID19: Real Talk from Health Care Workers around the Globe   \n",
       "144       COVID19: Real Talk from Health Care Workers around the Globe   \n",
       "474       COVID19: Real Talk from Health Care Workers around the Globe   \n",
       "19   Health Care Assistants HCA / Nurses / Support Workers - JOBS (UK)   \n",
       "\n",
       "     User Name       Facebook Id Page Category  Page Admin Top Country  \\\n",
       "103        NaN  1073058046385811          none                     NaN   \n",
       "480        NaN  1073058046385811          none                     NaN   \n",
       "124        NaN  1073058046385811          none                     NaN   \n",
       "432        NaN  1073058046385811          none                     NaN   \n",
       "9          NaN  1556784341144788          none                     NaN   \n",
       "315        NaN  3938079882870550          none                     NaN   \n",
       "76         NaN  1073058046385811          none                     NaN   \n",
       "144        NaN  1073058046385811          none                     NaN   \n",
       "474        NaN  1073058046385811          none                     NaN   \n",
       "19         NaN  1570841303216433          none                     NaN   \n",
       "\n",
       "     Page Description  Page Created  Likes at Posting  Followers at Posting  \\\n",
       "103               NaN           NaN          109582.0                   NaN   \n",
       "480               NaN           NaN           48860.0                   NaN   \n",
       "124               NaN           NaN          107766.0                   NaN   \n",
       "432               NaN           NaN          107842.0                   NaN   \n",
       "9                 NaN           NaN               NaN                   NaN   \n",
       "315               NaN           NaN               NaN                   NaN   \n",
       "76                NaN           NaN          107753.0                   NaN   \n",
       "144               NaN           NaN          111149.0                   NaN   \n",
       "474               NaN           NaN          107795.0                   NaN   \n",
       "19                NaN           NaN           34205.0                   NaN   \n",
       "\n",
       "                Post Created  ... predict_1  \\\n",
       "103  2020-08-11 21:46:31 EDT  ...  Comments   \n",
       "480  2020-03-29 15:58:29 EDT  ...  Comments   \n",
       "124  2020-12-17 23:30:26 EST  ...  Comments   \n",
       "432  2020-11-18 20:41:03 EST  ...  Comments   \n",
       "9    2020-04-16 15:50:01 EDT  ...  Comments   \n",
       "315  2020-04-16 10:20:48 EDT  ...      Real   \n",
       "76   2020-12-07 20:46:45 EST  ...      None   \n",
       "144  2020-05-28 15:26:37 EDT  ...  Comments   \n",
       "474  2021-01-09 00:02:13 EST  ...  Comments   \n",
       "19   2021-08-02 07:33:10 EDT  ...  Comments   \n",
       "\n",
       "                                                         probability_1  \\\n",
       "103   [0.00010242078133160248, 0.000590130512136966, 0.99930739402771]   \n",
       "480   [0.009789294563233852, 0.022784806787967682, 0.9674258828163147]   \n",
       "124  [0.0003218159545212984, 0.001806577667593956, 0.9978716373443604]   \n",
       "432     [0.06370309740304947, 0.16327203810214996, 0.7730249166488647]   \n",
       "9    [0.005032265558838844, 0.0070299385115504265, 0.9879377484321594]   \n",
       "315    [0.7864987850189209, 0.21058917045593262, 0.002912011230364442]   \n",
       "76                                                                None   \n",
       "144      [0.2533581852912903, 0.25821736454963684, 0.4884243905544281]   \n",
       "474    [0.029040303081274033, 0.07921350002288818, 0.8917461633682251]   \n",
       "19    [0.005987084470689297, 0.007517407648265362, 0.9864954948425293]   \n",
       "\n",
       "    entropy_1  entropy_threshold_1  passed_threshold_1  predict_2  \\\n",
       "103  0.008686             0.375034               False   Comments   \n",
       "480  0.235869             0.375034               False       None   \n",
       "124  0.023263             0.375034               False       None   \n",
       "432  0.967071             0.375034                True       None   \n",
       "9    0.105996             0.375034               False       None   \n",
       "315  0.770338             0.688707                True       Fake   \n",
       "76        NaN                  NaN                None       Real   \n",
       "144  1.511156             0.375034                True       None   \n",
       "474  0.585447             0.375034                True       None   \n",
       "19   0.116598             0.375034               False       Fake   \n",
       "\n",
       "                                                        probability_2  \\\n",
       "103  [0.000405871425755322, 0.003203626722097397, 0.9963905215263367]   \n",
       "480                                                              None   \n",
       "124                                                              None   \n",
       "432                                                              None   \n",
       "9                                                                None   \n",
       "315   [0.23777706921100616, 0.7581254839897156, 0.004097355529665947]   \n",
       "76   [0.8064526915550232, 0.19045688211917877, 0.0030904437880963087]   \n",
       "144                                                              None   \n",
       "474                                                              None   \n",
       "19         [0.19375079870224, 0.6918608546257019, 0.1143883466720581]   \n",
       "\n",
       "     entropy_2  entropy_threshold_2  passed_threshold_2  \n",
       "103   0.036316             0.375034                True  \n",
       "480        NaN                  NaN                None  \n",
       "124        NaN                  NaN                None  \n",
       "432        NaN                  NaN                None  \n",
       "9          NaN                  NaN                None  \n",
       "315   0.828111             0.517653               False  \n",
       "76    0.731702             0.688707               False  \n",
       "144        NaN                  NaN                None  \n",
       "474        NaN                  NaN                None  \n",
       "19    1.184241             0.517653               False  \n",
       "\n",
       "[10 rows x 52 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>predict_1</th>\n",
       "      <th>probability_1</th>\n",
       "      <th>entropy_1</th>\n",
       "      <th>entropy_threshold_1</th>\n",
       "      <th>passed_threshold_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Judges are apparently forcing hospitals to administer ivermectin in multiple cases. I‚Äôve never heard of anything like this before.</td>\n",
       "      <td>Fake</td>\n",
       "      <td>[0.3932177424430847, 0.5643640756607056, 0.04241819679737091]</td>\n",
       "      <td>1.188670</td>\n",
       "      <td>0.517653</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>How often are healthcare workers whom are in close contact care with positive Covid patients being tested themselves? Or what‚Äôs the recommendation for your facilities?</td>\n",
       "      <td>Fake</td>\n",
       "      <td>[0.3282310664653778, 0.6674463152885437, 0.004322689026594162]</td>\n",
       "      <td>0.950794</td>\n",
       "      <td>0.517653</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>Meanwhile in India during the devastating second wave, doctors are getting brutally assaulted.</td>\n",
       "      <td>Fake</td>\n",
       "      <td>[0.26339009404182434, 0.7233384251594543, 0.013271420262753963]</td>\n",
       "      <td>0.927694</td>\n",
       "      <td>0.517653</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Merry Christmas Eve from our COVID unit to yours üòò</td>\n",
       "      <td>Fake</td>\n",
       "      <td>[0.2204810380935669, 0.7764163613319397, 0.003102540737017989]</td>\n",
       "      <td>0.790249</td>\n",
       "      <td>0.517653</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Just out of curiosity does anyone else get the feeling that some are on here because they are scared and know we‚Äôre all a medical team? Please delete if inappropriate.</td>\n",
       "      <td>Fake</td>\n",
       "      <td>[0.2516616880893707, 0.46662119030952454, 0.2817171514034271]</td>\n",
       "      <td>1.528939</td>\n",
       "      <td>0.517653</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>Anybody else out of Covid-19 test in the hospital? We're told there is a national shortage...</td>\n",
       "      <td>Fake</td>\n",
       "      <td>[0.10680346190929413, 0.8752534985542297, 0.017943084239959717]</td>\n",
       "      <td>0.616977</td>\n",
       "      <td>0.517653</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>Has anyone heard of this study or it‚Äôs results?</td>\n",
       "      <td>Fake</td>\n",
       "      <td>[0.12313830107450485, 0.8281078934669495, 0.048753827810287476]</td>\n",
       "      <td>0.809902</td>\n",
       "      <td>0.517653</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Is the Pfizer vaccine truly been approved? I keep hearing people say it‚Äôs not really approved and that a different vaccine is approved but not available yet. Anyone hearing this? What are they talking about? So tired of all the false information. Thanks.</td>\n",
       "      <td>Fake</td>\n",
       "      <td>[0.31345051527023315, 0.6571012735366821, 0.02944825030863285]</td>\n",
       "      <td>1.072463</td>\n",
       "      <td>0.517653</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>[A new study finds no evidence of benefit from a malaria drug widely promoted as a treatment for coronavirus infection. Hydroxychloroquine did not lower the risk of dying or needing a breathing tube in a comparison that involved nearly 1,400 patients treated at Columbia University in New York, r...</td>\n",
       "      <td>Fake</td>\n",
       "      <td>[0.3928290009498596, 0.4414222240447998, 0.1657487452030182]</td>\n",
       "      <td>1.480095</td>\n",
       "      <td>0.517653</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>Good news for healthcare workers! Costco announced a new ‚Äúpriority access‚Äù policy for frontline workers, specifically first responders and healthcare workers, which allows them to skip straight to ‚Äúthe front of any line to enter the warehouse.‚Äù All you need to do is show your work ID to cut the ...</td>\n",
       "      <td>Fake</td>\n",
       "      <td>[0.47324714064598083, 0.5234177112579346, 0.003335219109430909]</td>\n",
       "      <td>1.027088</td>\n",
       "      <td>0.517653</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                            text  \\\n",
       "7                                                                                                                                                                            Judges are apparently forcing hospitals to administer ivermectin in multiple cases. I‚Äôve never heard of anything like this before.    \n",
       "39                                                                                                                                       How often are healthcare workers whom are in close contact care with positive Covid patients being tested themselves? Or what‚Äôs the recommendation for your facilities?   \n",
       "408                                                                                                                                                                                                               Meanwhile in India during the devastating second wave, doctors are getting brutally assaulted.   \n",
       "5                                                                                                                                                                                                                                                             Merry Christmas Eve from our COVID unit to yours üòò   \n",
       "17                                                                                                                                       Just out of curiosity does anyone else get the feeling that some are on here because they are scared and know we‚Äôre all a medical team? Please delete if inappropriate.   \n",
       "199                                                                                                                                                                                                                Anybody else out of Covid-19 test in the hospital? We're told there is a national shortage...   \n",
       "141                                                                                                                                                                                                                                                             Has anyone heard of this study or it‚Äôs results?    \n",
       "6                                                 Is the Pfizer vaccine truly been approved? I keep hearing people say it‚Äôs not really approved and that a different vaccine is approved but not available yet. Anyone hearing this? What are they talking about? So tired of all the false information. Thanks.   \n",
       "185  [A new study finds no evidence of benefit from a malaria drug widely promoted as a treatment for coronavirus infection. Hydroxychloroquine did not lower the risk of dying or needing a breathing tube in a comparison that involved nearly 1,400 patients treated at Columbia University in New York, r...   \n",
       "385  Good news for healthcare workers! Costco announced a new ‚Äúpriority access‚Äù policy for frontline workers, specifically first responders and healthcare workers, which allows them to skip straight to ‚Äúthe front of any line to enter the warehouse.‚Äù All you need to do is show your work ID to cut the ...   \n",
       "\n",
       "    predict_1  \\\n",
       "7        Fake   \n",
       "39       Fake   \n",
       "408      Fake   \n",
       "5        Fake   \n",
       "17       Fake   \n",
       "199      Fake   \n",
       "141      Fake   \n",
       "6        Fake   \n",
       "185      Fake   \n",
       "385      Fake   \n",
       "\n",
       "                                                       probability_1  \\\n",
       "7      [0.3932177424430847, 0.5643640756607056, 0.04241819679737091]   \n",
       "39    [0.3282310664653778, 0.6674463152885437, 0.004322689026594162]   \n",
       "408  [0.26339009404182434, 0.7233384251594543, 0.013271420262753963]   \n",
       "5     [0.2204810380935669, 0.7764163613319397, 0.003102540737017989]   \n",
       "17     [0.2516616880893707, 0.46662119030952454, 0.2817171514034271]   \n",
       "199  [0.10680346190929413, 0.8752534985542297, 0.017943084239959717]   \n",
       "141  [0.12313830107450485, 0.8281078934669495, 0.048753827810287476]   \n",
       "6     [0.31345051527023315, 0.6571012735366821, 0.02944825030863285]   \n",
       "185     [0.3928290009498596, 0.4414222240447998, 0.1657487452030182]   \n",
       "385  [0.47324714064598083, 0.5234177112579346, 0.003335219109430909]   \n",
       "\n",
       "     entropy_1  entropy_threshold_1 passed_threshold_1  \n",
       "7     1.188670             0.517653               True  \n",
       "39    0.950794             0.517653               True  \n",
       "408   0.927694             0.517653               True  \n",
       "5     0.790249             0.517653               True  \n",
       "17    1.528939             0.517653               True  \n",
       "199   0.616977             0.517653               True  \n",
       "141   0.809902             0.517653               True  \n",
       "6     1.072463             0.517653               True  \n",
       "185   1.480095             0.517653               True  \n",
       "385   1.027088             0.517653               True  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.options.display.max_colwidth = 300\n",
    "\n",
    "columns_to_keep = [\n",
    "    \"text\", \"predict_1\", \"probability_1\", \"entropy_1\", \"entropy_threshold_1\", \"passed_threshold_1\"\n",
    "]\n",
    "\n",
    "test_results_df.loc[\n",
    "    (test_results_df[\"predict_1\"] == \"Fake\") & (test_results_df[\"passed_threshold_1\"] == True), \n",
    "    columns_to_keep\n",
    "].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>predict_1</th>\n",
       "      <th>probability_1</th>\n",
       "      <th>entropy_1</th>\n",
       "      <th>entropy_threshold_1</th>\n",
       "      <th>passed_threshold_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>BRITAIN Cleaners at the Ministry of Justice in London have downed tools because two of their colleagues have died from suspected covid and they do not have proper protection.</td>\n",
       "      <td>Real</td>\n",
       "      <td>[0.7346838712692261, 0.2520679235458374, 0.013248229399323463]</td>\n",
       "      <td>0.910574</td>\n",
       "      <td>0.688707</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Health care workers! We are working our tails off! Let‚Äôs show some appreciation. Post a picture of yourself or a #covidhero in their PPE‚ù§Ô∏è stay safe üò∑ü©∫‚ù§Ô∏è</td>\n",
       "      <td>Real</td>\n",
       "      <td>[0.5208881497383118, 0.46961653232574463, 0.009495341219007969]</td>\n",
       "      <td>1.066018</td>\n",
       "      <td>0.688707</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>Half a million workers in Karachi, Pakistan, one of the world's largest megacities, have been illegally fired from their jobs during the COVID19 lockdown. In many cases across the country, factories are forcing their workers (who are often illiterate) to sign a document resigning, while in other...</td>\n",
       "      <td>Real</td>\n",
       "      <td>[0.48944786190986633, 0.3792383372783661, 0.13131378591060638]</td>\n",
       "      <td>1.419603</td>\n",
       "      <td>0.688707</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>New study on the spread of Covid. Edit to add: 1. Im not pro or con on the study. Im simply sharing it. 2. It was conducted by real epidemiologists and public health experts at Princeton and Johns Hopkins and Berkley in addition to other notable international institutes. 3. Not everything posted...</td>\n",
       "      <td>Real</td>\n",
       "      <td>[0.46576693654060364, 0.11471937596797943, 0.41951361298561096]</td>\n",
       "      <td>1.397526</td>\n",
       "      <td>0.688707</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>SOUTH AFRICA. \"Workers use refuse bags as masks\". Health workers union threatens national strike. [https://www.thesouthafrican.com/news/nehawu-strike-over-lack-of-ppe-21-august-2020/](https://www.thesouthafrican.com/news/nehawu-strike-over-lack-of-ppe-21-august-2020/)</td>\n",
       "      <td>Real</td>\n",
       "      <td>[0.7798680067062378, 0.2015141397714615, 0.018617866560816765]</td>\n",
       "      <td>0.852446</td>\n",
       "      <td>0.688707</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Just a polite reminder if anyone has made anything bags ear savers. Could you please wash in 60 degrees and seal in food bags with the date sealed just ploughing through lots of bags that have been delivered When? washed and not in bags so have washed and ironed and now putting bags thankyou Jen...</td>\n",
       "      <td>Real</td>\n",
       "      <td>[0.44291776418685913, 0.1333048939704895, 0.42377740144729614]</td>\n",
       "      <td>1.432823</td>\n",
       "      <td>0.688707</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>Nurses‚Äô Pleas Spur U.S. Pledge to Tap 44 Million-Mask Stockpile Hospitals and medical offices are once again running short on masks and gowns in the midst of a raging pandemic, but the federal government is still drawing up plans to distribute its swelling stockpile.</td>\n",
       "      <td>Real</td>\n",
       "      <td>[0.6369713544845581, 0.36096030473709106, 0.0020683177281171083]</td>\n",
       "      <td>0.963564</td>\n",
       "      <td>0.688707</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>‚ÄúThe Federation of State Medical Boards (FSMB), which supports its member state medical licensing boards, has recently issued a statement saying that providing misinformation about the COVID-19 vaccine contradicts physicians‚Äô ethical and professional responsibilities, and therefore may subject a...</td>\n",
       "      <td>Real</td>\n",
       "      <td>[0.6012201905250549, 0.3976283073425293, 0.001151527278125286]</td>\n",
       "      <td>0.981605</td>\n",
       "      <td>0.688707</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Keeping everyone of you in my prayers. Please know that your service to others at this tragic and chaotic time is what His Holiness always talks about. We are all extremely proud of you üôèüèΩüí™üèºüëçüèº</td>\n",
       "      <td>Real</td>\n",
       "      <td>[0.7494724988937378, 0.18610769510269165, 0.06441985070705414]</td>\n",
       "      <td>1.018146</td>\n",
       "      <td>0.688707</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>Noting that our sickest patients seem to be largely Hispanic males between 40-60. This is from Texas. Any thoughts?</td>\n",
       "      <td>Real</td>\n",
       "      <td>[0.36942723393440247, 0.31001216173171997, 0.32056060433387756]</td>\n",
       "      <td>1.580677</td>\n",
       "      <td>0.688707</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                            text  \\\n",
       "254                                                                                                                              BRITAIN Cleaners at the Ministry of Justice in London have downed tools because two of their colleagues have died from suspected covid and they do not have proper protection.    \n",
       "64                                                                                                                                                     Health care workers! We are working our tails off! Let‚Äôs show some appreciation. Post a picture of yourself or a #covidhero in their PPE‚ù§Ô∏è stay safe üò∑ü©∫‚ù§Ô∏è   \n",
       "311  Half a million workers in Karachi, Pakistan, one of the world's largest megacities, have been illegally fired from their jobs during the COVID19 lockdown. In many cases across the country, factories are forcing their workers (who are often illiterate) to sign a document resigning, while in other...   \n",
       "438  New study on the spread of Covid. Edit to add: 1. Im not pro or con on the study. Im simply sharing it. 2. It was conducted by real epidemiologists and public health experts at Princeton and Johns Hopkins and Berkley in addition to other notable international institutes. 3. Not everything posted...   \n",
       "26                                  SOUTH AFRICA. \"Workers use refuse bags as masks\". Health workers union threatens national strike. [https://www.thesouthafrican.com/news/nehawu-strike-over-lack-of-ppe-21-august-2020/](https://www.thesouthafrican.com/news/nehawu-strike-over-lack-of-ppe-21-august-2020/)   \n",
       "77   Just a polite reminder if anyone has made anything bags ear savers. Could you please wash in 60 degrees and seal in food bags with the date sealed just ploughing through lots of bags that have been delivered When? washed and not in bags so have washed and ironed and now putting bags thankyou Jen...   \n",
       "320                                  Nurses‚Äô Pleas Spur U.S. Pledge to Tap 44 Million-Mask Stockpile Hospitals and medical offices are once again running short on masks and gowns in the midst of a raging pandemic, but the federal government is still drawing up plans to distribute its swelling stockpile.   \n",
       "52   ‚ÄúThe Federation of State Medical Boards (FSMB), which supports its member state medical licensing boards, has recently issued a statement saying that providing misinformation about the COVID-19 vaccine contradicts physicians‚Äô ethical and professional responsibilities, and therefore may subject a...   \n",
       "49                                                                                                              Keeping everyone of you in my prayers. Please know that your service to others at this tragic and chaotic time is what His Holiness always talks about. We are all extremely proud of you üôèüèΩüí™üèºüëçüèº   \n",
       "421                                                                                                                                                                                          Noting that our sickest patients seem to be largely Hispanic males between 40-60. This is from Texas. Any thoughts?   \n",
       "\n",
       "    predict_1  \\\n",
       "254      Real   \n",
       "64       Real   \n",
       "311      Real   \n",
       "438      Real   \n",
       "26       Real   \n",
       "77       Real   \n",
       "320      Real   \n",
       "52       Real   \n",
       "49       Real   \n",
       "421      Real   \n",
       "\n",
       "                                                        probability_1  \\\n",
       "254    [0.7346838712692261, 0.2520679235458374, 0.013248229399323463]   \n",
       "64    [0.5208881497383118, 0.46961653232574463, 0.009495341219007969]   \n",
       "311    [0.48944786190986633, 0.3792383372783661, 0.13131378591060638]   \n",
       "438   [0.46576693654060364, 0.11471937596797943, 0.41951361298561096]   \n",
       "26     [0.7798680067062378, 0.2015141397714615, 0.018617866560816765]   \n",
       "77     [0.44291776418685913, 0.1333048939704895, 0.42377740144729614]   \n",
       "320  [0.6369713544845581, 0.36096030473709106, 0.0020683177281171083]   \n",
       "52     [0.6012201905250549, 0.3976283073425293, 0.001151527278125286]   \n",
       "49     [0.7494724988937378, 0.18610769510269165, 0.06441985070705414]   \n",
       "421   [0.36942723393440247, 0.31001216173171997, 0.32056060433387756]   \n",
       "\n",
       "     entropy_1  entropy_threshold_1 passed_threshold_1  \n",
       "254   0.910574             0.688707               True  \n",
       "64    1.066018             0.688707               True  \n",
       "311   1.419603             0.688707               True  \n",
       "438   1.397526             0.688707               True  \n",
       "26    0.852446             0.688707               True  \n",
       "77    1.432823             0.688707               True  \n",
       "320   0.963564             0.688707               True  \n",
       "52    0.981605             0.688707               True  \n",
       "49    1.018146             0.688707               True  \n",
       "421   1.580677             0.688707               True  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.options.display.max_colwidth = 300\n",
    "\n",
    "columns_to_keep = [\n",
    "    \"text\", \"predict_1\", \"probability_1\", \"entropy_1\", \"entropy_threshold_1\", \"passed_threshold_1\"\n",
    "]\n",
    "\n",
    "test_results_df.loc[\n",
    "    (test_results_df[\"predict_1\"] == \"Real\") & (test_results_df[\"passed_threshold_1\"] == True), \n",
    "    columns_to_keep\n",
    "].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predict_1\n",
       "Comments    268\n",
       "Fake         56\n",
       "Real         31\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results_df['predict_1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results_df.to_excel(DATA_PATH / 'facebook_data_to_complate.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
