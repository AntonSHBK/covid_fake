{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение определения фейковых фактов о COVID и вакцинации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cpu'\n",
    "if torch.backends.mps.is_available():\n",
    "    DEVICE = 'mps'\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "DATA_PATH = Path('data/')\n",
    "DATA_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "DATA_CACHE = Path('data/cache_dir/')\n",
    "DATA_CACHE.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "DATA_PATH_SAVE_MODELS = Path('data/models/')\n",
    "DATA_PATH_SAVE_MODELS.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "pd.set_option('display.max_colwidth', 500) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"covid_vaccine_fake_model\"\n",
    "TEST_DF_NAME = \"facebook_data_to_model.xlsx\"\n",
    "\n",
    "MAX_LENGTH = 128\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_excel(DATA_PATH / TEST_DF_NAME)\n",
    "data_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2label = {\n",
    "    0: \"Real\",\n",
    "    1: \"Fake\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Tuple\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import PreTrainedTokenizer\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class TokenizedDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataframe: pd.DataFrame,\n",
    "        tokenizer: PreTrainedTokenizer,\n",
    "        max_length: int,\n",
    "        text_column: str = \"text\",\n",
    "        tensor_dtype: Tuple[torch.dtype, torch.dtype] = (torch.long, torch.long),\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Инициализация датасета с токенизацией.\n",
    "\n",
    "        Args:\n",
    "            dataframe (pd.DataFrame): DataFrame с колонкой, содержащей текст для токенизации.\n",
    "            tokenizer (PreTrainedTokenizer): Токенайзер для преобразования текста.\n",
    "            max_length (int): Максимальная длина токенов.\n",
    "            text_column (str): Название колонки с текстом.\n",
    "            tensor_dtype (tuple): Типы данных для токенов (input_ids, attention_mask).\n",
    "        \"\"\"\n",
    "        self.tensor_dtype = tensor_dtype\n",
    "\n",
    "        if text_column not in dataframe.columns:\n",
    "            raise ValueError(f\"Колонка '{text_column}' отсутствует в DataFrame\")\n",
    "\n",
    "        tokenized_data = tokenizer(\n",
    "            dataframe[text_column].tolist(),\n",
    "            max_length=max_length,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        self.input_ids = tokenized_data[\"input_ids\"].to(dtype=self.tensor_dtype[0])\n",
    "        self.attention_mask = tokenized_data[\"attention_mask\"].to(dtype=self.tensor_dtype[1])\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"\n",
    "        Возвращает количество примеров в датасете.\n",
    "        \"\"\"\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Dict[str, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Возвращает токенизированные данные.\n",
    "\n",
    "        Args:\n",
    "            idx (int): Индекс примера.\n",
    "\n",
    "        Returns:\n",
    "            Dict[str, torch.Tensor]: Словарь с токенами.\n",
    "        \"\"\"\n",
    "        return {\n",
    "            \"input_ids\": self.input_ids[idx],\n",
    "            \"attention_mask\": self.attention_mask[idx],\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from transformers import PreTrainedTokenizer\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def create_dataloader(\n",
    "    dataframe: pd.DataFrame,\n",
    "    tokenizer: PreTrainedTokenizer,\n",
    "    text_column: str = \"text\",\n",
    "    max_length: int = 64,\n",
    "    batch_size: int = 16,\n",
    "    shuffle: bool = False,\n",
    "    tensor_dtype=(torch.long, torch.long),\n",
    ") -> DataLoader:\n",
    "    \"\"\"\n",
    "    Создание DataLoader из DataFrame без меток (для предсказания).\n",
    "\n",
    "    Args:\n",
    "        dataframe (pd.DataFrame): DataFrame с колонкой текста.\n",
    "        tokenizer (PreTrainedTokenizer): Токенайзер для преобразования текста.\n",
    "        text_column (str): Название колонки с текстом.\n",
    "        max_length (int): Максимальная длина токенов.\n",
    "        batch_size (int): Размер батча.\n",
    "        shuffle (bool): Перемешивать ли данные (по умолчанию False).\n",
    "        tensor_dtype (tuple): Типы данных для токенов.\n",
    "\n",
    "    Returns:\n",
    "        DataLoader: DataLoader для предсказания.\n",
    "    \"\"\"\n",
    "    dataset = TokenizedDataset(dataframe, tokenizer, max_length, text_column=text_column, tensor_dtype=tensor_dtype)\n",
    "    dataloader = DataLoader(\n",
    "        dataset, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=shuffle, \n",
    "    )\n",
    "    return dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer\n",
    "\n",
    "tokenizer: RobertaTokenizer = RobertaTokenizer.from_pretrained(DATA_PATH_SAVE_MODELS / MODEL_NAME)\n",
    "\n",
    "test_loader_1 = create_dataloader(\n",
    "    dataframe=data_df,\n",
    "    tokenizer=tokenizer,\n",
    "    text_column=\"text\",\n",
    "    max_length=MAX_LENGTH,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_loader_2 = create_dataloader(\n",
    "    dataframe=data_df,\n",
    "    tokenizer=tokenizer,\n",
    "    text_column=\"text\",\n",
    "    max_length=MAX_LENGTH,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaForSequenceClassification, RobertaTokenizer\n",
    "\n",
    "model = RobertaForSequenceClassification.from_pretrained(\n",
    "    DATA_PATH_SAVE_MODELS / MODEL_NAME)\n",
    "\n",
    "model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тестирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def run_model_on_dataloader(\n",
    "    model: torch.nn.Module,\n",
    "    dataloader: DataLoader,\n",
    "    device: torch.device\n",
    ") -> tuple:\n",
    "    \"\"\"\n",
    "    Прогоняет модель по даталоадеру и возвращает предсказания и вероятности.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): Обученная модель.\n",
    "        dataloader (DataLoader): DataLoader для обработки.\n",
    "        device (torch.device): Устройство для вычислений (CPU/GPU).\n",
    "\n",
    "    Returns:\n",
    "        Tuple: (список предсказанных меток, список вероятностей)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    predictions = []\n",
    "    probabilities = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Processing\"):\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "\n",
    "            # Получаем логиты\n",
    "            logits = model(input_ids=input_ids, attention_mask=attention_mask).logits\n",
    "            probs = torch.softmax(logits, dim=-1).cpu().numpy()\n",
    "            preds = torch.argmax(logits, dim=-1).cpu().numpy()\n",
    "\n",
    "            # Добавляем в списки\n",
    "            predictions.extend(preds)\n",
    "            probabilities.extend(probs.tolist())\n",
    "\n",
    "    return predictions, probabilities\n",
    "\n",
    "\n",
    "def test_model_on_dataset(\n",
    "    model: torch.nn.Module,\n",
    "    dataloader_1: DataLoader,\n",
    "    dataloader_2: DataLoader,\n",
    "    test_df: pd.DataFrame,\n",
    "    idx2label: dict,\n",
    "    device: torch.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Прогоняет датасет через модель для двух даталоадеров и добавляет результаты в DataFrame.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): Обученная модель.\n",
    "        dataloader_1 (DataLoader): Первый DataLoader.\n",
    "        dataloader_2 (DataLoader): Второй DataLoader.\n",
    "        test_df (pd.DataFrame): Исходный DataFrame (без меток).\n",
    "        idx2label (dict): Словарь, отображающий индексы категорий в названия.\n",
    "        device (torch.device): Устройство для вычислений (CPU/GPU).\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame с добавленными предсказаниями:\n",
    "            - 'predict_1': предсказанная метка для первого даталоадера,\n",
    "            - 'probability_1': вероятность предсказания для первого даталоадера,\n",
    "            - 'predict_2': предсказанная метка для второго даталоадера,\n",
    "            - 'probability_2': вероятность предсказания для второго даталоадера.\n",
    "    \"\"\"\n",
    "    print(\"Processing DataLoader 1...\")\n",
    "    predictions_1, probabilities_1 = run_model_on_dataloader(model, dataloader_1, device)\n",
    "\n",
    "    print(\"Processing DataLoader 2...\")\n",
    "    predictions_2, probabilities_2 = run_model_on_dataloader(model, dataloader_2, device)\n",
    "\n",
    "    # Преобразуем предсказанные индексы в метки\n",
    "    test_df = test_df.reset_index(drop=True)\n",
    "    test_df[\"predict_1\"] = [idx2label[p] for p in predictions_1]\n",
    "    test_df[\"probability_1\"] = probabilities_1\n",
    "    test_df[\"predict_2\"] = [idx2label[p] for p in predictions_2]\n",
    "    test_df[\"probability_2\"] = probabilities_2\n",
    "\n",
    "    return test_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_results_df = test_model_on_dataset(\n",
    "    model=model,\n",
    "    dataloader_1=test_loader_1,\n",
    "    dataloader_2=test_loader_2,\n",
    "    test_df=data_df,\n",
    "    idx2label=idx2label,\n",
    "    device=DEVICE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results_df.sample(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
