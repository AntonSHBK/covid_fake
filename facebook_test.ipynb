{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение определения фейковых фактов о COVID и вакцинации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cpu'\n",
    "if torch.backends.mps.is_available():\n",
    "    DEVICE = 'mps'\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "DATA_PATH = Path('data/')\n",
    "DATA_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "DATA_CACHE = Path('data/cache_dir/')\n",
    "DATA_CACHE.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "DATA_PATH_SAVE_MODELS = Path('data/models/')\n",
    "DATA_PATH_SAVE_MODELS.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "pd.set_option('display.max_colwidth', 500) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"covid_vaccine_fake_model\"\n",
    "TEST_DF_NAME = \"facebook_data_to_model.xlsx\"\n",
    "\n",
    "MAX_LENGTH = 128\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Group Name</th>\n",
       "      <th>User Name</th>\n",
       "      <th>Facebook Id</th>\n",
       "      <th>Page Category</th>\n",
       "      <th>Page Admin Top Country</th>\n",
       "      <th>Page Description</th>\n",
       "      <th>Page Created</th>\n",
       "      <th>Likes at Posting</th>\n",
       "      <th>Followers at Posting</th>\n",
       "      <th>Post Created</th>\n",
       "      <th>...</th>\n",
       "      <th>Final Link</th>\n",
       "      <th>Image Text</th>\n",
       "      <th>Link Text</th>\n",
       "      <th>Description</th>\n",
       "      <th>Sponsor Id</th>\n",
       "      <th>Sponsor Name</th>\n",
       "      <th>Sponsor Category</th>\n",
       "      <th>Overperforming Score (weighted  —  Likes 1x Shares 1x Comments 1x Love 1x Wow 1x Haha 1x Sad 1x Angry 1x Care 1x )</th>\n",
       "      <th>text</th>\n",
       "      <th>link_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COVID19: Real Talk from Health Care Workers around the Globe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1073058046385811</td>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66994.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-04-01 22:42:32 EDT</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>189.33</td>\n",
       "      <td>We extubated 2 covid patients today and they are doing awesome! Should be on a tele floor tomorrow! (TX)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Group Name  User Name  \\\n",
       "0  COVID19: Real Talk from Health Care Workers around the Globe        NaN   \n",
       "\n",
       "        Facebook Id Page Category  Page Admin Top Country  Page Description  \\\n",
       "0  1073058046385811          none                     NaN               NaN   \n",
       "\n",
       "   Page Created  Likes at Posting  Followers at Posting  \\\n",
       "0           NaN           66994.0                   NaN   \n",
       "\n",
       "              Post Created  ... Final Link Image Text Link Text  Description  \\\n",
       "0  2020-04-01 22:42:32 EDT  ...        NaN        NaN       NaN          NaN   \n",
       "\n",
       "   Sponsor Id  Sponsor Name  Sponsor Category  \\\n",
       "0         NaN           NaN               NaN   \n",
       "\n",
       "   Overperforming Score (weighted  —  Likes 1x Shares 1x Comments 1x Love 1x Wow 1x Haha 1x Sad 1x Angry 1x Care 1x )  \\\n",
       "0                                                                                                              189.33   \n",
       "\n",
       "                                                                                                       text  \\\n",
       "0  We extubated 2 covid patients today and they are doing awesome! Should be on a tele floor tomorrow! (TX)   \n",
       "\n",
       "   link_text  \n",
       "0        NaN  \n",
       "\n",
       "[1 rows x 42 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_excel(DATA_PATH / TEST_DF_NAME)\n",
    "data_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2label = {\n",
    "    0: \"Real\",\n",
    "    1: \"Fake\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Tuple\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import PreTrainedTokenizer\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class TokenizedDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataframe: pd.DataFrame,\n",
    "        tokenizer: PreTrainedTokenizer,\n",
    "        max_length: int,\n",
    "        text_column: str = \"text\",\n",
    "        link_text_column: str = \"link_text\",\n",
    "        tensor_dtype: Tuple[torch.dtype, torch.dtype] = (torch.long, torch.long),\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Инициализация датасета с ленивой токенизацией.\n",
    "\n",
    "        Args:\n",
    "            dataframe (pd.DataFrame): DataFrame с колонками для токенизации.\n",
    "            tokenizer (PreTrainedTokenizer): Токенайзер для преобразования текста.\n",
    "            max_length (int): Максимальная длина токенов.\n",
    "            text_column (str): Название основной текстовой колонки.\n",
    "            link_text_column (str): Название колонки с дополнительным текстом.\n",
    "            tensor_dtype (tuple): Типы данных для токенов (input_ids, attention_mask).\n",
    "        \"\"\"\n",
    "        self.dataframe = dataframe.copy()  # Копируем DataFrame, чтобы избежать изменений в оригинале\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.text_column = text_column\n",
    "        self.link_text_column = link_text_column\n",
    "        self.tensor_dtype = tensor_dtype\n",
    "\n",
    "        # Проверка, есть ли указанные колонки в DataFrame\n",
    "        if text_column not in dataframe.columns:\n",
    "            raise ValueError(f\"Колонка '{text_column}' отсутствует в DataFrame\")\n",
    "        if link_text_column not in dataframe.columns:\n",
    "            raise ValueError(f\"Колонка '{link_text_column}' отсутствует в DataFrame\")\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"\n",
    "        Возвращает количество примеров в датасете.\n",
    "        \"\"\"\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def _tokenize_text(self, text: str) -> Dict[str, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Токенизирует текст, если он не пустой, иначе возвращает тензоры с нулями.\n",
    "\n",
    "        Args:\n",
    "            text (str): Текст для токенизации.\n",
    "\n",
    "        Returns:\n",
    "            Dict[str, torch.Tensor]: Тензоры input_ids и attention_mask.\n",
    "        \"\"\"\n",
    "        if pd.isna(text) or text.strip() == \"\":\n",
    "            return {\n",
    "                \"input_ids\": torch.zeros(self.max_length, dtype=self.tensor_dtype[0]),\n",
    "                \"attention_mask\": torch.zeros(self.max_length, dtype=self.tensor_dtype[1]),\n",
    "            }\n",
    "        else:\n",
    "            tokens = self.tokenizer(\n",
    "                text,\n",
    "                max_length=self.max_length,\n",
    "                padding=\"max_length\",\n",
    "                truncation=True,\n",
    "                return_tensors=\"pt\",\n",
    "            )\n",
    "            return {\n",
    "                \"input_ids\": tokens[\"input_ids\"][0].to(dtype=self.tensor_dtype[0]),\n",
    "                \"attention_mask\": tokens[\"attention_mask\"][0].to(dtype=self.tensor_dtype[1]),\n",
    "            }\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Dict[str, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Возвращает токенизированные данные.\n",
    "\n",
    "        Args:\n",
    "            idx (int): Индекс примера.\n",
    "\n",
    "        Returns:\n",
    "            Dict[str, torch.Tensor]: Словарь с токенами из двух колонок.\n",
    "        \"\"\"\n",
    "        row = self.dataframe.iloc[idx]\n",
    "\n",
    "        text_tokens = self._tokenize_text(row[self.text_column])\n",
    "\n",
    "        link_text_tokens = self._tokenize_text(row[self.link_text_column])\n",
    "\n",
    "        return {\n",
    "            \"input_ids_text\": text_tokens[\"input_ids\"],\n",
    "            \"attention_mask_text\": text_tokens[\"attention_mask\"],\n",
    "            \"input_ids_link\": link_text_tokens[\"input_ids\"],\n",
    "            \"attention_mask_link\": link_text_tokens[\"attention_mask\"],\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer\n",
    "\n",
    "tokenizer: RobertaTokenizer = RobertaTokenizer.from_pretrained(DATA_PATH_SAVE_MODELS / MODEL_NAME)\n",
    "\n",
    "dataset = TokenizedDataset(data_df, tokenizer, MAX_LENGTH, text_column='text', link_text_column='link_text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids_text': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'attention_mask_text': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'input_ids_link': tensor([    0, 34141, 39941,   231,    12,   180,    12,   279,    19, 19258,\n",
       "         29048, 19961, 29382, 13410,  6247, 43814,    12,  1646,     2,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1]),\n",
       " 'attention_mask_link': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0])}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import RobertaForSequenceClassification, RobertaTokenizer\n",
    "\n",
    "model = RobertaForSequenceClassification.from_pretrained(\n",
    "    DATA_PATH_SAVE_MODELS / MODEL_NAME)\n",
    "\n",
    "model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тестирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def test_model_on_dataset(\n",
    "    model: torch.nn.Module,\n",
    "    dataset: TokenizedDataset,\n",
    "    idx2label: dict,\n",
    "    batch_size: int = 16,\n",
    "    device: torch.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Прогоняет датасет через модель и добавляет предсказания в DataFrame.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): Обученная модель.\n",
    "        dataset (Dataset): Токенизированный датасет.\n",
    "        idx2label (dict): Словарь, отображающий индексы категорий в названия.\n",
    "        batch_size (int): Размер батча для DataLoader.\n",
    "        device (torch.device): Устройство для вычислений (CPU/GPU).\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame с добавленными предсказаниями:\n",
    "            - 'predict_1': предсказанная метка для основной колонки,\n",
    "            - 'probability_1': вероятность предсказания для основной колонки,\n",
    "            - 'predict_2': предсказанная метка для дополнительной колонки,\n",
    "            - 'probability_2': вероятность предсказания для дополнительной колонки.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    # Создаём DataLoader\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    test_df = dataset.dataframe.copy()\n",
    "\n",
    "    # Списки для хранения предсказаний\n",
    "    predictions_1, probabilities_1 = [], []\n",
    "    predictions_2, probabilities_2 = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Processing\"):\n",
    "            batch_size_current = batch[\"input_ids_text\"].shape[0]\n",
    "\n",
    "            # Обрабатываем основную колонку (text)\n",
    "            input_ids_text = batch[\"input_ids_text\"].to(device)\n",
    "            attention_mask_text = batch[\"attention_mask_text\"].to(device)\n",
    "\n",
    "            text_has_content = [torch.any(input_ids_text[i] != 0).item() for i in range(batch_size_current)]\n",
    "            if any(text_has_content):  # Если хотя бы в одном есть текст\n",
    "                logits = model(input_ids=input_ids_text, attention_mask=attention_mask_text).logits\n",
    "                probs = torch.softmax(logits, dim=-1).cpu().numpy()\n",
    "                preds = torch.argmax(logits, dim=-1).cpu().numpy()\n",
    "\n",
    "                for i in range(batch_size_current):\n",
    "                    if text_has_content[i]:\n",
    "                        predictions_1.append(preds[i])\n",
    "                        probabilities_1.append(probs[i].tolist())\n",
    "                    else:\n",
    "                        predictions_1.append(None)\n",
    "                        probabilities_1.append(None)\n",
    "            else:\n",
    "                predictions_1.extend([None] * batch_size_current)\n",
    "                probabilities_1.extend([None] * batch_size_current)\n",
    "\n",
    "            # Обрабатываем дополнительную колонку (link_text)\n",
    "            input_ids_link = batch[\"input_ids_link\"].to(device)\n",
    "            attention_mask_link = batch[\"attention_mask_link\"].to(device)\n",
    "\n",
    "            link_text_has_content = [torch.any(input_ids_link[i] != 0).item() for i in range(batch_size_current)]\n",
    "            if any(link_text_has_content):  # Если хотя бы в одном есть текст\n",
    "                logits = model(input_ids=input_ids_link, attention_mask=attention_mask_link).logits\n",
    "                probs = torch.softmax(logits, dim=-1).cpu().numpy()\n",
    "                preds = torch.argmax(logits, dim=-1).cpu().numpy()\n",
    "\n",
    "                for i in range(batch_size_current):\n",
    "                    if link_text_has_content[i]:\n",
    "                        predictions_2.append(preds[i])\n",
    "                        probabilities_2.append(probs[i].tolist())\n",
    "                    else:\n",
    "                        predictions_2.append(None)\n",
    "                        probabilities_2.append(None)\n",
    "            else:\n",
    "                predictions_2.extend([None] * batch_size_current)\n",
    "                probabilities_2.extend([None] * batch_size_current)\n",
    "\n",
    "    # Преобразуем предсказания в DataFrame\n",
    "    test_df = test_df.reset_index(drop=True)\n",
    "    test_df[\"predict_1\"] = [idx2label[p] if p is not None else None for p in predictions_1]\n",
    "    test_df[\"probability_1\"] = probabilities_1\n",
    "    test_df[\"predict_2\"] = [idx2label[p] if p is not None else None for p in predictions_2]\n",
    "    test_df[\"probability_2\"] = probabilities_2\n",
    "\n",
    "    return test_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf6f6dd7ac5543b0aaaf84f60dcf6073",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing:   0%|          | 0/108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_results_df = test_model_on_dataset(\n",
    "    model=model,\n",
    "    dataset=dataset,\n",
    "    idx2label=idx2label,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Group Name</th>\n",
       "      <th>User Name</th>\n",
       "      <th>Facebook Id</th>\n",
       "      <th>Page Category</th>\n",
       "      <th>Page Admin Top Country</th>\n",
       "      <th>Page Description</th>\n",
       "      <th>Page Created</th>\n",
       "      <th>Likes at Posting</th>\n",
       "      <th>Followers at Posting</th>\n",
       "      <th>Post Created</th>\n",
       "      <th>...</th>\n",
       "      <th>Sponsor Id</th>\n",
       "      <th>Sponsor Name</th>\n",
       "      <th>Sponsor Category</th>\n",
       "      <th>Overperforming Score (weighted  —  Likes 1x Shares 1x Comments 1x Love 1x Wow 1x Haha 1x Sad 1x Angry 1x Care 1x )</th>\n",
       "      <th>text</th>\n",
       "      <th>link_text</th>\n",
       "      <th>predict_1</th>\n",
       "      <th>probability_1</th>\n",
       "      <th>predict_2</th>\n",
       "      <th>probability_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1312</th>\n",
       "      <td>COVID19: Real Talk from Health Care Workers around the Globe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1073058046385811</td>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>109718.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-08-03 15:20:48 EDT</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4449</th>\n",
       "      <td>Protect Essential Workers - Global Coronavirus Action</td>\n",
       "      <td>NaN</td>\n",
       "      <td>641756303052335</td>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-04-20 13:20:08 EDT</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.42</td>\n",
       "      <td>We are launching a global day of action on April 28. Too many of our colleagues, our friends and families, have already paid the ultimate price for the failures of our governments and employers around the world. Health workers are on the frontlines without, or with inadequate, Personal Protective Equipment or testing. Care workers are turning away from older people to sneeze. It's the only protection they both have. Non-essential work in construction, the service sector and industry undermin...</td>\n",
       "      <td>Coronavirus Global Day of Action We are calling on workers everywhere to join our global day of action for safety and security. This Workers Memorial Day - 28 April 2020 - our slogan means more than ever. Add your action to our map today.</td>\n",
       "      <td>Real</td>\n",
       "      <td>[0.6934360265731812, 0.30656397342681885]</td>\n",
       "      <td>Real</td>\n",
       "      <td>[0.9977990984916687, 0.002200827933847904]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4744</th>\n",
       "      <td>COVID19: Real Talk from Health Care Workers around the Globe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1073058046385811</td>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>107665.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-12-24 18:32:31 EST</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.33</td>\n",
       "      <td>Does anyone know what happens if say, we get the first shot and then decide to back out of the second? Basically like getting no shot at all? Just curious...it's the second one that makes me nervous with my brain/gut disorder (cvs).</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fake</td>\n",
       "      <td>[0.00819011777639389, 0.9918099045753479]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2109</th>\n",
       "      <td>COVID19: Real Talk from Health Care Workers around the Globe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1073058046385811</td>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12548.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-03-23 18:54:57 EDT</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>COVID19: Real Talk from Health Care Workers around the Globe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1073058046385811</td>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>110166.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-07-15 08:10:13 EDT</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.58</td>\n",
       "      <td>NaN</td>\n",
       "      <td>France to give $9 billion in pay raises to health care workers</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Fake</td>\n",
       "      <td>[0.35708892345428467, 0.6429110169410706]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1939</th>\n",
       "      <td>COVID19: Real Talk from Health Care Workers around the Globe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1073058046385811</td>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>107457.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-02-15 18:33:37 EST</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.47</td>\n",
       "      <td>8,400 vaccines redistributed when Texas power outage cut energy to vaccine freezers and back-up generator failed.. https://www.consumerreports.org/home-maintenance-repairs/how-to-keep-pipes-from-freezing/ 24 of 50 states are being affected by these weather systems.. 3 million Texans in power outage. They are purposefully turning portions of grid off to prevent further outage. Watching the weather issues across the mid-west from New York. My own home state of Minnesota was between -35 to -45 ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Real</td>\n",
       "      <td>[0.9755354523658752, 0.024464568123221397]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3844</th>\n",
       "      <td>COVID19: Real Talk from Health Care Workers around the Globe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1073058046385811</td>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>107781.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-11 11:23:35 EST</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.69</td>\n",
       "      <td>Got my 2nd dose, Pfizer, on Sat. @ 10 am. By 8 pm had some nausea, sore arm, back pain and low grade fever. Over the next 24 hrs: same plus chills and sweats. But woke up today and everything is resolved. Good luck team!!!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fake</td>\n",
       "      <td>[0.11500360816717148, 0.8849963545799255]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5587</th>\n",
       "      <td>Covid19 Real Stories by Frontline and Affected People</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3938079882870550</td>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4211.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-07-04 12:50:32 EDT</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Scientists say WHO ignores the risk that coronavirus floats in air as aerosol More than 200 researchers worldwide sign an open letter saying current guidance ignores evidence that the coronavirus readily spreads on microscopic particles known as aerosols that can hang in the air for long periods and float dozens of feet.</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Fake</td>\n",
       "      <td>[0.4271196126937866, 0.5728803277015686]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2571</th>\n",
       "      <td>COVID19: Real Talk from Health Care Workers around the Globe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1073058046385811</td>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>110397.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-06-22 21:24:07 EDT</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.59</td>\n",
       "      <td>I work in a small hospital outside Houston. We test about 150+ a day. The positive numbers are definitely going up. But I'm noticing the symptoms are less severe among our positives.Is anyone noticing the same thing?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Real</td>\n",
       "      <td>[0.9826356172561646, 0.0173643846064806]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3117</th>\n",
       "      <td>COVID19: Real Talk from Health Care Workers around the Globe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1073058046385811</td>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>109897.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-04-28 01:25:52 EDT</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>New York State Nurses Association Crisis standards ≠ scientific standards. This pandemic is no excuse to prop up unproven methods for cleaning disposable respirators. Read our COVID-19 Protection Bulletin on the dangers of \"cleaning\" and reusing N95 respirators: bit.ly/noPPEreuse ⚠️</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Real</td>\n",
       "      <td>[0.5847894549369812, 0.4152105748653412]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        Group Name  User Name  \\\n",
       "1312  COVID19: Real Talk from Health Care Workers around the Globe        NaN   \n",
       "4449         Protect Essential Workers - Global Coronavirus Action        NaN   \n",
       "4744  COVID19: Real Talk from Health Care Workers around the Globe        NaN   \n",
       "2109  COVID19: Real Talk from Health Care Workers around the Globe        NaN   \n",
       "60    COVID19: Real Talk from Health Care Workers around the Globe        NaN   \n",
       "1939  COVID19: Real Talk from Health Care Workers around the Globe        NaN   \n",
       "3844  COVID19: Real Talk from Health Care Workers around the Globe        NaN   \n",
       "5587         Covid19 Real Stories by Frontline and Affected People        NaN   \n",
       "2571  COVID19: Real Talk from Health Care Workers around the Globe        NaN   \n",
       "3117  COVID19: Real Talk from Health Care Workers around the Globe        NaN   \n",
       "\n",
       "           Facebook Id Page Category  Page Admin Top Country  \\\n",
       "1312  1073058046385811          none                     NaN   \n",
       "4449   641756303052335          none                     NaN   \n",
       "4744  1073058046385811          none                     NaN   \n",
       "2109  1073058046385811          none                     NaN   \n",
       "60    1073058046385811          none                     NaN   \n",
       "1939  1073058046385811          none                     NaN   \n",
       "3844  1073058046385811          none                     NaN   \n",
       "5587  3938079882870550          none                     NaN   \n",
       "2571  1073058046385811          none                     NaN   \n",
       "3117  1073058046385811          none                     NaN   \n",
       "\n",
       "      Page Description  Page Created  Likes at Posting  Followers at Posting  \\\n",
       "1312               NaN           NaN          109718.0                   NaN   \n",
       "4449               NaN           NaN               NaN                   NaN   \n",
       "4744               NaN           NaN          107665.0                   NaN   \n",
       "2109               NaN           NaN           12548.0                   NaN   \n",
       "60                 NaN           NaN          110166.0                   NaN   \n",
       "1939               NaN           NaN          107457.0                   NaN   \n",
       "3844               NaN           NaN          107781.0                   NaN   \n",
       "5587               NaN           NaN            4211.0                   NaN   \n",
       "2571               NaN           NaN          110397.0                   NaN   \n",
       "3117               NaN           NaN          109897.0                   NaN   \n",
       "\n",
       "                 Post Created  ... Sponsor Id Sponsor Name Sponsor Category  \\\n",
       "1312  2020-08-03 15:20:48 EDT  ...        NaN          NaN              NaN   \n",
       "4449  2020-04-20 13:20:08 EDT  ...        NaN          NaN              NaN   \n",
       "4744  2020-12-24 18:32:31 EST  ...        NaN          NaN              NaN   \n",
       "2109  2020-03-23 18:54:57 EDT  ...        NaN          NaN              NaN   \n",
       "60    2020-07-15 08:10:13 EDT  ...        NaN          NaN              NaN   \n",
       "1939  2021-02-15 18:33:37 EST  ...        NaN          NaN              NaN   \n",
       "3844  2021-01-11 11:23:35 EST  ...        NaN          NaN              NaN   \n",
       "5587  2020-07-04 12:50:32 EDT  ...        NaN          NaN              NaN   \n",
       "2571  2020-06-22 21:24:07 EDT  ...        NaN          NaN              NaN   \n",
       "3117  2020-04-28 01:25:52 EDT  ...        NaN          NaN              NaN   \n",
       "\n",
       "      Overperforming Score (weighted  —  Likes 1x Shares 1x Comments 1x Love 1x Wow 1x Haha 1x Sad 1x Angry 1x Care 1x )  \\\n",
       "1312                                                                                                                5.08   \n",
       "4449                                                                                                                1.42   \n",
       "4744                                                                                                                1.33   \n",
       "2109                                                                                                                3.17   \n",
       "60                                                                                                                 46.58   \n",
       "1939                                                                                                                3.47   \n",
       "3844                                                                                                                1.69   \n",
       "5587                                                                                                                1.10   \n",
       "2571                                                                                                                2.59   \n",
       "3117                                                                                                                2.12   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     text  \\\n",
       "1312                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  NaN   \n",
       "4449  We are launching a global day of action on April 28. Too many of our colleagues, our friends and families, have already paid the ultimate price for the failures of our governments and employers around the world. Health workers are on the frontlines without, or with inadequate, Personal Protective Equipment or testing. Care workers are turning away from older people to sneeze. It's the only protection they both have. Non-essential work in construction, the service sector and industry undermin...   \n",
       "4744                                                                                                                                                                                                                                                                             Does anyone know what happens if say, we get the first shot and then decide to back out of the second? Basically like getting no shot at all? Just curious...it's the second one that makes me nervous with my brain/gut disorder (cvs).   \n",
       "2109                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  NaN   \n",
       "60                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    NaN   \n",
       "1939  8,400 vaccines redistributed when Texas power outage cut energy to vaccine freezers and back-up generator failed.. https://www.consumerreports.org/home-maintenance-repairs/how-to-keep-pipes-from-freezing/ 24 of 50 states are being affected by these weather systems.. 3 million Texans in power outage. They are purposefully turning portions of grid off to prevent further outage. Watching the weather issues across the mid-west from New York. My own home state of Minnesota was between -35 to -45 ...   \n",
       "3844                                                                                                                                                                                                                                                                                       Got my 2nd dose, Pfizer, on Sat. @ 10 am. By 8 pm had some nausea, sore arm, back pain and low grade fever. Over the next 24 hrs: same plus chills and sweats. But woke up today and everything is resolved. Good luck team!!!   \n",
       "5587                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  NaN   \n",
       "2571                                                                                                                                                                                                                                                                                             I work in a small hospital outside Houston. We test about 150+ a day. The positive numbers are definitely going up. But I'm noticing the symptoms are less severe among our positives.Is anyone noticing the same thing?   \n",
       "3117                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  NaN   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                               link_text  \\\n",
       "1312                                                                                                                                                                                                                                                                                                                                 NaN   \n",
       "4449                                                                                      Coronavirus Global Day of Action We are calling on workers everywhere to join our global day of action for safety and security. This Workers Memorial Day - 28 April 2020 - our slogan means more than ever. Add your action to our map today.   \n",
       "4744                                                                                                                                                                                                                                                                                                                                 NaN   \n",
       "2109                                                                                                                                                                                                                                                                                                                                 NaN   \n",
       "60                                                                                                                                                                                                                                                                        France to give $9 billion in pay raises to health care workers   \n",
       "1939                                                                                                                                                                                                                                                                                                                                 NaN   \n",
       "3844                                                                                                                                                                                                                                                                                                                                 NaN   \n",
       "5587  Scientists say WHO ignores the risk that coronavirus floats in air as aerosol More than 200 researchers worldwide sign an open letter saying current guidance ignores evidence that the coronavirus readily spreads on microscopic particles known as aerosols that can hang in the air for long periods and float dozens of feet.   \n",
       "2571                                                                                                                                                                                                                                                                                                                                 NaN   \n",
       "3117                                         New York State Nurses Association Crisis standards ≠ scientific standards. This pandemic is no excuse to prop up unproven methods for cleaning disposable respirators. Read our COVID-19 Protection Bulletin on the dangers of \"cleaning\" and reusing N95 respirators: bit.ly/noPPEreuse ⚠️   \n",
       "\n",
       "      predict_1                               probability_1  predict_2  \\\n",
       "1312       None                                        None       None   \n",
       "4449       Real   [0.6934360265731812, 0.30656397342681885]       Real   \n",
       "4744       Fake   [0.00819011777639389, 0.9918099045753479]       None   \n",
       "2109       None                                        None       None   \n",
       "60         None                                        None       Fake   \n",
       "1939       Real  [0.9755354523658752, 0.024464568123221397]       None   \n",
       "3844       Fake   [0.11500360816717148, 0.8849963545799255]       None   \n",
       "5587       None                                        None       Fake   \n",
       "2571       Real    [0.9826356172561646, 0.0173643846064806]       None   \n",
       "3117       None                                        None       Real   \n",
       "\n",
       "                                   probability_2  \n",
       "1312                                        None  \n",
       "4449  [0.9977990984916687, 0.002200827933847904]  \n",
       "4744                                        None  \n",
       "2109                                        None  \n",
       "60     [0.35708892345428467, 0.6429110169410706]  \n",
       "1939                                        None  \n",
       "3844                                        None  \n",
       "5587    [0.4271196126937866, 0.5728803277015686]  \n",
       "2571                                        None  \n",
       "3117    [0.5847894549369812, 0.4152105748653412]  \n",
       "\n",
       "[10 rows x 46 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results_df.to_excel(DATA_PATH / 'facebook_data_to_complate.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
