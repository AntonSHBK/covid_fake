{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cpu'\n",
    "if torch.backends.mps.is_available():\n",
    "    DEVICE = 'mps'\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "DATA_PATH = Path('data/')\n",
    "DATA_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "DATA_CACHE = Path('data/cache_dir/')\n",
    "DATA_CACHE.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "DATA_PATH_SAVE_MODELS = Path('data/models/')\n",
    "DATA_PATH_SAVE_MODELS.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "pd.set_option('display.max_colwidth', 500) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"covid_vaccine_fake_model\"\n",
    "TEST_DF_NAME = \"facebook_data_to_complate.xlsx\"\n",
    "\n",
    "MAX_LENGTH = 128\n",
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_excel(DATA_PATH / TEST_DF_NAME).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = data_df.dropna(how='all')\n",
    "data_df['text'] = data_df['text'].astype(str)\n",
    "data_df = data_df.dropna(subset='predict_1')\n",
    "data_df[\"truncated_text\"] = data_df[\"text\"].str[:200]\n",
    "data_df[\"id\"] = data_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2label = {\n",
    "    0: \"Real\",\n",
    "    1: \"Fake\",\n",
    "    2: \"Comments\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer\n",
    "\n",
    "tokenizer: RobertaTokenizer = RobertaTokenizer.from_pretrained(DATA_PATH_SAVE_MODELS / MODEL_NAME, cache_dir=DATA_CACHE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaModel\n",
    "\n",
    "model = RobertaModel.from_pretrained(\n",
    "    DATA_PATH_SAVE_MODELS / MODEL_NAME, cache_dir=DATA_CACHE)\n",
    "\n",
    "model.to(DEVICE)\n",
    "model.eval()\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from typing import List\n",
    "from tqdm import tqdm\n",
    "\n",
    "def add_text_embeddings(\n",
    "    texts: List[str], \n",
    "    strategy: str = \"cls\",\n",
    "    max_length: int = 128, \n",
    "    batch_size: int = 64\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Генерирует эмбеддинги для списка текстов.\n",
    "\n",
    "    Параметры:\n",
    "    - texts: список текстов для обработки.\n",
    "    - strategy: метод усреднения токенов (\"mean\", \"cls\", \"max\", \"sum\").\n",
    "    - max_length: максимальная длина токенов.\n",
    "    - batch_size: размер батча для обработки.\n",
    "\n",
    "    Возвращает:\n",
    "    - Массив NumPy с эмбеддингами (shape: [num_texts, embedding_dim]).\n",
    "    \"\"\"\n",
    "    embeddings = []\n",
    "\n",
    "    for i in tqdm(range(0, len(texts), batch_size), desc=\"Processing batches\"):\n",
    "        inputs = tokenizer(\n",
    "            texts[i:i + batch_size], padding=True, truncation=True, \n",
    "            max_length=max_length, return_tensors=\"pt\"\n",
    "        )\n",
    "        inputs.to(DEVICE)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        \n",
    "        hidden_states = outputs.last_hidden_state\n",
    "\n",
    "        if strategy == \"mean\":\n",
    "            batch_embeddings = hidden_states.mean(dim=1)\n",
    "        elif strategy == \"cls\":\n",
    "            batch_embeddings = hidden_states[:, 0, :]\n",
    "        elif strategy == \"max\":\n",
    "            batch_embeddings, _ = hidden_states.max(dim=1)\n",
    "        elif strategy == \"sum\":\n",
    "            batch_embeddings = hidden_states.sum(dim=1)\n",
    "        else:\n",
    "            raise ValueError(\"Некорректная стратегия. Выберите из ['mean', 'cls', 'max', 'sum'].\")\n",
    "        embeddings.append(batch_embeddings.cpu().numpy())\n",
    "    return np.vstack(embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = add_text_embeddings(data_df['text'].to_list(), strategy=\"cls\", max_length=MAX_LENGTH, batch_size=BATCH_SIZE)\n",
    "import pickle\n",
    "\n",
    "with open(DATA_PATH / 'facebook_embeddings.pkl', 'wb') as f:\n",
    "    pickle.dump(embeddings, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(DATA_PATH / 'facebook_embeddings.pkl', 'rb') as f:\n",
    "    embeddings = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import umap\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from typing import Literal, Optional\n",
    "from scipy.spatial import cKDTree\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "\n",
    "# Dictionary to map indices to label names\n",
    "idx2label = {\n",
    "    0: \"Real\",\n",
    "    1: \"Fake\",\n",
    "    2: \"Comments\"\n",
    "}\n",
    "\n",
    "# Dictionary to map label names to indices\n",
    "label2idx = {v: k for k, v in idx2label.items()}\n",
    "\n",
    "class EmbeddingVisualizer:\n",
    "    def __init__(self, embeddings: np.ndarray, data_df: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        A universal class for dimensionality reduction of embeddings and visualization.\n",
    "\n",
    "        :param embeddings: Array of embeddings (shape: [num_samples, embedding_dim])\n",
    "        :param data_df: DataFrame with additional data (e.g., text, predict_1, id)\n",
    "        \"\"\"\n",
    "        self.embeddings = embeddings\n",
    "        self.data_df = data_df.copy()\n",
    "        self.reduced_embeddings = None\n",
    "    \n",
    "    def reduce_dimensionality(self, method: Literal[\"pca\", \"tsne\", \"umap\"], n_components: int = 2):\n",
    "        \"\"\"\n",
    "        Reduces the dimensionality of the embeddings using the specified method.\n",
    "        \n",
    "        :param method: Dimensionality reduction method ('pca', 'tsne', 'umap')\n",
    "        :param n_components: Number of target dimensions (2 or 3 for visualization)\n",
    "        \"\"\"\n",
    "        if method == \"pca\":\n",
    "            reducer = PCA(n_components=n_components)\n",
    "        elif method == \"tsne\":\n",
    "            reducer = TSNE(n_components=n_components, perplexity=30, random_state=42)\n",
    "        elif method == \"umap\":\n",
    "            reducer = umap.UMAP(n_components=n_components, random_state=42)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported method. Use 'pca', 'tsne', or 'umap'.\")\n",
    "        \n",
    "        self.reduced_embeddings = reducer.fit_transform(self.embeddings)\n",
    "        for i in range(n_components):\n",
    "            self.data_df[f\"{method}_{i+1}\"] = self.reduced_embeddings[:, i]\n",
    "    \n",
    "    def compute_opacity(self, points: np.ndarray, radius: float = 0.1) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Computes the opacity of points based on their density.\n",
    "        Now, denser points are brighter, and sparse ones are dimmer.\n",
    "        \n",
    "        :param points: Array of coordinates (Nx2 or Nx3)\n",
    "        :param radius: Radius for calculating point density\n",
    "        :return: Array of opacity values (0.3 - 1.0)\n",
    "        \"\"\"\n",
    "        tree = cKDTree(points)\n",
    "        densities = np.array([len(tree.query_ball_point(p, radius)) for p in points])\n",
    "        min_density = np.min(densities)\n",
    "        max_density = np.max(densities)\n",
    "        opacities = 0.3 + (densities - min_density) / (max_density - min_density) * 0.7  # Invert opacity\n",
    "        return np.clip(opacities, 0.3, 1.0)\n",
    "    \n",
    "    def visualize(self, method: Literal[\"pca\", \"tsne\", \"umap\"], n_components: int = 2, title: str = \"Embedding Visualization\", label2idx=label2idx):\n",
    "        \"\"\"\n",
    "        Visualizes the reduced embeddings with interactive points in Plotly.\n",
    "        \n",
    "        :param method: Method used for dimensionality reduction ('pca', 'tsne', 'umap')\n",
    "        :param n_components: Visualization dimensionality (2D or 3D)\n",
    "        :param title: Plot title\n",
    "        \"\"\"\n",
    "        if self.reduced_embeddings is None or f\"{method}_1\" not in self.data_df.columns:\n",
    "            raise ValueError(\"Call reduce_dimensionality() first.\")\n",
    "        \n",
    "        self.data_df[\"predict_idx\"] = self.data_df[\"predict_1\"].map(label2idx)  # Map prediction labels to indices\n",
    "        coords = self.reduced_embeddings[:, :n_components]  # Get reduced coordinates for plotting\n",
    "        opacities = self.compute_opacity(coords)  # Compute opacities based on density\n",
    "        \n",
    "        # Color mapping for different labels\n",
    "        color_mapping = {0: \"blue\", 1: \"red\", 2: \"green\"}\n",
    "        \n",
    "        fig = go.Figure()\n",
    "        \n",
    "        if n_components == 2:\n",
    "            # Plot 2D scatter plot\n",
    "            for idx, label in idx2label.items():\n",
    "                subset = self.data_df[self.data_df[\"predict_idx\"] == idx]  # Get subset for each label\n",
    "                opacity_subset = opacities[self.data_df[\"predict_idx\"] == idx]\n",
    "\n",
    "                fig.add_trace(go.Scatter(\n",
    "                    x=subset[f\"{method}_1\"],\n",
    "                    y=subset[f\"{method}_2\"],\n",
    "                    mode=\"markers\",\n",
    "                    marker=dict(\n",
    "                        size=8,\n",
    "                        color=color_mapping[idx],\n",
    "                        opacity=opacity_subset,\n",
    "                    ),\n",
    "                    name=f\"{label}\",\n",
    "                    customdata=subset[[\"truncated_text\", \"id\", \"predict_1\", \"entropy_1\", \"entropy_threshold_1\", \"passed_threshold_1\"]],\n",
    "                    hovertemplate=(\n",
    "                        \"<b>Text:</b> %{customdata[0]}<br>\" \n",
    "                        \"<b>ID:</b> %{customdata[1]}<br>\"\n",
    "                        \"<b>Predict:</b> %{customdata[2]}<br>\"\n",
    "                        \"<b>Entropy:</b> %{customdata[3]}<br>\"\n",
    "                        \"<b>Entropy threshold:</b> %{customdata[4]}<br>\"\n",
    "                        \"<b>Passed threshold:</b> %{customdata[5]}\"\n",
    "                    )\n",
    "                ))\n",
    "        else:\n",
    "            # Plot 3D scatter plot\n",
    "            for idx, label in idx2label.items():\n",
    "                subset = self.data_df[self.data_df[\"predict_idx\"] == idx]\n",
    "\n",
    "                fig.add_trace(go.Scatter3d(\n",
    "                    x=subset[f\"{method}_1\"],\n",
    "                    y=subset[f\"{method}_2\"],\n",
    "                    z=subset[f\"{method}_3\"],\n",
    "                    mode=\"markers\",\n",
    "                    marker=dict(\n",
    "                        size=5,\n",
    "                        color=color_mapping[idx]\n",
    "                    ),\n",
    "                    name=f\"{label}\",\n",
    "                    customdata=subset[[\"truncated_text\", \"id\", \"predict_1\", \"entropy_1\", \"entropy_threshold_1\", \"passed_threshold_1\"]],\n",
    "                    hovertemplate=(\n",
    "                        \"<b>Text:</b> %{customdata[0]}<br>\" \n",
    "                        \"<b>ID:</b> %{customdata[1]}<br>\"\n",
    "                        \"<b>Predict:</b> %{customdata[2]}<br>\"\n",
    "                        \"<b>Entropy:</b> %{customdata[3]}<br>\"\n",
    "                        \"<b>Entropy threshold:</b> %{customdata[4]}<br>\"\n",
    "                        \"<b>Passed threshold:</b> %{customdata[5]}\"\n",
    "                    )\n",
    "                ))\n",
    "        \n",
    "        # Update layout for 2D visualization\n",
    "        fig.update_layout(\n",
    "            title=title,\n",
    "            xaxis=dict(\n",
    "                title=f\"{method.upper()} 1 →\",  # Add arrow\n",
    "                showline=True,  # Add border\n",
    "                linewidth=2,\n",
    "                linecolor=\"black\",\n",
    "                mirror=True,  # Border around the entire plot area\n",
    "                gridcolor=\"lightgray\",\n",
    "                gridwidth=0.5,  # Thinner grid\n",
    "                zeroline=True,  # X axis goes through 0\n",
    "                zerolinecolor=\"black\",\n",
    "                zerolinewidth=1.2\n",
    "            ),\n",
    "            yaxis=dict(\n",
    "                title=f\"{method.upper()} 2 →\",  # Add arrow\n",
    "                showline=True,\n",
    "                linewidth=2,\n",
    "                linecolor=\"black\",\n",
    "                mirror=True,\n",
    "                gridcolor=\"lightgray\",\n",
    "                gridwidth=0.5,\n",
    "                zeroline=True,  # Y axis goes through 0\n",
    "                zerolinecolor=\"black\",\n",
    "                zerolinewidth=1.2\n",
    "            ),\n",
    "            template=\"plotly_white\",\n",
    "            width=1400,\n",
    "            height=1000,\n",
    "            legend_title=\"Class Labels\"\n",
    "        )\n",
    "\n",
    "        # Update layout for 3D visualization\n",
    "        if n_components == 3:\n",
    "            fig.update_layout(scene=dict(\n",
    "                xaxis=dict(\n",
    "                    title=f\"{method.upper()} 1 →\",  # Add arrow\n",
    "                    showline=True,\n",
    "                    linewidth=2,\n",
    "                    linecolor=\"black\",\n",
    "                    mirror=True,\n",
    "                    gridcolor=\"lightgray\",\n",
    "                    gridwidth=0.5\n",
    "                ),\n",
    "                yaxis=dict(\n",
    "                    title=f\"{method.upper()} 2 →\",  # Add arrow\n",
    "                    showline=True,\n",
    "                    linewidth=2,\n",
    "                    linecolor=\"black\",\n",
    "                    mirror=True,\n",
    "                    gridcolor=\"lightgray\",\n",
    "                    gridwidth=0.5\n",
    "                ),\n",
    "                zaxis=dict(\n",
    "                    title=f\"{method.upper()} 3 →\",  # Add arrow\n",
    "                    showline=True,\n",
    "                    linewidth=2,\n",
    "                    linecolor=\"black\",\n",
    "                    mirror=True,\n",
    "                    gridcolor=\"lightgray\",\n",
    "                    gridwidth=0.5\n",
    "                )\n",
    "            ))\n",
    "\n",
    "        # Display the plot\n",
    "        fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer = EmbeddingVisualizer(embeddings, data_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "visualizer.reduce_dimensionality(\"pca\", n_components=2)\n",
    "visualizer.visualize(\"pca\", n_components=2, title=\"PCA 2D Visualization\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizer.reduce_dimensionality(\"pca\", n_components=3)\n",
    "# visualizer.visualize(\"pca\", n_components=3, title=\"PCA 3D Visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TSNE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "visualizer.reduce_dimensionality(\"tsne\", n_components=2)\n",
    "visualizer.visualize(\"tsne\", n_components=2, title=\"t-SNE 2D Visualization\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizer.reduce_dimensionality(\"tsne\", n_components=3)\n",
    "# visualizer.visualize(\"tsne\", n_components=3, title=\"t-SNE 3D Visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer.reduce_dimensionality(\"umap\", n_components=2)\n",
    "visualizer.visualize(\"umap\", n_components=2, title=\"UMAP 2D Visualization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizer.reduce_dimensionality(\"umap\", n_components=3)\n",
    "# visualizer.visualize(\"umap\", n_components=3, title=\"UMAP 3D Visualization\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
