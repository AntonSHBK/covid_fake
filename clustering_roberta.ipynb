{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cpu'\n",
    "if torch.backends.mps.is_available():\n",
    "    DEVICE = 'mps'\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "DATA_PATH = Path('data/')\n",
    "DATA_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "DATA_CACHE = Path('data/cache_dir/')\n",
    "DATA_CACHE.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "DATA_PATH_SAVE_MODELS = Path('data/models/')\n",
    "DATA_PATH_SAVE_MODELS.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "pd.set_option('display.max_colwidth', 500) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"roberta-base\"\n",
    "TEST_DF_NAME = \"facebook_data_to_model.xlsx\"\n",
    "\n",
    "MAX_LENGTH = 128\n",
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_excel(DATA_PATH / TEST_DF_NAME).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = data_df.dropna(how='all')\n",
    "data_df['text'] = data_df['text'].astype(str)\n",
    "data_df = data_df[~data_df['text'].isin([None, 'none', 'nan']) & data_df['text'].notna() & (data_df['text'] != '')]\n",
    "data_df[\"truncated_text\"] = data_df[\"text\"].str[:200]\n",
    "data_df[\"id\"] = data_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_df = data_df.sample(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer\n",
    "\n",
    "tokenizer: RobertaTokenizer = RobertaTokenizer.from_pretrained(MODEL_NAME, cache_dir=DATA_CACHE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaModel\n",
    "\n",
    "model = RobertaModel.from_pretrained(\n",
    "    MODEL_NAME, cache_dir=DATA_CACHE)\n",
    "\n",
    "model.to(DEVICE)\n",
    "model.eval()\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Получение эмбедингов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from typing import List\n",
    "from tqdm import tqdm\n",
    "\n",
    "def add_text_embeddings(\n",
    "    texts: List[str], \n",
    "    strategy: str = \"cls\",\n",
    "    max_length: int = 128, \n",
    "    batch_size: int = 64\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Generates embeddings for a list of texts.\n",
    "\n",
    "    Parameters:\n",
    "    - texts: list of texts to process.\n",
    "    - strategy: token averaging method (\"mean\", \"cls\", \"max\", \"sum\").\n",
    "    - max_length: maximum token length.\n",
    "    - batch_size: batch size for processing.\n",
    "\n",
    "    Returns:\n",
    "    - NumPy array of embeddings (shape: [num_texts, embedding_dim]).\n",
    "    \"\"\"\n",
    "    embeddings = []\n",
    "\n",
    "    for i in tqdm(range(0, len(texts), batch_size), desc=\"Processing batches\"):\n",
    "        inputs = tokenizer(\n",
    "            texts[i:i + batch_size], padding=True, truncation=True, \n",
    "            max_length=max_length, return_tensors=\"pt\"\n",
    "        )\n",
    "        inputs.to(DEVICE)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        \n",
    "        hidden_states = outputs.last_hidden_state\n",
    "\n",
    "        if strategy == \"mean\":\n",
    "            batch_embeddings = hidden_states.mean(dim=1)\n",
    "        elif strategy == \"cls\":\n",
    "            batch_embeddings = hidden_states[:, 0, :]\n",
    "        elif strategy == \"max\":\n",
    "            batch_embeddings, _ = hidden_states.max(dim=1)\n",
    "        elif strategy == \"sum\":\n",
    "            batch_embeddings = hidden_states.sum(dim=1)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid strategy. Choose from ['mean', 'cls', 'max', 'sum'].\")\n",
    "        embeddings.append(batch_embeddings.cpu().numpy())\n",
    "    return np.vstack(embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = add_text_embeddings(data_df['text'].to_list(), strategy=\"cls\", max_length=MAX_LENGTH, batch_size=BATCH_SIZE)\n",
    "import pickle\n",
    "\n",
    "with open(DATA_PATH / 'facebook_embeddings.pkl', 'wb') as f:\n",
    "    pickle.dump(embeddings, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(DATA_PATH / 'facebook_embeddings.pkl', 'rb') as f:\n",
    "    embeddings = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import umap\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering, SpectralClustering\n",
    "from typing import Literal, Optional, Dict, Any\n",
    "from scipy.spatial import cKDTree\n",
    "\n",
    "\n",
    "class EmbeddingVisualizer:\n",
    "    def __init__(self, embeddings: np.ndarray, data_df: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        A universal class for dimensionality reduction of embeddings and visualization.\n",
    "\n",
    "        :param embeddings: Embedding array (shape: [num_samples, embedding_dim])\n",
    "        :param data_df: DataFrame with additional data (e.g., text, predict_1, id)\n",
    "        \"\"\"\n",
    "        self.embeddings = embeddings\n",
    "        self.data_df = data_df.copy()\n",
    "        self.reduced_embeddings = None\n",
    "        self.cluster_labels = None\n",
    "    \n",
    "    def reduce_dimensionality(self, method: Literal[\"pca\", \"tsne\", \"umap\"], n_components: int = 2):\n",
    "        \"\"\"\n",
    "        Reduces the dimensionality of the embeddings using the specified method.\n",
    "        \n",
    "        :param method: Dimensionality reduction method ('pca', 'tsne', 'umap')\n",
    "        :param n_components: Number of target dimensions (2 or 3 for visualization)\n",
    "        \"\"\"\n",
    "        if method == \"pca\":\n",
    "            reducer = PCA(n_components=n_components)\n",
    "        elif method == \"tsne\":\n",
    "            reducer = TSNE(n_components=n_components, perplexity=30, random_state=42)\n",
    "        elif method == \"umap\":\n",
    "            reducer = umap.UMAP(n_components=n_components, random_state=42)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported method. Use 'pca', 'tsne', or 'umap'.\")\n",
    "        \n",
    "        self.reduced_embeddings = reducer.fit_transform(self.embeddings)\n",
    "        for i in range(n_components):\n",
    "            self.data_df[f\"{method}_{i+1}\"] = self.reduced_embeddings[:, i]\n",
    "    \n",
    "    def cluster_data(self, method: Literal[\"kmeans\", \"dbscan\", \"agglomerative\", \"spectral\"], **kwargs: Dict[str, Any]):\n",
    "        \"\"\"\n",
    "        Applies clustering to the reduced embeddings.\n",
    "\n",
    "        :param method: Clustering method ('kmeans', 'dbscan', 'agglomerative', 'spectral')\n",
    "        :param kwargs: Additional parameters for clustering algorithms\n",
    "        \"\"\"\n",
    "        if self.reduced_embeddings is None:\n",
    "            raise ValueError(\"Run reduce_dimensionality() before clustering.\")\n",
    "\n",
    "        if method == \"kmeans\":\n",
    "            model = KMeans(n_clusters=kwargs.get(\"n_clusters\", 3), random_state=42)\n",
    "        elif method == \"dbscan\":\n",
    "            model = DBSCAN(eps=kwargs.get(\"eps\", 0.5), min_samples=kwargs.get(\"min_samples\", 5))\n",
    "        elif method == \"agglomerative\":\n",
    "            model = AgglomerativeClustering(n_clusters=kwargs.get(\"n_clusters\", 3))\n",
    "        elif method == \"spectral\":\n",
    "            model = SpectralClustering(n_clusters=kwargs.get(\"n_clusters\", 3), random_state=42, assign_labels=\"discretize\")\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported clustering method.\")\n",
    "\n",
    "        self.cluster_labels = model.fit_predict(self.reduced_embeddings)\n",
    "        self.data_df[\"cluster\"] = self.cluster_labels\n",
    "    \n",
    "    def compute_opacity(self, points: np.ndarray, radius: float = 0.1) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Computes the opacity of points based on their density.\n",
    "        Now denser points are brighter, and sparse points are dimmer.\n",
    "        \n",
    "        :param points: Array of coordinates (Nx2 or Nx3)\n",
    "        :param radius: Radius for density calculation of points\n",
    "        :return: Array of opacity values (0.3 - 1.0)\n",
    "        \"\"\"\n",
    "        tree = cKDTree(points)\n",
    "        densities = np.array([len(tree.query_ball_point(p, radius)) for p in points])\n",
    "        min_density = np.min(densities)\n",
    "        max_density = np.max(densities)\n",
    "        opacities = 0.3 + (densities - min_density) / (max_density - min_density) * 0.7  # Inverts opacity\n",
    "        return np.clip(opacities, 0.3, 1.0)\n",
    "    \n",
    "    def visualize(self, method: Literal[\"pca\", \"tsne\", \"umap\"], n_components: int = 2, use_clusters: bool = False, use_opacity: bool = True, title: str = \"Embedding Visualization\"):\n",
    "        \"\"\"\n",
    "        Visualizes the reduced embeddings with interactive points in Plotly.\n",
    "\n",
    "        :param method: Dimensionality reduction method used ('pca', 'tsne', 'umap')\n",
    "        :param n_components: Number of dimensions for visualization (2D or 3D)\n",
    "        :param use_clusters: If True, colors points by cluster labels\n",
    "        :param use_opacity: If True, applies density-based opacity\n",
    "        :param title: Plot title\n",
    "        \"\"\"\n",
    "\n",
    "        if self.reduced_embeddings is None or f\"{method}_1\" not in self.data_df.columns:\n",
    "            raise ValueError(\"Run reduce_dimensionality() first.\")\n",
    "\n",
    "        coords = self.reduced_embeddings[:, :n_components]\n",
    "        opacities = self.compute_opacity(coords) if use_opacity else 1.0\n",
    "\n",
    "        fig = go.Figure()\n",
    "\n",
    "        if n_components == 2:\n",
    "            if use_clusters and self.cluster_labels is not None:\n",
    "                unique_clusters = np.unique(self.cluster_labels)\n",
    "\n",
    "                for cluster in unique_clusters:\n",
    "                    cluster_mask = self.cluster_labels == cluster\n",
    "                    fig.add_trace(go.Scatter(\n",
    "                        x=self.data_df.loc[cluster_mask, f\"{method}_1\"],\n",
    "                        y=self.data_df.loc[cluster_mask, f\"{method}_2\"],\n",
    "                        mode=\"markers\",\n",
    "                        marker=dict(\n",
    "                            size=12,\n",
    "                            opacity=opacities[cluster_mask] if use_opacity else 1.0\n",
    "                        ),\n",
    "                        name=f\"Cluster {cluster}\",\n",
    "                        customdata=self.data_df.loc[cluster_mask, [\"truncated_text\", \"id\"]],\n",
    "                        hovertemplate=(\n",
    "                            \"<b>Text:</b> %{customdata[0]}<br>\"\n",
    "                            \"<b>ID:</b> %{customdata[1]}\"\n",
    "                        )\n",
    "                    ))\n",
    "            else:\n",
    "                # Обычная визуализация (без кластеров)\n",
    "                fig.add_trace(go.Scatter(\n",
    "                    x=self.data_df[f\"{method}_1\"],\n",
    "                    y=self.data_df[f\"{method}_2\"],\n",
    "                    mode=\"markers\",\n",
    "                    marker=dict(\n",
    "                        size=12,\n",
    "                        opacity=opacities if use_opacity else 1.0,\n",
    "                        color=\"blue\"\n",
    "                    ),\n",
    "                    name=\"Post's text\",\n",
    "                    customdata=self.data_df[[\"truncated_text\", \"id\"]],\n",
    "                    hovertemplate=(\n",
    "                        \"<b>Text:</b> %{customdata[0]}<br>\"\n",
    "                        \"<b>ID:</b> %{customdata[1]}\"\n",
    "                    )\n",
    "                ))\n",
    "        else:\n",
    "            if use_clusters and self.cluster_labels is not None:\n",
    "                unique_clusters = np.unique(self.cluster_labels)\n",
    "\n",
    "                for cluster in unique_clusters:\n",
    "                    cluster_mask = self.cluster_labels == cluster\n",
    "                    fig.add_trace(go.Scatter3d(\n",
    "                        x=self.data_df.loc[cluster_mask, f\"{method}_1\"],\n",
    "                        y=self.data_df.loc[cluster_mask, f\"{method}_2\"],\n",
    "                        z=self.data_df.loc[cluster_mask, f\"{method}_3\"],\n",
    "                        mode=\"markers\",\n",
    "                        marker=dict(\n",
    "                            size=5,\n",
    "                            # opacity=opacities[cluster_mask] if use_opacity else 1.0\n",
    "                        ),\n",
    "                        name=f\"Cluster {cluster}\",\n",
    "                        customdata=self.data_df.loc[cluster_mask, [\"truncated_text\", \"id\"]],\n",
    "                        hovertemplate=(\n",
    "                            \"<b>Text:</b> %{customdata[0]}<br>\"\n",
    "                            \"<b>ID:</b> %{customdata[1]}\"\n",
    "                        )\n",
    "                    ))\n",
    "            else:\n",
    "                fig.add_trace(go.Scatter3d(\n",
    "                    x=self.data_df[f\"{method}_1\"],\n",
    "                    y=self.data_df[f\"{method}_2\"],\n",
    "                    z=self.data_df[f\"{method}_3\"],\n",
    "                    mode=\"markers\",\n",
    "                    marker=dict(\n",
    "                        size=5,\n",
    "                        # opacity=opacities if use_opacity else 1.0,\n",
    "                        color=\"blue\"\n",
    "                    ),\n",
    "                    name=\"Post's text\",\n",
    "                    customdata=self.data_df[[\"truncated_text\", \"id\"]],\n",
    "                    hovertemplate=(\n",
    "                        \"<b>Text:</b> %{customdata[0]}<br>\"\n",
    "                        \"<b>ID:</b> %{customdata[1]}\"\n",
    "                    )\n",
    "                ))\n",
    "\n",
    "\n",
    "        fig.update_layout(\n",
    "            title=title,\n",
    "            xaxis=dict(\n",
    "                title=f\"{method.upper()} 1 →\",\n",
    "                showline=True,\n",
    "                linewidth=2,\n",
    "                linecolor=\"black\",\n",
    "                mirror=True,\n",
    "                gridcolor=\"lightgray\",\n",
    "                gridwidth=0.5,\n",
    "                zeroline=True,\n",
    "                zerolinecolor=\"black\",\n",
    "                zerolinewidth=1.2\n",
    "            ),\n",
    "            yaxis=dict(\n",
    "                title=f\"{method.upper()} 2 →\",\n",
    "                showline=True,\n",
    "                linewidth=2,\n",
    "                linecolor=\"black\",\n",
    "                mirror=True,\n",
    "                gridcolor=\"lightgray\",\n",
    "                gridwidth=0.5,\n",
    "                zeroline=True,\n",
    "                zerolinecolor=\"black\",\n",
    "                zerolinewidth=1.2\n",
    "            ),\n",
    "            template=\"plotly_white\",\n",
    "            width=1400,\n",
    "            height=1000,\n",
    "            legend_title=\"Clusters\" if use_clusters else \"Embedding Visualization\"\n",
    "        )\n",
    "\n",
    "        if n_components == 3:\n",
    "            fig.update_layout(scene=dict(\n",
    "                xaxis_title=f\"{method.upper()} 1\",\n",
    "                yaxis_title=f\"{method.upper()} 2\",\n",
    "                zaxis_title=f\"{method.upper()} 3\"\n",
    "            ))\n",
    "\n",
    "        fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Параметры `visualize()`**\n",
    "\n",
    "- **`method: Literal[\"pca\", \"tsne\", \"umap\"]`**  \n",
    "  Метод снижения размерности, который был использован перед визуализацией.  \n",
    "  - `\"pca\"` – Метод главных компонент (быстрый, но линейный).  \n",
    "  - `\"tsne\"` – t-SNE (хорошо для кластеризации, но медленный).  \n",
    "  - `\"umap\"` – UMAP (быстрее t-SNE, но сохраняет больше глобальной структуры).  \n",
    "\n",
    "- **`n_components: int = 2`**  \n",
    "  Количество измерений визуализации:  \n",
    "  - `2` – Отображение в 2D.  \n",
    "  - `3` – Отображение в 3D.  \n",
    "\n",
    "- **`use_clusters: bool = False`**  \n",
    "  Определяет, будут ли точки окрашены по кластерам или нет.  \n",
    "  - `True` – Цвета точек соответствуют кластерам.  \n",
    "  - `False` – Цвета точек соответствуют синему цвету.  \n",
    "\n",
    "- **`use_opacity: bool = True`**  \n",
    "  Управляет прозрачностью точек на основе плотности распределения.  \n",
    "  - `True` – Плотные кластеры ярче, разреженные тусклее.  \n",
    "  - `False` – Все точки одинаково непрозрачны.  \n",
    "\n",
    "\n",
    "- **`title: str = \"Embedding Visualization\"`**  \n",
    "  Заголовок графика. Можно передавать собственное название для различных экспериментов.\n",
    "\n",
    "## **Параметры `cluster_data()`**\n",
    "\n",
    "- **`method: Literal[\"kmeans\", \"dbscan\", \"agglomerative\", \"spectral\"]`**  \n",
    "  Метод кластеризации, который будет применен к уменьшенным эмбеддингам.  \n",
    "  - `\"kmeans\"` – K-средних (хорош для плотных, сферических кластеров).  \n",
    "  - `\"dbscan\"` – DBSCAN (может находить кластеры разной формы, работает с шумными данными).  \n",
    "  - `\"agglomerative\"` – Иерархическая агломеративная кластеризация (не требует указания количества кластеров).  \n",
    "  - `\"spectral\"` – Спектральная кластеризация (основана на графах, подходит для сложных структур).  \n",
    "\n",
    "- **`n_clusters: int = 3`** *(только для `\"kmeans\"`, `\"agglomerative\"`, `\"spectral\"`)*  \n",
    "  Количество кластеров, которые нужно найти (если метод поддерживает фиксированное число кластеров).  \n",
    "  - Используется в **`kmeans`**, **`agglomerative`**, **`spectral`**.  \n",
    "  - Игнорируется в **`dbscan`**, так как он определяет кластеры автоматически.  \n",
    "\n",
    "- **`eps: float = 0.5`** *(только для `\"dbscan\"`)*  \n",
    "  Радиус окрестности для поиска точек в `DBSCAN`. Чем больше `eps`, тем больше точек попадает в кластеры.  \n",
    "  - Оптимальный `eps` зависит от плотности данных.  \n",
    "\n",
    "- **`min_samples: int = 5`** *(только для `\"dbscan\"`)*  \n",
    "  Минимальное количество точек в группе для формирования кластера в `DBSCAN`.  \n",
    "\n",
    "- **`random_state: int = 42`** *(по умолчанию, для `\"kmeans\"`, `\"spectral\"`, `\"agglomerative\"`)*  \n",
    "  Фиксирует случайное состояние для воспроизводимости результатов.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer = EmbeddingVisualizer(embeddings, data_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer.reduce_dimensionality(\"pca\", n_components=2)\n",
    "visualizer.visualize(\"pca\", n_components=2, title=\"PCA 2D Visualization no clusters\", use_clusters=False, use_opacity=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer.cluster_data(\"kmeans\", n_clusters=4)\n",
    "visualizer.visualize(\"pca\", title=\"PCA 2D Visualization with clusters\", use_clusters=True, use_opacity=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TSNE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer.reduce_dimensionality(\"tsne\", n_components=2)\n",
    "visualizer.visualize(\"tsne\", n_components=2, title=\"t-SNE 2D Visualization no clusters\", use_clusters=False, use_opacity=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer.cluster_data(\"kmeans\", n_clusters=4)\n",
    "visualizer.visualize(\"tsne\", title=\"t-SNE 2D Visualization with clusters\", use_clusters=True, use_opacity=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer.reduce_dimensionality(\"umap\", n_components=2)\n",
    "visualizer.visualize(\"umap\", n_components=2, title=\"UMAP 2D Visualization no clusters\", use_clusters=False, use_opacity=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer.cluster_data(\"kmeans\", n_clusters=4)\n",
    "visualizer.visualize(\"umap\", title=\"UMAP 2D Visualization with clusters\", use_clusters=True, use_opacity=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
