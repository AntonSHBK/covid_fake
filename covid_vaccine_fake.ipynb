{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение определения фейковых фактов о COVID и вакцинации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cpu'\n",
    "if torch.backends.mps.is_available():\n",
    "    DEVICE = 'mps'\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "DATA_PATH = Path('data/')\n",
    "DATA_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "DATA_CACHE = Path('data/cache_dir/')\n",
    "DATA_CACHE.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "DATA_PATH_SAVE_MODELS = Path('data/models/')\n",
    "DATA_PATH_SAVE_MODELS.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "pd.set_option('display.max_colwidth', 500) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"roberta-base\"\n",
    "TRAIN_DF_NAME = \"covid_vaccine_fake_clear.xlsx\"\n",
    "MAX_LENGTH = 128\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>is_fake</th>\n",
       "      <th>original_label_1</th>\n",
       "      <th>source</th>\n",
       "      <th>original_label_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The CDC currently reports 99031 deaths. In general the discrepancies in death counts between different sources are small and explicable. The death toll stands at roughly 100000 people today.</td>\n",
       "      <td>0</td>\n",
       "      <td>real</td>\n",
       "      <td>nanyy1025</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                             text  \\\n",
       "0  The CDC currently reports 99031 deaths. In general the discrepancies in death counts between different sources are small and explicable. The death toll stands at roughly 100000 people today.   \n",
       "\n",
       "   is_fake original_label_1     source original_label_2  \n",
       "0        0             real  nanyy1025              NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_excel(DATA_PATH / TRAIN_DF_NAME)\n",
    "data_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.rename(columns={'is_fake': 'label'}, inplace=True)\n",
    "data_df = data_df.fillna(\"\")\n",
    "\n",
    "for col in data_df.select_dtypes(include=[\"object\", \"bool\"]).columns:\n",
    "    data_df[col] = data_df[col].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_id2idx = {int(key): int(idx) for idx, key in enumerate(data_df['label_id'].unique())}\n",
    "\n",
    "# idx2label_id = dict([(v, k) for k, v in label_id2idx.items()])\n",
    "\n",
    "# idx2label = {k: df_messages[df_messages['label_id'] == v]['label'].iloc[0] for k, v in idx2label_id.items()}\n",
    "\n",
    "# label2idx = dict([(v, k) for k, v in idx2label.items()])\n",
    "\n",
    "# df_messages['label_idx'] = df_messages['label_id'].apply(lambda x: label_id2idx[x])\n",
    "\n",
    "# df_messages.head(1)\n",
    "\n",
    "\n",
    "idx2label = {\n",
    "    0: \"Real\",\n",
    "    1: \"Fake\",\n",
    "    # 2: \"Comments\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_CLASSES = len(idx2label)\n",
    "NUM_CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер тренировочного набора: 13179\n",
      "Размер валидационного набора: 1465\n",
      "Размер тестового набора: 1628\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_val_df, test_df = train_test_split(data_df, test_size=0.1, stratify=data_df[\"label\"], random_state=42, shuffle=True)\n",
    "train_df, val_df = train_test_split(train_val_df, test_size=0.1, stratify=train_val_df[\"label\"], random_state=42, shuffle=True)\n",
    "\n",
    "print(f\"Размер тренировочного набора: {len(train_df)}\")\n",
    "print(f\"Размер валидационного набора: {len(val_df)}\")\n",
    "print(f\"Размер тестового набора: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import PreTrainedTokenizer\n",
    "import pandas as pd\n",
    "from typing import Dict, Tuple\n",
    "\n",
    "\n",
    "class TokenizedDataset(Dataset):\n",
    "    def __init__(\n",
    "        self, \n",
    "        dataframe: pd.DataFrame, \n",
    "        tokenizer: PreTrainedTokenizer, \n",
    "        max_length: int, \n",
    "        tensor_dtype: Tuple[torch.dtype, torch.dtype, torch.dtype] = (torch.long, torch.long, torch.long)\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Инициализация датасета с токенизацией.\n",
    "\n",
    "        Args:\n",
    "            dataframe (pd.DataFrame): DataFrame с колонками \"text\" и \"label\".\n",
    "            tokenizer (PreTrainedTokenizer): Токенайзер для преобразования текста.\n",
    "            max_length (int): Максимальная длина токенов.\n",
    "            tensor_dtype (tuple): Типы данных для токенов и меток.\n",
    "        \"\"\"\n",
    "        self.tensor_dtype = tensor_dtype\n",
    "\n",
    "        # Токенизация данных\n",
    "        tokenized_data = tokenizer(\n",
    "            dataframe[\"text\"].tolist(),\n",
    "            max_length=max_length,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        self.input_ids = tokenized_data[\"input_ids\"].to(dtype=self.tensor_dtype[0])\n",
    "        self.attention_mask = tokenized_data[\"attention_mask\"].to(dtype=self.tensor_dtype[1])\n",
    "        self.labels = torch.tensor(dataframe[\"label\"].tolist(), dtype=self.tensor_dtype[2])\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"\n",
    "        Возвращает количество примеров в датасете.\n",
    "        \"\"\"\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Dict[str, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Возвращает токенизированные данные и метки.\n",
    "\n",
    "        Args:\n",
    "            idx (int): Индекс примера.\n",
    "\n",
    "        Returns:\n",
    "            Dict[str, torch.Tensor]: Словарь с токенами и меткой.\n",
    "        \"\"\"\n",
    "        return {\n",
    "            \"input_ids\": self.input_ids[idx],\n",
    "            \"attention_mask\": self.attention_mask[idx],\n",
    "            \"labels\": self.labels[idx],\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from transformers import PreTrainedTokenizer\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def create_dataloader(\n",
    "    dataframe: pd.DataFrame,\n",
    "    tokenizer: PreTrainedTokenizer,\n",
    "    max_length: int = 64,\n",
    "    batch_size: int = 16,\n",
    "    shuffle: bool = True,\n",
    "    tensor_dtype=(torch.long, torch.long, torch.long),\n",
    ") -> DataLoader:\n",
    "    \"\"\"\n",
    "    Создание DataLoader из DataFrame.\n",
    "\n",
    "    Args:\n",
    "        dataframe (pd.DataFrame): DataFrame с колонками \"text\" и \"label\".\n",
    "        tokenizer (PreTrainedTokenizer): Токенайзер для преобразования текста.\n",
    "        max_length (int): Максимальная длина токенов.\n",
    "        batch_size (int): Размер батча.\n",
    "        shuffle (bool): Перемешивать ли данные.\n",
    "        tensor_dtype (tuple): Типы данных для токенов и меток.\n",
    "\n",
    "    Returns:\n",
    "        DataLoader: DataLoader для работы с моделью.\n",
    "    \"\"\"\n",
    "    dataset = TokenizedDataset(dataframe, tokenizer, max_length, tensor_dtype=tensor_dtype)\n",
    "    dataloader = DataLoader(\n",
    "        dataset, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=shuffle, \n",
    "    )\n",
    "    return dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер тренировочного набора: 13179\n",
      "Размер валидационного набора: 1465\n",
      "Размер тестового набора: 1628\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaTokenizer\n",
    "\n",
    "tokenizer: RobertaTokenizer = RobertaTokenizer.from_pretrained(MODEL_NAME, cache_dir=DATA_CACHE)\n",
    "\n",
    "train_loader = create_dataloader(\n",
    "    dataframe=train_df,\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=MAX_LENGTH,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader(\n",
    "    dataframe=val_df,\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=MAX_LENGTH,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_loader = create_dataloader(\n",
    "    dataframe=test_df,\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=MAX_LENGTH,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Выводим размер набора данных\n",
    "print(f\"Размер тренировочного набора: {len(train_loader.dataset)}\")\n",
    "print(f\"Размер валидационного набора: {len(val_loader.dataset)}\")\n",
    "print(f\"Размер тестового набора: {len(test_loader.dataset)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, Dict, Any\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Optimizer\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "\n",
    "class VaccineFakeClassifierTrainer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: torch.nn.Module,\n",
    "        train_loader: DataLoader,\n",
    "        val_loader: DataLoader,\n",
    "        optimizer: Optimizer,\n",
    "        criterion: torch.nn.Module,\n",
    "        device: torch.device,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Инициализация класса Trainer.\n",
    "\n",
    "        Args:\n",
    "            model: Модель для обучения (e.g., RobertaForSequenceClassification).\n",
    "            train_loader: DataLoader для обучающего набора.\n",
    "            val_loader: DataLoader для валидационного набора.\n",
    "            optimizer: Оптимизатор.\n",
    "            criterion: Функция потерь.\n",
    "            device: Устройство ('cuda' или 'cpu').\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.optimizer = optimizer\n",
    "        self.criterion = criterion\n",
    "        self.device = device\n",
    "        self.history = {\n",
    "            \"train_loss\": [],\n",
    "            \"val_loss\": [],\n",
    "            \"train_metrics\": [],\n",
    "            \"val_metrics\": []\n",
    "        }\n",
    "\n",
    "        self.model.to(self.device)\n",
    "\n",
    "    def train_epoch(self) -> Tuple[float, Dict[str, float]]:\n",
    "        \"\"\"\n",
    "        Обучение модели за одну эпоху.\n",
    "\n",
    "        Returns:\n",
    "            Средние потери и метрики за эпоху.\n",
    "        \"\"\"\n",
    "        self.model.train()\n",
    "        running_loss = 0.0\n",
    "        all_labels = []\n",
    "        all_preds = []\n",
    "\n",
    "        for batch in tqdm(self.train_loader, desc=\"Training\"):\n",
    "            input_ids = batch[\"input_ids\"].to(self.device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(self.device)\n",
    "            labels = batch[\"labels\"].to(self.device)\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            outputs = self.model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            logits = outputs.logits\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            preds = logits.argmax(dim=-1)\n",
    "            all_labels.append(labels.cpu())\n",
    "            all_preds.append(preds.cpu())\n",
    "\n",
    "        all_labels = torch.cat(all_labels)\n",
    "        all_preds = torch.cat(all_preds)\n",
    "        metrics = self._compute_metrics(all_preds, all_labels)\n",
    "\n",
    "        epoch_loss = running_loss / len(self.train_loader)\n",
    "        return epoch_loss, metrics\n",
    "\n",
    "    def validate_epoch(self) -> Tuple[float, Dict[str, float]]:\n",
    "        \"\"\"\n",
    "        Валидация модели за одну эпоху.\n",
    "\n",
    "        Returns:\n",
    "            Средние потери и метрики за эпоху.\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        running_loss = 0.0\n",
    "        all_labels = []\n",
    "        all_preds = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(self.val_loader, desc=\"Validation\"):\n",
    "                input_ids = batch[\"input_ids\"].to(self.device)\n",
    "                attention_mask = batch[\"attention_mask\"].to(self.device)\n",
    "                labels = batch[\"labels\"].to(self.device)\n",
    "\n",
    "                outputs = self.model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "                loss = outputs.loss\n",
    "                logits = outputs.logits\n",
    "\n",
    "                running_loss += loss.item()\n",
    "\n",
    "                preds = logits.argmax(dim=-1)\n",
    "                all_labels.append(labels.cpu())\n",
    "                all_preds.append(preds.cpu())\n",
    "\n",
    "        all_labels = torch.cat(all_labels)\n",
    "        all_preds = torch.cat(all_preds)\n",
    "        metrics = self._compute_metrics(all_preds, all_labels)\n",
    "\n",
    "        epoch_loss = running_loss / len(self.val_loader)\n",
    "        return epoch_loss, metrics\n",
    "\n",
    "    def fit(self, num_epochs: int):\n",
    "        \"\"\"\n",
    "        Обучение и валидация модели.\n",
    "\n",
    "        Args:\n",
    "            num_epochs: Общее количество эпох.\n",
    "        \"\"\"\n",
    "        for epoch in range(num_epochs):\n",
    "            print(f\"\\nEpoch {epoch + 1}/{num_epochs}\")\n",
    "\n",
    "            train_loss, train_metrics = self.train_epoch()\n",
    "            val_loss, val_metrics = self.validate_epoch()\n",
    "\n",
    "            self.history[\"train_loss\"].append(train_loss)\n",
    "            self.history[\"val_loss\"].append(val_loss)\n",
    "            self.history[\"train_metrics\"].append(train_metrics)\n",
    "            self.history[\"val_metrics\"].append(val_metrics)\n",
    "\n",
    "            print(f\"Train Loss: {train_loss:.4f} | Validation Loss: {val_loss:.4f}\")\n",
    "            print(f\"Train Metrics: {train_metrics} | Validation Metrics: {val_metrics}\")\n",
    "\n",
    "    def plot_results(self, metrics_to_plot=None):\n",
    "        \"\"\"\n",
    "        Построение графиков потерь и метрик для обучения и валидации.\n",
    "\n",
    "        Args:\n",
    "            metrics_to_plot: Список метрик для визуализации.\n",
    "        \"\"\"\n",
    "        if metrics_to_plot is None:\n",
    "            metrics_to_plot = [\"accuracy\", \"f1\"]\n",
    "\n",
    "        num_plots = len(metrics_to_plot) + 1\n",
    "        plt.figure(figsize=(15, 5 * (num_plots // 2 + 1)))\n",
    "\n",
    "        # График потерь\n",
    "        plt.subplot((num_plots + 1) // 2, 2, 1)\n",
    "        plt.plot(self.history[\"train_loss\"], label=\"Train Loss\", color=\"blue\", linestyle=\"--\")\n",
    "        plt.plot(self.history[\"val_loss\"], label=\"Validation Loss\", color=\"red\", linestyle=\"-\")\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.title(\"Loss over Epochs\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "\n",
    "        # Графики метрик\n",
    "        for i, metric in enumerate(metrics_to_plot, start=2):\n",
    "            train_metric = [m[metric] for m in self.history[\"train_metrics\"]]\n",
    "            val_metric = [m[metric] for m in self.history[\"val_metrics\"]]\n",
    "\n",
    "            plt.subplot((num_plots + 1) // 2, 2, i)\n",
    "            plt.plot(train_metric, label=f\"Train {metric.capitalize()}\", color=\"blue\", linestyle=\"--\")\n",
    "            plt.plot(val_metric, label=f\"Validation {metric.capitalize()}\", color=\"red\", linestyle=\"-\")\n",
    "            plt.xlabel(\"Epochs\")\n",
    "            plt.ylabel(metric.capitalize())\n",
    "            plt.title(f\"{metric.capitalize()} over Epochs\")\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    @staticmethod\n",
    "    def _compute_metrics(preds: torch.Tensor, labels: torch.Tensor) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Вычисление метрик.\n",
    "\n",
    "        Args:\n",
    "            preds: Предсказания модели.\n",
    "            labels: Истинные метки.\n",
    "\n",
    "        Returns:\n",
    "            Словарь метрик.\n",
    "        \"\"\"\n",
    "        preds = preds.numpy()\n",
    "        labels = labels.numpy()\n",
    "\n",
    "        metrics = {\n",
    "            \"accuracy\": accuracy_score(labels, preds),\n",
    "            \"f1\": f1_score(labels, preds, average=\"weighted\"),\n",
    "        }\n",
    "        return metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.optim import AdamW\n",
    "from transformers import RobertaForSequenceClassification\n",
    "\n",
    "LEARNING_RATE = 1e-5\n",
    "NUM_EPOCHS = 5\n",
    "WEIGHT_DECAY = 0.01\n",
    "\n",
    "model = RobertaForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME, num_labels=NUM_CLASSES, cache_dir=DATA_CACHE)\n",
    "\n",
    "model.to(DEVICE)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = VaccineFakeClassifierTrainer(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    device=DEVICE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(num_epochs=NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.plot_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = DATA_PATH_SAVE_MODELS / \"covid_vaccine_fake_model\"\n",
    "model.save_pretrained(model_save_path)\n",
    "tokenizer.save_pretrained(model_save_path)\n",
    "print(f\"Модель и токинайзер сохранены в: {model_save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тестирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "\n",
    "def test_model(\n",
    "    model: torch.nn.Module,\n",
    "    test_loader: DataLoader,\n",
    "    test_df: pd.DataFrame,\n",
    "    idx2label: dict,\n",
    "    device: torch.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Тестирует модель на тестовом DataLoader и возвращает DataFrame с результатами.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): Обученная модель.\n",
    "        test_loader (DataLoader): DataLoader для тестового набора.\n",
    "        test_df (pd.DataFrame): Исходный DataFrame тестовых данных.\n",
    "        idx2label (dict): Словарь, отображающий индексы категорий в названия.\n",
    "        device (torch.device): Устройство для вычислений (CPU/GPU).\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame с результатами, содержащий:\n",
    "            - 'text': текст примера,\n",
    "            - 'true_label': истинная метка,\n",
    "            - 'predicted_label': предсказанная метка,\n",
    "            - 'probability': вероятность предсказания,\n",
    "            - 'correct': корректность предсказания (True/False).\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    test_results = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader, desc=\"Testing\"):\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            true_labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            logits = model(input_ids=input_ids, attention_mask=attention_mask).logits\n",
    "            probabilities = torch.softmax(logits, dim=-1).cpu().numpy()\n",
    "\n",
    "            predictions = torch.argmax(logits, dim=-1).cpu().numpy()\n",
    "            true_labels = true_labels.cpu().numpy()\n",
    "\n",
    "            for true_label, predicted_label, probs in zip(true_labels, predictions, probabilities):\n",
    "                test_results.append({\n",
    "                    \"true_label\": idx2label[true_label],\n",
    "                    \"predicted_label\": idx2label[predicted_label],\n",
    "                    \"probability\": probs.tolist(),\n",
    "                    \"correct\": true_label == predicted_label,\n",
    "                })\n",
    "\n",
    "    test_results_df = pd.DataFrame(test_results)\n",
    "\n",
    "    test_df = test_df.reset_index(drop=True)\n",
    "    test_df = pd.concat([test_df, test_results_df], axis=1)\n",
    "\n",
    "    accuracy = accuracy_score(test_df[\"true_label\"], test_df[\"predicted_label\"])\n",
    "    f1 = f1_score(test_df[\"true_label\"], test_df[\"predicted_label\"], average=\"weighted\")\n",
    "\n",
    "    print(\"\\n=== Результаты тестирования ===\")\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "    return test_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import RobertaForSequenceClassification, RobertaTokenizer\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained(DATA_PATH_SAVE_MODELS / \"covid_vaccine_fake_model\")\n",
    "model = RobertaForSequenceClassification.from_pretrained(\n",
    "    DATA_PATH_SAVE_MODELS / \"covid_vaccine_fake_model\")\n",
    "\n",
    "model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0e2da92310a4732969ad5abe4bcb8fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Результаты тестирования ===\n",
      "Accuracy: 93.43%\n",
      "F1 Score: 0.9343\n"
     ]
    }
   ],
   "source": [
    "test_results_df = test_model(\n",
    "    model=model,\n",
    "    test_loader=test_loader,\n",
    "    test_df=test_df,\n",
    "    idx2label=idx2label,\n",
    "    device=DEVICE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>original_label_1</th>\n",
       "      <th>source</th>\n",
       "      <th>original_label_2</th>\n",
       "      <th>true_label</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>probability</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>Many countries have 'perfected' COVID-19 vaccines</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>justinqbui_1</td>\n",
       "      <td></td>\n",
       "      <td>Fake</td>\n",
       "      <td>Fake</td>\n",
       "      <td>[0.006007475312799215, 0.9939925074577332]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1035</th>\n",
       "      <td>People in Scotland have been banned from visiting other households indoors in tough new restrictions that go further than those announced for England. Get more on the new measures in Scotland here:</td>\n",
       "      <td>0</td>\n",
       "      <td>real</td>\n",
       "      <td>nanyy1025</td>\n",
       "      <td></td>\n",
       "      <td>Real</td>\n",
       "      <td>Real</td>\n",
       "      <td>[0.9992978572845459, 0.0007021332858130336]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1115</th>\n",
       "      <td>No COVID-19 deaths in Israel due to baking soda remedy</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>justinqbui_1</td>\n",
       "      <td></td>\n",
       "      <td>Fake</td>\n",
       "      <td>Fake</td>\n",
       "      <td>[0.0012017586268484592, 0.9987982511520386]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>816</th>\n",
       "      <td>A series of claims including that the COVID-19 pandemic was \"fake\" and 5G telecommunications is causing the illness.</td>\n",
       "      <td>1</td>\n",
       "      <td>fake</td>\n",
       "      <td>nanyy1025</td>\n",
       "      <td></td>\n",
       "      <td>Fake</td>\n",
       "      <td>Fake</td>\n",
       "      <td>[0.0017301528714597225, 0.99826979637146]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1318</th>\n",
       "      <td>Melburnians have been advised to wear face masks as  case numbers continue to climb in Australia's second largest city. But just how effective are they at stopping the spread?</td>\n",
       "      <td>1</td>\n",
       "      <td>fake</td>\n",
       "      <td>nanyy1025</td>\n",
       "      <td></td>\n",
       "      <td>Fake</td>\n",
       "      <td>Real</td>\n",
       "      <td>[0.9987951517105103, 0.0012047699419781566]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024</th>\n",
       "      <td>Tuberculosis (TB) has a higher death rate than coronavirus.</td>\n",
       "      <td>1</td>\n",
       "      <td>fake</td>\n",
       "      <td>nanyy1025</td>\n",
       "      <td></td>\n",
       "      <td>Fake</td>\n",
       "      <td>Fake</td>\n",
       "      <td>[0.027301350608468056, 0.9726986885070801]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>The flu didn't kill any Americans this year.</td>\n",
       "      <td>1</td>\n",
       "      <td>pants-fire</td>\n",
       "      <td>justinqbui_2</td>\n",
       "      <td>false</td>\n",
       "      <td>Fake</td>\n",
       "      <td>Fake</td>\n",
       "      <td>[0.00776379369199276, 0.9922361969947815]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>If you get vaccinated while wearing red shoes, the vaccine won’t work. Red interferes with its ability to circulate in the bloodstream.</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>synthetic</td>\n",
       "      <td></td>\n",
       "      <td>Fake</td>\n",
       "      <td>Fake</td>\n",
       "      <td>[0.000679028918966651, 0.9993209838867188]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926</th>\n",
       "      <td>Coronavirus victims in China.</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>justinqbui_1</td>\n",
       "      <td></td>\n",
       "      <td>Fake</td>\n",
       "      <td>Fake</td>\n",
       "      <td>[0.02821573056280613, 0.9717842936515808]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>SARS-CoV-2 is a “bacterial infection” not a virus.</td>\n",
       "      <td>1</td>\n",
       "      <td>fake</td>\n",
       "      <td>nanyy1025</td>\n",
       "      <td></td>\n",
       "      <td>Fake</td>\n",
       "      <td>Fake</td>\n",
       "      <td>[0.006632894277572632, 0.9933671355247498]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                       text  \\\n",
       "889                                                                                                                                                       Many countries have 'perfected' COVID-19 vaccines   \n",
       "1035  People in Scotland have been banned from visiting other households indoors in tough new restrictions that go further than those announced for England. Get more on the new measures in Scotland here:   \n",
       "1115                                                                                                                                                 No COVID-19 deaths in Israel due to baking soda remedy   \n",
       "816                                                                                    A series of claims including that the COVID-19 pandemic was \"fake\" and 5G telecommunications is causing the illness.   \n",
       "1318                        Melburnians have been advised to wear face masks as  case numbers continue to climb in Australia's second largest city. But just how effective are they at stopping the spread?   \n",
       "1024                                                                                                                                            Tuberculosis (TB) has a higher death rate than coronavirus.   \n",
       "867                                                                                                                                                            The flu didn't kill any Americans this year.   \n",
       "309                                                                 If you get vaccinated while wearing red shoes, the vaccine won’t work. Red interferes with its ability to circulate in the bloodstream.   \n",
       "926                                                                                                                                                                           Coronavirus victims in China.   \n",
       "274                                                                                                                                                      SARS-CoV-2 is a “bacterial infection” not a virus.   \n",
       "\n",
       "      label original_label_1        source original_label_2 true_label  \\\n",
       "889       1            False  justinqbui_1                        Fake   \n",
       "1035      0             real     nanyy1025                        Real   \n",
       "1115      1            False  justinqbui_1                        Fake   \n",
       "816       1             fake     nanyy1025                        Fake   \n",
       "1318      1             fake     nanyy1025                        Fake   \n",
       "1024      1             fake     nanyy1025                        Fake   \n",
       "867       1       pants-fire  justinqbui_2            false       Fake   \n",
       "309       1                      synthetic                        Fake   \n",
       "926       1            False  justinqbui_1                        Fake   \n",
       "274       1             fake     nanyy1025                        Fake   \n",
       "\n",
       "     predicted_label                                  probability  correct  \n",
       "889             Fake   [0.006007475312799215, 0.9939925074577332]     True  \n",
       "1035            Real  [0.9992978572845459, 0.0007021332858130336]     True  \n",
       "1115            Fake  [0.0012017586268484592, 0.9987982511520386]     True  \n",
       "816             Fake    [0.0017301528714597225, 0.99826979637146]     True  \n",
       "1318            Real  [0.9987951517105103, 0.0012047699419781566]    False  \n",
       "1024            Fake   [0.027301350608468056, 0.9726986885070801]     True  \n",
       "867             Fake    [0.00776379369199276, 0.9922361969947815]     True  \n",
       "309             Fake   [0.000679028918966651, 0.9993209838867188]     True  \n",
       "926             Fake    [0.02821573056280613, 0.9717842936515808]     True  \n",
       "274             Fake   [0.006632894277572632, 0.9933671355247498]     True  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results_df.to_excel(DATA_PATH / 'test_results_learning.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PreTrainedTokenizer, PreTrainedModel\n",
    "import torch\n",
    "\n",
    "\n",
    "def test_model_with_text(\n",
    "    model: PreTrainedModel,\n",
    "    tokenizer: PreTrainedTokenizer,\n",
    "    text: str,\n",
    "    max_length: int = 128,\n",
    "    label_map: dict = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Проверяет модель на введенном вручную тексте, используя argmax для классификации.\n",
    "\n",
    "    Args:\n",
    "        model (PreTrainedModel): Загруженная обученная модель (например, RobertaForSequenceClassification).\n",
    "        tokenizer (PreTrainedTokenizer): Токенизатор для подготовки текста.\n",
    "        text (str): Текст для классификации.\n",
    "        max_length (int): Максимальная длина токенизированного текста.\n",
    "        label_map (dict): Словарь для отображения меток, если метки числовые.\n",
    "\n",
    "    Returns:\n",
    "        dict: Словарь с текстом, вероятностями и предсказанными метками.\n",
    "    \"\"\"\n",
    "\n",
    "    model.eval()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    inputs = tokenizer(\n",
    "        text,\n",
    "        max_length=max_length,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        probs = torch.softmax(logits, dim=-1).cpu().numpy()[0]  # Вероятности для каждого класса\n",
    "\n",
    "    predicted_index = torch.argmax(logits, dim=-1).item()\n",
    "    predicted_label = label_map[predicted_index] if label_map else predicted_index\n",
    "\n",
    "    # Результаты\n",
    "    result = {\n",
    "        \"text\": text,\n",
    "        \"probabilities\": probs.tolist(),\n",
    "        \"predicted_label\": predicted_label\n",
    "    }\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'COVID-19 vaccines do not affect fertility or reproductive health. This has been confirmed through multiple studies and ongoing research.', 'probabilities': [0.9964038133621216, 0.0035962604451924562], 'predicted_label': 'Real'}\n"
     ]
    }
   ],
   "source": [
    "text = \"COVID-19 vaccines do not affect fertility or reproductive health. This has been confirmed through multiple studies and ongoing research.\"\n",
    "\n",
    "result = test_model_with_text(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    text=text,\n",
    "    max_length=128,\n",
    "    label_map=idx2label\n",
    ")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'COVID-19 vaccines affect fertility or reproductive health.', 'probabilities': [0.3103806674480438, 0.6896193027496338], 'predicted_label': 'Fake'}\n"
     ]
    }
   ],
   "source": [
    "text = \"COVID-19 vaccines affect fertility or reproductive health.\"\n",
    "\n",
    "result = test_model_with_text(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    text=text,\n",
    "    max_length=128,\n",
    "    label_map=idx2label\n",
    ")\n",
    "\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
