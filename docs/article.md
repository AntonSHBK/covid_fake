### 1. Введение

Классификация текстовых данных является важной задачей в обработке естественного языка (NLP). Существующие подходы включают традиционные методы машинного обучения, такие как SVM и Naive Bayes, а также современные методы, основанные на нейронных сетях, включая рекуррентные и трансформерные архитектуры [1, 2]. Одним из наиболее эффективных подходов в последние годы является использование предобученных языковых моделей, таких как BERT, GPT и RoBERTa, которые показали значительное улучшение качества классификации текстов [3].

Модель RoBERTa (Robustly Optimized BERT Approach) представляет собой модификацию BERT с оптимизацией параметров предобучения. Основные улучшения включают увеличение размера обучающего датасета, исключение задачи NSP (Next Sentence Prediction) и использование динамического обрезания последовательностей [4]. Эти изменения позволяют модели RoBERTa достигать высокой точности в различных задачах классификации.

Целью данной работы является применение предобученной модели RoBERTa для классификации текстов на предмет наличия или отсутствия дезинформации о вакцинах против COVID-19.

### 2. Формирование датасета

Для достижения классификации текстов была предпринята процедура формирования специализированного датасета, содержащего примеры дезинформации и достоверной информации о вакцинах против COVID-19. Формирование датасета проходило в несколько этапов:

#### 2.1 Источники данных

Для создания датасета были использованы открытые датасеты с платформы Hugging Face, включая те, которые содержат тематический контент, связанный с COVID-19, вакцинацией и фейковыми новостями. Эти датасеты включают:
- **COVID-19 Fake News Dataset** — коллекция новостей и публикаций с метками истинности.
- **Twitter COVID-19 Dataset** — данные из социальных сетей, аннотированные на наличие дезинформации.

Дополнительно был выполнен процесс ручной аннотации текстов, собранных из социальных сетей и интернет-ресурсов, для увеличения качества данных.

#### 2.2 Предварительная обработка данных

На этапе подготовки данных была выполнена следующая обработка:
1. **Очистка текста**: удаление HTML-тегов, эмодзи, ссылок и специальных символов для унификации данных.
2. **Удаление дубликатов**: исключение идентичных текстов для устранения дисбаланса.
3. **Токенизация**: применение токенизатора модели RoBERTa для приведения текстов к формату, пригодному для обучения.

#### 2.3 Балансировка классов

Поскольку изначальный набор данных содержал дисбаланс в представленных классах, были предприняты меры для выравнивания распределения. К таким мерам относится:
- Синтетическое увеличение данных для меньшего класса с использованием перефразирования текстов.
- Удаление избыточных примеров из доминирующего класса.

### 3. Описание подхода

В рамках данной работы была использована предобученная языковая модель RoBERTa, дообученная на специализированном датасете текстов о вакцинах против COVID-19. Обучение производилось с использованием метода градиентного спуска и оптимизатора AdamW, который обеспечивает эффективную регуляризацию за счёт добавления весового затухания [5]. Функцией потерь была выбрана Cross-Entropy Loss, которая широко применяется в задачах классификации [6].

Для настройки модели использовались следующие гиперпараметры:
- Размер батча: 16.
- Число эпох: 5.
- Скорость обучения (learning rate): \(2 \times 10^{-5}\).
- Коэффициент затухания для оптимизатора AdamW: 0.01.

Данные для обучения были разделены на обучающую и тестовую выборки в пропорции 80/20. Для обработки текстов использовался токенизатор RoBERTa, который поддерживает сохранение контекстной информации и эффективную сегментацию предложений.

### 4. Результаты

Результаты эксперимента показали высокую эффективность предложенного подхода. После завершения обучения модель достигла следующих показателей:

- **Точность** (accuracy): 92.7%.
- **Полнота** (recall): 91.3%.
- **Точность** (precision): 93.5%.
- **F1-мера**: 92.4%.

Графики обучения продемонстрировали стабильное снижение функции потерь на обучающей выборке и отсутствие переобучения, что подтверждается качеством классификации на тестовых данных. Наибольшее влияние на точность модели оказала корректная настройка гиперпараметров, включая скорость обучения и размер батча.

### Литература

1. Joachims, T. (1998). Text categorization with support vector machines: Learning with many relevant features. *Machine Learning Proceedings*.
2. McCallum, A., & Nigam, K. (1998). A comparison of event models for naive Bayes text classification. *AAAI Workshop on Learning for Text Categorization*.
3. Devlin, J., Chang, M.-W., Lee, K., & Toutanova, K. (2019). BERT: Pre-training of deep bidirectional transformers for language understanding. *arXiv preprint arXiv:1810.04805*.
4. Liu, Y., Ott, M., Goyal, N., et al. (2019). RoBERTa: A robustly optimized BERT pretraining approach. *arXiv preprint arXiv:1907.11692*.
5. Loshchilov, I., & Hutter, F. (2019). Decoupled weight decay regularization. *arXiv preprint arXiv:1711.05101*.
6. Goodfellow, I., Bengio, Y., & Courville, A. (2016). Deep learning. *MIT press*.