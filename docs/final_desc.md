# Covid Fake

- [Covid Fake](#covid-fake)
  - [**1. Введение**](#1-введение)
  - [**2. Общее описание подхода обработки текса**](#2-общее-описание-подхода-обработки-текса)
  - [**3. Формирование эмбеддингов и предварительный анализ**](#3-формирование-эмбеддингов-и-предварительный-анализ)
  - [**4. Дообучение модели**](#4-дообучение-модели)
  - [**5. Анализ эмбеддингов**](#5-анализ-эмбеддингов)
  - [**6. Дальнейшие исследования**](#6-дальнейшие-исследования)
  - [**Описание датасета**](#описание-датасета)
    - [**Таблица 1. Краткие характеристики использованных датасетов**](#таблица-1-краткие-характеристики-использованных-датасетов)
    - [**Таблица 2. Количественные параметры объединённого датасета**](#таблица-2-количественные-параметры-объединённого-датасета)
    - [**Литература**](#литература)

## **1. Введение**

Пандемия COVID-19 сопровождалась не только стремительным распространением вируса, но и лавинообразным ростом информационного шума. Социальные сети, мессенджеры и новостные порталы стали источниками как полезной, так и ложной информации. В результате возник феномен **"инфодемии"** — масштабного распространения дезинформации, фейковых новостей и конспирологических теорий, напрямую влияющих на поведение людей, общественное мнение и даже государственную политику.

Особенно опасной является дезинформация, касающаяся **вакцинации против COVID-19**. Недоверие к вакцинам, основанное на ложных утверждениях (например, о вживлении чипов, смертельных побочных эффектах или "заговорах фармкомпаний"), подрывает общественные усилия по борьбе с пандемией, снижает уровень вакцинации и увеличивает риски для здоровья населения.

В таких условиях остро встаёт задача создания **автоматизированной системы**, способной анализировать большое количество текстов (постов, комментариев, статей) и **выделять сообщения, содержащие дезинформацию**, достоверные научные факты, а также нейтральные пользовательские высказывания. Такая система может использоваться как инструмент поддержки принятия решений, мониторинга информационного пространства и исследования социологических тенденций.

Одним из ключевых инструментов в решении этой задачи является **обработка естественного языка (NLP)** и **анализ настроений**, в том числе с применением **встраиваний (эмбеддингов)**. NLP — это форма искусственного интеллекта, которая позволяет извлекать смысл из текстов, структурировать неформальные сообщения и выделять важные семантические признаки. Особенно полезен в этом контексте **анализ настроений**, позволяющий выявлять положительные, отрицательные и нейтральные интонации в текстах, что критически важно при исследовании манипулятивных сообщений и дезинформации. Такие подходы доказали свою эффективность при работе с большими объёмами данных, где ручная проверка невозможна [139], [140].

Хотя автоматические методы могут уступать человеку в точности при оценке контекста, исследования показывают, что результаты, полученные с использованием NLP, во многих случаях совпадают с аннотациями, сделанными вручную, особенно в задачах анализа тональности. При этом даже человеческие аннотации могут быть непоследовательными — разные аннотаторы по-разному интерпретируют неоднозначные сообщения, что делает автоматические подходы не менее надёжными в масштабных задачах [140].

Для выполнения анализа текста NLP-модели разбивают неструктурированный текст на логические единицы: выполняют **лемматизацию**, **грамматический разбор** и **контекстуализацию значений слов**, что позволяет проводить анализ как на уровне документа в целом, так и на уровне отдельных предложений или токенов [141].

Особую роль в современном NLP играют **встраивания (эмбеддинги)** — числовые представления слов и фраз в многомерном пространстве, отражающие их семантику. Использование эмбеддингов позволяет системам более точно интерпретировать значения и контексты, что особенно важно при выявлении дезинформации, в которой используются эвфемизмы, искажения и скрытые намёки. Встраивания также помогают зафиксировать **тонкие сигналы, указывающие на манипуляции, предвзятость или эмоциональный накал** в тексте — всё это делает их важнейшим компонентом в построении надёжной системы мониторинга дезинформации [126], [142], [143].

Проект нацелен на решение описанных задач с помощью современных NLP-технологий, включая:
- использование **предобученных трансформеров** (в частности, модели RoBERTa),
- генерацию **векторных представлений (эмбеддингов)** текстов,
- **кластеризацию** и визуализацию смысловых групп сообщений,
- **классификацию** на основе контекста и структуры текста,

В работе используются как **реальные, так и синтетические данные**, а также сообщения, собранные с различных интернет-источников, включая Facebook, Reddit и тематические датасеты с платформы Hugging Face.

Цель проекта — разработка **интерпретируемой и надёжной системы классификации и анализа текстов**, способной выявлять фейковую информацию о COVID-19, поддерживать прозрачность и доверие к результатам, а также быть масштабируемой для других тематик в будущем.

## **2. Общее описание подхода обработки текса**

Проект опирается на современные методы обработки естественного языка, в частности трансформерные языковые модели, векторные представления текста и тематическое моделирование. Ключевая цель — создание автоматизированной системы, способной выявлять фейковую информацию и достоверные утверждения о COVID-19 на основе анализа пользовательских сообщений и публикаций. Такой подход требует глубокого понимания структуры текста, скрытых смыслов, эмоциональной окраски и контекста, что делает применение трансформеров и эмбеддингов особенно эффективным.

В качестве основной архитектуры для анализа текстов была выбрана модель **RoBERTa** (Robustly Optimized BERT Pretraining Approach), представляющая собой улучшенную версию BERT. В отличие от оригинального BERT, RoBERTa обучалась на значительно большем объёме данных, не использует задачу предсказания следующего предложения и применяет динамическое маскирование токенов. Эти усовершенствования позволяют модели захватывать более широкий спектр контекстуальной информации и делать более точные предсказания. Выбор RoBERTa обусловлен её высокой производительностью в задачах текстовой классификации и способности обрабатывать короткие, но семантически насыщенные фразы, характерные для социальных сетей и новостных заголовков.

Формирование эмбеддингов происходит на основе вывода скрытых состояний из последнего слоя модели RoBERTa. Каждый текст преобразуется в числовой вектор фиксированной размерности, отражающий его семантическое содержание. Вектор создаётся путём агрегации токенов — например, усреднением всех эмбеддингов или извлечением вектора специального токена `[CLS]`. Полученные эмбеддинги служат основой для дальнейшего анализа — от классификации до кластеризации, извлечения информации и измерения текстового сходства. Используя эти представления, можно не только классифицировать тексты, но и строить системы извлечения информации, которые находят релевантные сообщения на основе семантической близости, а также определять дублированные или почти дублированные посты по высокой степени векторного совпадения.

Кластеризация текста с помощью эмбеддингов применяется для группировки схожих по смыслу сообщений, что позволяет анализировать внутреннюю структуру больших коллекций текстов, выявлять скрытые паттерны и темы. Это особенно важно в контексте дезинформации, где сообщения часто варьируются в формулировках, но передают одни и те же идеи. Для визуального анализа структуры эмбеддингов используется метод понижения размерности **t-SNE (t-distributed Stochastic Neighbor Embedding)**, который позволяет проецировать высокоразмерные вектора в двумерное пространство. Он сохраняет локальные расстояния между точками, что делает возможным визуальное выявление плотных кластеров, отражающих тематически однородные группы сообщений.

Дополнительно в проекте используется тематическое моделирование на базе **BERTopic** — фреймворка, который сочетает семантические эмбеддинги и иерархическую кластеризацию. BERTopic позволяет выделить устойчивые темы в корпусе текстов и представить их в виде интерпретируемых топиков. Это даёт возможность не только анализировать частотность тем, но и отслеживать, как меняется информационная повестка во времени или как темы пересекаются с фейковыми утверждениями.

Ещё одним направлением использования эмбеддингов в проекте является **анализ настроений**. Встраивания текста служат входом для классификаторов, определяющих эмоциональную окраску сообщения — будь то позитивное, негативное, нейтральное или смешанное. Анализ настроений используется как дополнительная характеристика текста и может быть полезен для выявления манипулятивных эмоциональных стратегий в фейковых постах. Методы анализа могут включать предсказательные модели, обученные на размеченных корпусах, лексиконные подходы с использованием словарей тональности, статистические модели скрытых аспектов, а также правила, основанные на подсчёте позитивных и негативных слов. Результаты анализа могут интерпретироваться по-разному: от шкал [0, 1] или [-1, 1] до процентного распределения настроений [139], [140].

**Система кодирования** (или **кодировочная рамка**) будет разработана исследователем для структурирования и аннотирования текстовых данных. Она будет основана на терминах и выражениях, выявленных в научных исследованиях по здравоохранению и дезинформации, включая лексику, связанную с медицинскими работниками, COVID-19, вакцинацией, а также обозначениями, указывающими на географические или институциональные контексты. 

Вот текст для раздела **3. Формирование эмбеддингов и предварительный анализ**, написанный в академическом и логичном стиле:

## **3. Формирование эмбеддингов и предварительный анализ**

На начальном этапе работы для понимания структуры и смыслового распределения текстов было решено использовать предобученную языковую модель **RoBERTa** без дообучения на целевой задаче. Такая модель предоставляет универсальные контекстные представления текста и может быть применена для извлечения эмбеддингов — векторных представлений, отражающих семантическое содержание сообщений.  

Каждое текстовое сообщение из корпуса (включая посты, комментарии и описания ссылок) обрабатывалось с помощью токенизатора `RobertaTokenizer` и преобразовывалось в входные данные фиксированной длины. Далее тексты подавались в модель `RobertaModel`, откуда извлекались скрытые состояния последнего слоя. Для формирования единого эмбеддинга предложения применялась агрегация векторов по стратегии **усреднения**.

Полученные вектора размерности 768 использовались для дальнейшего **анализа структуры данных**. С целью визуализации и исследования семантических кластеров применялся метод **t-SNE (t-distributed Stochastic Neighbor Embedding)**, позволяющий отобразить высокоразмерные данные в двумерном пространстве, при этом сохраняя локальные отношения между точками.  

Визуальный анализ проекций t-SNE показал наличие определённой структуры: в данных прослеживались группы сообщений, схожих по тону, тематике или лексике. Например, можно было выделить плотные кластеры пользовательских комментариев или коротких высказываний без фактической нагрузки. Однако границы между фейками и достоверными фактами оказывались размытыми. Это связано с тем, что **универсальные эмбеддинги, полученные без учёта контекста задачи, не обладают достаточной дискриминативной способностью для точной классификации по смыслу и достоверности**.

Таким образом, предварительный анализ на основе эмбеддингов и t-SNE подтвердил наличие некоторой структурной организации в корпусе. Однако без учёта специфики задачи (например, различения дезинформации и правдивой информации), модель RoBERTa в базовом виде не позволяет достичь надёжной классификации. Это наблюдение стало основанием для следующего этапа — **дообучения модели под задачу трёхклассовой классификации**: фейк, факт, комментарий.

## **4. Дообучение модели**

Результаты предварительного анализа эмбеддингов, полученных с помощью предобученной модели RoBERTa, показали ограниченную способность такой модели различать фейковые утверждения, достоверную информацию и нейтральные комментарии. Это стало основанием для перехода к следующему этапу — **дообучению модели под конкретную задачу классификации**. Цель заключалась в том, чтобы на основе размеченного корпуса обучить модель различать три типа сообщений:  
- **(1)** фейковая информация (дезинформация),  
- **(2)** достоверные факты (основанные на научных источниках или проверенных данных),  
- **(3)** комментарии (нейтральные или не несущие смысловой нагрузки утверждения, часто эмоциональные, бытовые или обрывочные).

Для формирования обучающего корпуса были использованы несколько открытых датасетов, а также собственная коллекция текстов, собранная с платформ Facebook и Reddit. Источники включали как сообщения, заведомо размеченные по степени достоверности (например, `nanyy1025/covid_fake_news`, `justinqbui/covid_fact_checked_google_api`, `polifact`), так и пользовательские комментарии, не содержащие фактологического содержания, но характерные для повседневной дискуссии в социальных сетях. Эти данные были вручную приведены к единой структуре и аннотированы с учётом трёхклассовой схемы.

Фейковыми помечались утверждения, содержащие заведомо ложную или манипулятивную информацию (например, дезинформация о вакцинации, распространённые мифы, конспирологические теории). Класс достоверных фактов включал тексты, подтверждённые экспертными источниками или научными публикациями. Комментариями считались эмоциональные, бытовые или реакционные высказывания пользователей, не претендующие на достоверность, но активно присутствующие в инфополе. 

После завершения подготовки корпуса данные были токенизированы и поданы на вход модели `RobertaForSequenceClassification` с конфигурацией на три класса. Для обучения использовалась функция потерь `CrossEntropyLoss`, оптимизатор `AdamW` и стандартное разбиение на тренировочную, валидационную и тестовую выборки. Обучение производилось в течение трёх эпох, пока не достигалась стабилизация метрик на валидации.  

Ниже приведены основные параметры обучения:

| Параметр                          | Значение              |
|----------------------------------|------------------------|
| **Максимальная длина токенов**   | 128                    |
| **Оптимизатор**                  | AdamW                  |
| **Функция потерь**               | CrossEntropyLoss       |
| **Размер батча**                 | 16                     |
| **Коэффициент обучения**         | \( 5 \times 10^{-5} \) |
| **Эпохи обучения**               | 3                      |
| **Warmup Steps**                 | 500                    |
| **Weight Decay**                 | 0.01                   |

Модель обучалась с использованием GPU для ускорения вычислений. На тестовой выборке были достигнуты следующие результаты:

- **Точность (Accuracy)**: 93.43%  
- **F1-мера (macro)**: 0.9343  

<img src="imgs/roberta_base_clusters.jpg" alt="emb" width="1000"/>  

Несмотря на высокие показатели точности на обучающей и тестовой выборках, при применении модели к реальным данным (например, комментариям из Facebook) наблюдается заметное снижение качества классификации. Это связано с тем, что трёхклассовая схема — фейк, факт и комментарий — оказывается недостаточно гибкой для отражения всего разнообразия высказываний в естественной среде. Многие тексты носят смешанный, ироничный или саркастический характер, не вписываясь в жёстко заданные категории. Тем не менее, полученная модель может служить **надёжной отправной точкой** для построения более сложной системы анализа текстов, включая расширение класса разметки, внедрение контекстных и дискурсивных признаков, а также развитие методов интерпретации предсказаний.


## **5. Анализ эмбеддингов**

На первом изображении представлена визуализация эмбеддингов текстов, проецированных в двумерное пространство с помощью метода t-SNE. Каждая точка соответствует отдельному сообщению, а цвет отражает класс, присвоенный моделью (фейк, факт или комментарий). Несмотря на частичное наложение классов, можно наблюдать явную тенденцию к формированию обособленных регионов, особенно для комментариев, которые образуют плотную, визуально однородную область.

<img src="imgs/tsne_all.jpg" alt="emb" width="1000"/>  

На втором изображении та же проекция дополнена результатами кластеризации. Кластеры, выделенные автоматически, показывают дополнительную структуру данных, не всегда совпадающую с заданной разметкой. Например, внутри класса "фейк" выделяются несколько подгрупп, вероятно, соответствующих разным типам дезинформации (антивакцинаторские тексты, политизированные заявления и т.п.). Аналогично, в классе "факт" можно заметить разделение по источникам или стилистике изложения.

<img src="imgs/tsne_clusters.jpg" alt="emb" width="1000"/>  

## **6. Дальнейшие исследования**

В следующих этапах проекта планируется расширить анализ за пределы базовой классификации текстов и эмбеддингового моделирования, сосредоточившись на более глубоком понимании содержания и восприятия постов с дезинформацией.

Во-первых, будет проведён **анализ эмоциональной окраски комментариев**, особенно со стороны медицинских работников, с использованием специализированных моделей анализа настроений, таких как `distilroberta-base-uncased-emotion`. Это позволит выявить, какие типы дезинформации вызывают наибольший эмоциональный отклик, и какова тональность реакции аудитории — от поддержки до возмущения.

Во-вторых, исследование будет дополнено **географическим анализом**, направленным на изучение различий в тематике, эмоциональной реакции и распространённости дезинформации в зависимости от региона (в частности, по регионам Великобритании). Такая детализация может выявить локальные особенности восприятия пандемии и вакцинной информации.

Третьим направлением станет **анализ постов по числовым метрикам**, включая охват, количество лайков, дизлайков, комментариев и репостов. Это позволит установить, какие виды контента получают наибольшее внимание, как дезинформация коррелирует с вовлечённостью пользователей и какие сообщения становятся вирусными. Дополнительно будет оценено, как реакции Facebook (например, «грусть», «злость», «нравится») соотносятся с содержанием поста и тональностью комментариев.

Наконец, особое внимание будет уделено **тематическому моделированию с использованием BERTopic**. Этот метод позволит автоматически выявлять скрытые темы внутри постов и кластеров, а также изучить, как распределяются темы между разными категориями (фейк, факт, комментарий), географическими регионами и эмоциональными реакциями. Тематический анализ также станет важным инструментом для верификации и интерпретации дезинформационных кластеров.

Эти направления позволят перейти от статической классификации к многомерному исследованию структуры и воздействия дезинформации, дополняя автоматический анализ более глубокими контекстуальными и поведенческими характеристиками.

## **Описание датасета**

Для построения модели по классификации дезинформации был сформирован составной корпус текстов, включающий как реальные, так и синтетические данные. Основу датасета составили записи, собранные с открытых источников на платформе Hugging Face, охватывающие как сообщения СМИ, так и пользовательские комментарии из социальных сетей. Данные были приведены к единому формату, содержащему текст сообщения, его метку (`label`) и источник (`source`), что позволило использовать их как для обучения модели, так и для последующего анализа.

Одним из центральных источников стал датасет [`nanyy1025/covid_fake_news`](https://huggingface.co/datasets/nanyy1025/covid_fake_news), включающий более 10 000 твитов с метками “real” или “fake”. Эти данные были получены в рамках проекта *Fighting an Infodemic* [Patwa et al., 2020], и представляют собой сбалансированную коллекцию коротких утверждений, используемых в задачах классификации и zero-shot обучения. Также были использованы датасеты [`justinqbui/covid_fact_checked_google_api`](https://huggingface.co/datasets/justinqbui/covid_fact_checked_google_api) и [`justinqbui/covid_fact_checked_polifact`](https://huggingface.co/datasets/justinqbui/covid_fact_checked_polifact), содержащие утверждения, проверенные через Google Fact Checker API и платформу PolitiFact соответственно. Эти данные охватывают утверждения, маркированные по шкале достоверности, включая как бинарные оценки (“true” / “false”), так и более развернутые категории.

В дополнение к источникам с фактчекинговыми утверждениями в корпус были включены пользовательские комментарии. Комментарии из канадского сабреддита Reddit (`beenakurian/reddit_comments_subreddit_canada`) и датасет токсичных высказываний (`AiresPucrs/toxic-comments`) были добавлены для представления нейтральной и негативной пользовательской активности. Отдельно был использован крупномасштабный корпус твитов с разметкой по тональности — [`gxb912/large-twitter-tweets-sentiment`](https://huggingface.co/datasets/gxb912/large-twitter-tweets-sentiment), который позволил дополнительно учесть эмоциональный фон сообщений.

Для устранения дисбаланса и расширения тематического охвата в датасет были добавлены **синтетические тексты**, сгенерированные с использованием языковой модели GPT. Генерация включала утверждения как фейкового, так и правдивого характера. При этом использовались шаблонные промты, направленные на создание коротких, нейтральных, сенсационных и сравнительных утверждений. Примеры промтов включали:  
«Напиши 50 фейковых утверждений о распространении коронавируса (3 предложения)»;  
«Создай 50 правдивых утверждений о вакцинации (1 предложение)»;  
«Составь утверждение, где одно предложение — правда, а второе — фейк»;  
«Сформулируй научно звучащие, но ложные утверждения о COVID-19».

Все сгенерированные тексты прошли ручную валидацию с целью исключения бессмысленных формулировок и повторов. Каждая синтетическая запись была явно помечена как `synthetic`, чтобы сохранить прозрачность структуры корпуса. Генерация синтетики позволила повысить тематическую и лексическую вариативность, а также усилить способность модели обобщать редкие или искажённые формы дезинформации.


### **Таблица 1. Краткие характеристики использованных датасетов**

| Название датасета                              | Источник               | Тип данных          | Аннотация                     | Назначение                         |
|------------------------------------------------|------------------------|---------------------|-------------------------------|------------------------------------|
| nanyy1025/covid_fake_news                      | Hugging Face           | Твиты               | real / fake                   | Классификация фейковых новостей   |
| justinqbui/covid_fact_checked_google_api       | Hugging Face           | Факты               | true / false                  | Верификация утверждений           |
| justinqbui/covid_fact_checked_polifact         | Hugging Face           | Факты               | 7-балльная и 3-балльная шкала | Проверка достоверности            |
| beenakurian/reddit_comments_subreddit_canada   | Hugging Face           | Комментарии (Reddit)| sentiment (нейтрально и др.) | Моделирование пользовательской речи |
| AiresPucrs/toxic-comments                      | Hugging Face           | Комментарии         | токсично / нет                | Анализ токсичности                |
| gxb912/large-twitter-tweets-sentiment          | Hugging Face           | Твиты               | positive / negative           | Анализ тональности                |
| synthetic (GPT)                                | Сгенерированные        | Факты и фейки       | synthetic / real              | Балансировка и разнообразие корпуса |

### **Таблица 2. Количественные параметры объединённого датасета**

| Источник данных                                | Объём записей | Язык      | Формат        | Класс(ы)                         |
|------------------------------------------------|----------------|-----------|---------------|----------------------------------|
| nanyy1025/covid_fake_news                      | 10 700         | Английский | CSV / JSON    | real, fake                       |
| justinqbui/covid_fact_checked_google_api       | 3 043          | Английский | CSV / Parquet | true, false                      |
| justinqbui/covid_fact_checked_polifact         | 1 190          | Английский | CSV / Parquet | adjusted_rating (3 класса)       |
| reddit_comments_subreddit_canada               | 6 908          | Английский | CSV / Parquet | sentiment                        |
| toxic-comments                                 | 70 157         | Английский | CSV / Parquet | токсичность                      |
| large-twitter-tweets-sentiment                 | 224 994        | Английский | CSV           | sentiment (0, 1)                 |
| synthetic data (GPT)                           | ~1 000         | Английский | CSV / JSON    | fake, real                       |
| **Результирующий объединённый датасет**        | **318 331**    | Английский | Parquet / CSV | **Comments (302 059)**<br>**Fake (9 665)**<br>**Real (6 607)** |

### **Литература**
1. Patwa, P. et al. (2020). *Fighting an Infodemic: COVID-19 Fake News Dataset*. arXiv:2011.03327. [Hugging Face](https://huggingface.co/datasets/nanyy1025/covid_fake_news)  
2. [`justinqbui/covid_fact_checked_google_api`](https://huggingface.co/datasets/justinqbui/covid_fact_checked_google_api)  
3. [`justinqbui/covid_fact_checked_polifact`](https://huggingface.co/datasets/justinqbui/covid_fact_checked_polifact)  
4. [`beenakurian/reddit_comments_subreddit_canada`](https://huggingface.co/datasets/beenakurian/reddit_comments_subreddit_canada)  
5. [`AiresPucrs/toxic-comments`](https://huggingface.co/datasets/AiresPucrs/toxic-comments)  
6. [`gxb912/large-twitter-tweets-sentiment`](https://huggingface.co/datasets/gxb912/large-twitter-tweets-sentiment)

